{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fl7yR7P3CTTj"
   },
   "source": [
    "### ライブラリの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A7IQqCE7mCeD"
   },
   "source": [
    "###モジュールのインポートとGoogleドライブのマウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WLEMbaPJOs9v",
    "outputId": "f47ad633-eb58-49cd-8893-914d53aa4475",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-04 02:05:51.007948: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-04 02:05:51.054254: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-04 02:05:52.238259: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch.autograd\n",
    "\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import datetime\n",
    "#from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import copy\n",
    "import gc\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from PIL import Image\n",
    "import skimage.transform\n",
    "from collections import deque\n",
    "from typing import Sequence, Dict, Tuple, Union, Optional\n",
    "#from argparse import Namespace\n",
    "from dataclasses import dataclass, field\n",
    "from sacrebleu.metrics import BLEU\n",
    "from evaluate import load\n",
    "import jiwer\n",
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torchvision import models\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as dataset\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "#from timm.scheduler import CosineLRScheduler\n",
    "from transformers import  get_linear_schedule_with_warmup\n",
    "\n",
    "#from transformers import AutoImageProcessor, AutoModel, AutoProcessor, CLIPVisionModel\n",
    "#from transformers import AutoTokenizer, CLIPVisionModel, AutoModelForCausalLM\n",
    "from transformers import BertTokenizer, BertModel, CLIPVisionModel, BertForPreTraining\n",
    "\n",
    "import sys\n",
    "from evaluate import load\n",
    "\n",
    "import util\n",
    "import levenshtein\n",
    "from nltk import bleu_score\n",
    "#from torchmetrics.multimodal.clip_score import CLIPScore\n",
    "from torchmetrics.multimodal import CLIPScore\n",
    "import ssl\n",
    "from torch.amp import autocast, GradScaler\n",
    "from collections import OrderedDict\n",
    "from rouge_score import rouge_scorer\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "import json\n",
    "import collections\n",
    "from collections import Counter\n",
    "import plotly\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from optuna.storages import JournalStorage\n",
    "from optuna.storages.journal import JournalFileBackend\n",
    "fn = bleu_score.SmoothingFunction().method7\n",
    "import time\n",
    "from pycocoevalcap.spice.spice import Spice\n",
    "#logging.getLogger('rouge_score.rouge_scorer').setLevel(logging.WARNING)\n",
    "#logging.set_verbosity_warning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    '''\n",
    "    位置埋め込み （Positional embedding）\n",
    "    dim_embedding: 埋込み次元\n",
    "    max_len      : 入力の最大系列長\n",
    "    '''\n",
    "    def __init__(self, dim_embedding: int, max_len: int=2048):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pos_emb = nn.Embedding(max_len, dim_embedding)\n",
    "\n",
    "    '''\n",
    "    位置エンコーディングの順伝播\n",
    "    x: 位置エンコーディングを埋め込む対象のテンソル,\n",
    "       [バッチサイズ, 系列長, 埋め込み次元]\n",
    "    '''\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        seq = x.shape[1]\n",
    "        positions = torch.arange(start=0, end=seq, step=1, device=x.device).to(torch.long)\n",
    "        positions = self.pos_emb(positions)[:seq,:]\n",
    "        \n",
    "        return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google-bert/bert-large-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_id)\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "cls_token_id = tokenizer.cls_token_id\n",
    "sep_token_id = tokenizer.sep_token_id\n",
    "sos_token_id = tokenizer.encode( [ \"[unused0]\" ] )[1]\n",
    "eos_token_id = tokenizer.encode( [ \"[unused1]\" ] )[1]\n",
    "a_token_id = tokenizer.encode( [ \"a\" ] )[1]\n",
    "the_token_id = tokenizer.encode( [ \"the\" ] )[1]\n",
    "and_token_id = tokenizer.encode( [ \"and\" ] )[1]\n",
    "in_token_id = tokenizer.encode( [ \"in\" ] )[1]\n",
    "we_token_id = tokenizer.encode( [ \"we\" ] )[1]\n",
    "i_token_id = tokenizer.encode( [ \"i\" ] )[1]\n",
    "he_token_id = tokenizer.encode( [ \"he\" ] )[1]\n",
    "she_token_id = tokenizer.encode( [ \"she\" ] )[1]\n",
    "it_token_id = tokenizer.encode( [ \"it\" ] )[1]\n",
    "they_token_id = tokenizer.encode( [ \"they\" ] )[1]\n",
    "period_token_id = tokenizer.encode( [ \".\" ] )[1]\n",
    "comma_token_id = tokenizer.encode( [ \",\" ] )[1]\n",
    "dbl_token_id = tokenizer.encode( [ '\"' ] )[1]\n",
    "sgl_token_id = tokenizer.encode( [ \"'\" ] )[1]\n",
    "\n",
    "\n",
    "# 辞書サイズを保存\n",
    "vocab_size = len( tokenizer )\n",
    "\n",
    "class ComputeReward(nn.Module):\n",
    "    def __init__(self, device, reward_t = 'ordinary', decode_t = 'ordinary', sentence_level_metric=\"bleu\", \n",
    "                 repeat_thresh = [4,2,2,2], repeat_weight = [0.5, 1, 1, 2], cider_coef = 1.0, rouge_coef = 1.0, clip_coef = 2.0, \n",
    "                 bert_coef = 1.0, use_amp = True ):\n",
    "        super().__init__()\n",
    "        self.metric = sentence_level_metric\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tgt_lang = \"en\"\n",
    "        self.device = device\n",
    "\n",
    "        if sentence_level_metric =='special':\n",
    "            #self.bleu = BLEU(effective_order=\"True\")\n",
    "            self.scorer = Cider()\n",
    "            #self.meteor = load('meteor')\n",
    "            self.rougeL = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "            self.bert = load('bertscore')\n",
    "            self.metric = CLIPScore(model_name_or_path=\"openai/clip-vit-base-patch32\").to(self.device)\n",
    "            for param in self.metric.parameters():\n",
    "                param.requires_grad = False\n",
    "            self.spider = Spice()\n",
    "        elif sentence_level_metric == 'bleu':\n",
    "            self.bleu = BLEU(effective_order=\"True\")\n",
    "        elif sentence_level_metric == 'meteor':\n",
    "            self.meteor = load('meteor')\n",
    "        elif sentence_level_metric == 'rouge':\n",
    "            self.rougeL = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "        elif sentence_level_metric == 'cider':\n",
    "            self.scorer = Cider() \n",
    "        elif sentence_level_metric == 'ter':\n",
    "            #self.ter = load('ter')\n",
    "            pass\n",
    "        elif sentence_level_metric == 'bert':\n",
    "            #self.bert = load('bertscore')\n",
    "            pass\n",
    "        elif sentence_level_metric == 'bleurt':\n",
    "            #self.bleurt = load('bleurt', module_type='metric', checkpoint='bleurt-large-128')\n",
    "            pass\n",
    "        elif self.metric == \"comet\":\n",
    "            model_path = download_model(\"Unbabel/wmt22-comet-da\")\n",
    "            self.comet = load_from_checkpoint(model_path)\n",
    "        self.reward_t = reward_t\n",
    "        self.repeat_thresh = repeat_thresh\n",
    "        self.repeat_weight = repeat_weight\n",
    "        self.decode_t = decode_t\n",
    "        self.cider_coef = cider_coef\n",
    "        self.rouge_coef = rouge_coef\n",
    "        self.clip_coef = clip_coef\n",
    "        self.bert_coef = bert_coef\n",
    "        self.use_amp = use_amp\n",
    "    \n",
    "    def _compute_reward_ord(self, preds, targets, imgs2, sources=None):\n",
    "        \"\"\"\n",
    "        Compute reward metric for a batch of prediction and target sentences\n",
    "        \"\"\"\n",
    "        model_name = \"distilbert-base-uncased\"\n",
    "        # detokenize (convert to str) preds & targets\n",
    "        if self.decode_t == 'no-endoftext':\n",
    "            preds_str = [self.tokenizer.decode(\n",
    "                [pred[i] for i in range( 1,  len( pred )  ) if not (pred[i-1] == endoftext_token_id and pred[i] == endoftext_token_id) ]\n",
    "                ) for pred in preds]\n",
    "            targets_str = [self.tokenizer.decode(\n",
    "                [target[i] for i in range( 1,  len( target )  ) if not (target[i-1] == endoftext_token_id and target[i] == endoftext_token_id) ]\n",
    "                ) for target in targets]\n",
    "        elif self.decode_t == 'no-pad':\n",
    "            preds_str = [self.tokenizer.decode(\n",
    "                [ i for i in pred \\\n",
    "                 if i != pad_token_id \\\n",
    "                 and i != eos_token_id ] \\\n",
    "                ) for pred in preds]\n",
    "            preds_str2 = [self.tokenizer.decode(\n",
    "                [ i for i in pred \\\n",
    "                 if  i != eos_token_id  ] \\\n",
    "                 , skip_special_tokens = True ) for pred in preds]\n",
    "            targets_str = [self.tokenizer.decode(\n",
    "                [ i for i in target \\\n",
    "                if i != pad_token_id \\\n",
    "                 and i != eos_token_id ]       \n",
    "                ) for target in targets]\n",
    "        else:\n",
    "            preds_str = [self.tokenizer.decode(pred) for pred in preds]\n",
    "            targets_str = [self.tokenizer.decode(target) for target in targets]\n",
    "        sources_str = [self.tokenizer.decode(source, ref=\"src\") for source in sources] if sources is not None else None\n",
    "        #print( \"preds size:\", preds.size() )\n",
    "        #print( \"targets size:\", targets.size() )\n",
    "        \n",
    "        #print(f'1st target sent: {targets_str[0]}')\n",
    "        #print(f'1st pred sent: {preds_str[0]}')\n",
    "\n",
    "        # compute reward metric\n",
    "        seq_len = preds.shape[1]\n",
    "\n",
    "        if self.metric == 'special':\n",
    "            #reward_bleu = [[self.bleu.sentence_score(pred, [target]).score] * seq_len for pred, target in zip(preds_str, targets_str)]\n",
    "            #reward_bleu = [[bleu_score.sentence_bleu( target, pred, smoothing_function=fn)] * seq_len for pred, target in zip(preds_str, targets_str)]\n",
    "            #reward_bleu = torch.tensor(reward_bleu).to(self.device) / 100.0\n",
    "            #wer_scores = [jiwer.wer(target, pred) for pred, target in zip(targets_str, preds_str)]\n",
    "            #reward = [[score] * seq_len for score in wer_scores]\n",
    "            #reward_wer = - torch.tensor( reward ).to(self.device)\n",
    "            #start_time = time.time()\n",
    "            pred_dict = { str(i): [item] for i, item in enumerate( preds_str)}\n",
    "            target_dict = { str(i): [item] for i, item in enumerate( targets_str)}\n",
    "            score, scores = self.scorer.compute_score(target_dict, pred_dict)\n",
    "            reward_cider = torch.tensor( scores ).to( self.device )[:,None].expand( -1, seq_len )\n",
    "            #end_time = time.time()\n",
    "            #print( \"cider time:\", end_time - start_time )\n",
    "            #start_time = time.time()\n",
    "            reward_rouge = [[self.rougeL.score(target, pred)['rougeL'][0]]  * seq_len for pred, target in zip(preds_str, targets_str)]\n",
    "            reward_rouge = torch.tensor( reward_rouge ).to( self.device )\n",
    "            #end_time = time.time()\n",
    "            #print( \"rouge time:\", end_time - start_time )\n",
    "            #start_time = time.time()\n",
    "            with autocast(str(self.device),enabled=self.use_amp):\n",
    "                with torch.no_grad():\n",
    "                    #clip_scores = [[self.metric( img2, pred).detach()] * seq_len for img2, pred in zip( imgs2, preds_str2 )]\n",
    "                    #tmp = self.metric( imgs2, preds_str2 )\n",
    "                    #print( \"tmp size:\", tmp.size() )\n",
    "                    #clip_scores = [[self.metric( imgs2, preds_str2 ).detach()] * seq_len ]\n",
    "                    processed = self.metric.processor(text=preds_str2, images=imgs2, return_tensors=\"pt\", padding=True, \\\n",
    "                                                      truncation=True, max_length=77 ).to(self.device)\n",
    "                    outputs = self.metric.model(**processed)\n",
    "                    # 特徴量の正規化\n",
    "                    image_features = outputs.image_embeds / outputs.image_embeds.norm(p=2, dim=-1, keepdim=True)\n",
    "                    text_features = outputs.text_embeds / outputs.text_embeds.norm(p=2, dim=-1, keepdim=True)\n",
    "                    # 3. コサイン類似度を一括計算 (100倍してマイナスをカットするのが CLIPScore の定義)\n",
    "                    # 各画像ペアの個別スコア (Batch Size,) が得られる\n",
    "                    individual_scores = torch.clamp( (image_features * text_features).sum(axis=-1), min=0)\n",
    "                    #print( \"individual_scores size:\", individual_scores.size() )\n",
    "                    clip_scores = individual_scores[:,None].expand( -1, seq_len ).to( self.device ) / 100.0\n",
    "                    #print( \"clip_scores size:\", clip_scores.size() )\n",
    "                    reward_clip = clip_scores\n",
    "                    #end_time = time.time()\n",
    "                    #print( \"clip time:\", end_time - start_time )\n",
    "                    #start_time = time.time()\n",
    "                    bert_scores = self.bert.compute(predictions=preds_str, references=targets_str, use_fast_tokenizer=True, \\\n",
    "                                            model_type=model_name, lang='en',  device=self.device)['f1']\n",
    "                    reward_bert = torch.tensor( bert_scores )[:,None].expand( -1, seq_len ).to( self.device )\n",
    "                    #end_time = time.time()\n",
    "                    #print( \"bert time:\", end_time - start_time )\n",
    "            #image = torch.randint(255, (3, 224, 224), generator=torch.Generator().manual_seed(42))\n",
    "            #score = metric(image, \"a photo of a cat\")\n",
    "            #average_score, scores = self.spice.compute_score(target_dict, pred_dict)\n",
    "            #print( \"average_score:\", average_score ) \n",
    "            #reward_spice = torch.tensor( scores ).to( self.device )[:,None].expand( -1, seq_len )\n",
    "            #meteor_scores = [self.meteor.compute(predictions=[preds], references=[targets])['meteor'] for preds, targets in zip(preds_str, targets_str)]\n",
    "            #reward_meteor = [[score] * seq_len for score in meteor_scores]\n",
    "            #reward_meteor = torch.tensor( reward_meteor ).to( self.device )\n",
    "            #reward = reward_bleu + reward_cider\n",
    "            #print( \"reward_bleu:\", reward_bleu )\n",
    "            #print( \"reward_cider:\", reward_cider )\n",
    "            #print( \"reward_meteor:\", reward_meteor )\n",
    "            #reward = reward_meteor + reward_cider\n",
    "            #print( \"self.bert_coef:\", self.bert_coef )\n",
    "            #print( \"reward_bert:\", reward_bert )\n",
    "            #reward = self.clip_coef * reward_clip + self.bert_coef * reward_bert\n",
    "            reward = self.cider_coef * reward_cider + self.rouge_coef * reward_rouge \\\n",
    "                + self.clip_coef * reward_clip + self.bert_coef * reward_bert\n",
    "            reward2 = reward_cider + reward_rouge + reward_bert + reward_clip\n",
    "            #score, scores = self.spider.compute_score(gts, res)\n",
    "            #reward_rouge = [[self.spider.compute_score(target, pred)[1]]  * seq_len for pred, target in zip(preds_str, targets_str)]\n",
    "            #reward2 = reward_rouge + reward_bert + reward_clip\n",
    "            #reward = self.rouge_coef * reward_rouge + self.cider_coef * reward_cider + self.clip_coef * reward_clip \\\n",
    "            #    + self.bert_coef * reward_bert\n",
    "            #reward = reward_bleu + reward_cider\n",
    "            #reward = reward_bleu + reward_cider + reward_meteor\n",
    "            #reward = reward_wer + reward_cider\n",
    "            #reward = reward_bleu + reward_wer + reward_cider\n",
    "            #reward = reward_bleu + reward_wer + reward_cider + reward_meteor\n",
    "            #print( \"wer:\", reward_wer )\n",
    "            #print( \"cider:\", reward_cider )\n",
    "        elif self.metric == \"bleu\":\n",
    "            reward = [[self.bleu.sentence_score(pred, [target]).score] * seq_len for pred, target in zip(preds_str, targets_str)]\n",
    "        \n",
    "        elif self.metric == \"meteor\":\n",
    "            meteor_scores = [self.meteor.compute(predictions=[preds], references=[targets])['meteor'] for preds, targets in zip(preds_str, targets_str)]\n",
    "            reward = [[score] * seq_len for score in meteor_scores]\n",
    "            \n",
    "        elif self.metric == \"rouge\":\n",
    "            #rouge_scores = self.rouge.compute(predictions=preds_str, references=targets_str, use_aggregator=False )['rougeL']\n",
    "            reward = [[self.rouge.score(target, pred)['rougeL'][0]]  * seq_len for pred, target in zip(preds_str, targets_str)]\n",
    "        \n",
    "        elif self.metric == \"wer\":\n",
    "            wer_scores = [jiwer.wer(target, pred) for pred, target in zip(targets_str, preds_str)]\n",
    "            reward = [[score] * seq_len for score in wer_scores]\n",
    "            reward = - torch.tensor( reward )\n",
    "\n",
    "        elif self.metric == 'cider':\n",
    "            pred_dict = { str(i): [item] for i, item in enumerate( preds_str)}\n",
    "            target_dict = { str(i): [item] for i, item in enumerate( targets_str)}\n",
    "            #score, all_scores = parallel_cider_evaluation( target_dict, pred_dict )\n",
    "            score, scores = self.scorer.compute_score(target_dict, pred_dict)\n",
    "            reward = torch.tensor( scores ).to( self.device )[:,None].expand( -1, seq_len )\n",
    "            \n",
    "        #elif self.metric == \"bert\":\n",
    "        #    bert_scores = self.bert.compute(predictions=preds_str, references=targets_str, lang='en')['f1']\n",
    "        #    reward = [[score] * seq_len for score in bert_scores]\n",
    "\n",
    "        #elif self.metric == \"bleurt\":\n",
    "        #    bleurt_scores = self.bleurt.compute(predictions=preds_str, references=targets_str)['scores']\n",
    "        #    reward = [[score] * seq_len for score in bleurt_scores]\n",
    "            \n",
    "        elif self.metric == \"comet\":\n",
    "            data = [{\"src\": source, \"mt\": pred, \"ref\": target} for source, pred, target in zip(sources_str, preds_str, targets_str)]\n",
    "            reward = self.comet.predict(data, batch_size=8, gpus=1)['scores']\n",
    "            reward = [[score] * seq_len for score in reward]\n",
    "        else:\n",
    "            raise ValueError(f\"metric {self.metric} not supported\")\n",
    "        if self.metric != 'cider' and self.metric != 'special':\n",
    "            reward = torch.tensor(reward).to(self.device)\n",
    "        \n",
    "        #print( \"reward size:\", reward.size() )\n",
    "        #return reward\n",
    "        return reward, reward2\n",
    "\n",
    "    def my_index(self, list1, target ):\n",
    "        if target in list1:\n",
    "            return list1.index( target )\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def compute_length_reward( self, preds, targets ):\n",
    "\n",
    "        #def differentiable_argamx( logits, tau ):\n",
    "\n",
    "        #    tmp = F.gumbel_softmax( logits, tau, hard=True )\n",
    "        #    tmp1 = torch.arange( 0, logits.size(2) )[None,None] * tmp\n",
    "        #    tokens = torch.sum( tmp1, dim = 2 )\n",
    "\n",
    "        #    return tokens\n",
    "        '''\n",
    "        pred_index = preds == eos_token_id\n",
    "        first_index = ( pred_index.int().cumsum(dim = 1 ) == 1 ) & pred_index\n",
    "        #print( first_index )\n",
    "        arange_index = torch.arange( 0, first_index.size(1), device = self.device )\n",
    "        pred_lengths = torch.sum( first_index.float() * arange_index.float(), dim = 1 ) / preds.size(1)\n",
    "        #print( pred_lengths ) \n",
    "        \n",
    "        reward = pred_lengths[:,None].expand( -1, preds.size(1) )\n",
    "        \n",
    "        return reward         \n",
    "        '''\n",
    "        \n",
    "        pred_index = preds == eos_token_id\n",
    "        first_index = ( pred_index.int().cumsum(dim = 1 ) == 1 ) & pred_index\n",
    "        arange_index = torch.arange( 0, first_index.size(1), device = self.device )\n",
    "        pred_lengths = torch.sum( first_index.float() * arange_index.float(), dim = 1 ) / preds.size(1)\n",
    "        \n",
    "        target_index = targets == eos_token_id\n",
    "        first_index = ( target_index.int().cumsum(dim = 1 ) == 1 ) & target_index\n",
    "        target_lengths = torch.sum( first_index.float() * arange_index.float(), dim = 1 ) / targets.size(1)\n",
    "        #target_lengths = 1.1 * torch.sum( first_index.float() * arange_index.float(), dim = 1 ) / targets.size(1)\n",
    "        #target_lengths = torch.clamp( target_lengths, max = 1.0 )\n",
    "        #target_lengths = torch.full((preds.size(0),), self.target_length / preds.size(1), device = self.device )\n",
    "        \n",
    "        reward_lengths = - nn.MSELoss(reduction='none')( pred_lengths, target_lengths )\n",
    "        #reward_lengths = - torch.abs( pred_lengths - target_lengths )\n",
    "        \n",
    "        reward = reward_lengths[:,None].expand( -1, preds.size(1) )\n",
    "        \n",
    "        return reward  \n",
    "        \n",
    "        #reward = torch.tensor( [ self.my_index( pred.tolist(), eos_token_id ) for pred in preds ] ).to(self.device )\n",
    "        #reward = reward[:,None].expand( -1, preds.size(1) ).float()\n",
    "        \n",
    "        ##tokens = differentiable_argamx( logits, tau ) #logits から token を算出。微分可能 B * T\n",
    "        \n",
    "        '''\n",
    "        tmp1 = torch.abs( preds - tokenizer.pad_token_id ) # pad だけ 0 あとは1以上の正の数 B * T\n",
    "        tmp2 = torch.abs( preds - eos_token_id ) # pad だけ 0 あとは1以上の正の数 B * T\n",
    "        tmp = tmp1 * tmp2\n",
    "        pad_preds = F.sigmoid( 10 - 100 * tmp ) # pad のところだけ 1, あとは 0。 B * T  \n",
    "        reward = ( torch.tensor( preds.size(1))[None] - torch.sum( pad_preds, dim = 1 ))[:,None].expand( -1, preds.size(1) ) \n",
    "        '''\n",
    "        # 固定長97 から　pad と eos の長さを引いて、文章の長さ。文章の長さが大きいほどよい。\n",
    "        \n",
    "        #tmp1 = torch.abs( targets - tokenizer.pad_token_id ) # pad だけ 0 あとは1以上の正の数 B * T\n",
    "        #tmp2 = torch.abs( targets - eos_token_id ) # pad だけ 0 あとは1以上の正の数 B * T\n",
    "        #tmp = tmp1 * tmp2\n",
    "        #pad_targets = F.sigmoid( 10 - 100 * tmp ) # pad のところだけ 1, あとは 0。 B * T\n",
    "        \n",
    "        #reward = - nn.MSELoss( reduction = 'none' )( pad_preds, pad_targets )\n",
    "        \n",
    "        #return  reward\n",
    "    \n",
    "    def calc_ngram_repeat( self, preds ):\n",
    "\n",
    "        bsz, seq_len = preds.size()\n",
    "        \n",
    "        ngram_cnt = torch.zeros( (bsz), device = preds.device, dtype = torch.float )\n",
    "        for n in range( 2, 4 ):\n",
    "            for i, pred in enumerate( preds ):\n",
    "                pred = pred.tolist()\n",
    "                ngrams = zip(*[pred[i:] for i in range(n)])\n",
    "                counts = Counter(ngrams)\n",
    "                count_sum = 0\n",
    "                for count in counts.values():\n",
    "                    if count >= self.repeat_thresh:\n",
    "                        count_sum = count_sum + count\n",
    "                ngram_cnt[i] = ngram_cnt[i] + count_sum\n",
    "\n",
    "        return - ngram_cnt[:,None].expand( -1, seq_len ) / seq_len\n",
    "\n",
    "    def unique_ngram_ratio(self, preds):\n",
    "        \n",
    "        bsz, seq_len = preds.size()\n",
    "        ng = 5\n",
    "        unr = torch.zeros( (bsz, ng), device=preds.device, dtype=torch.float)\n",
    "\n",
    "        pred_index = preds == eos_token_id\n",
    "        first_index = ( pred_index.int().cumsum(dim = 1 ) == 1 ) & pred_index\n",
    "        arange_index = torch.arange( 0, first_index.size(1), device = self.device )\n",
    "        pred_lengths = torch.sum( first_index * arange_index, dim = 1 )\n",
    "        \n",
    "        for b in range( bsz ):\n",
    "            for n in range( 0, ng - 1 ): # n は ngram - 1\n",
    "                if pred_lengths[b] > 0:\n",
    "                    #print( \"pred_lengths[b]:\", pred_lengths[b] )\n",
    "                    pred_tmp = preds[b,:pred_lengths[b]]\n",
    "                    #print( \"pred_tmp:\", pred_tmp )\n",
    "                else:\n",
    "                    pred_tmp = preds[b]\n",
    "                ngram_tensor = pred_tmp.unfold(0, n + 1, 1)\n",
    "                ngram_count = len( ngram_tensor )\n",
    "                unique_count = len( torch.unique( ngram_tensor ) )\n",
    "                #unique_count = len( set( map(tuple, ngram_tensor.tolist())))\n",
    "                unr[b,n] = unique_count / ngram_count\n",
    "\n",
    "        return torch.mean( unr, dim = 1)[:, None].expand(-1, seq_len)\n",
    "    \n",
    "    def calc_ngram_repeat_fast(self, preds):\n",
    "        bsz, seq_len = preds.size()\n",
    "        ngram_cnt = torch.zeros(bsz, device=preds.device, dtype=torch.float)\n",
    "        \n",
    "        for n in range(1, 5):\n",
    "            # 無視するトークンのリスト\n",
    "            #ignore_ids = [self.pad_token_id, self.eos_token_id, self.cls_token_id, self.sep_token_id]\n",
    "            if n == 1:\n",
    "                ignore_ids = [pad_token_id, eos_token_id, cls_token_id, sep_token_id, a_token_id, the_token_id, \\\n",
    "                              period_token_id, comma_token_id, and_token_id, in_token_id ]\n",
    "            else:\n",
    "                ignore_ids = [pad_token_id, eos_token_id, cls_token_id, sep_token_id]\n",
    "            \n",
    "            # 1. 無視すべきトークンの位置を特定 (bsz, seq_len)\n",
    "            # ignore_mask[b, i] が True なら、そのトークンは無視対象\n",
    "            ignore_mask = torch.zeros_like(preds, dtype=torch.bool)\n",
    "            for idx in ignore_ids:\n",
    "                ignore_mask |= (preds == idx)\n",
    "            \n",
    "            if seq_len < n:\n",
    "                continue\n",
    "            \n",
    "            # n-gram を抽出 (bsz, num_ngrams, n)\n",
    "            ngrams = preds.unfold(dimension=1, size=n, step=1)\n",
    "            \n",
    "            # 2. 各 n-gram に無視対象トークンが含まれているか判定\n",
    "            # n-gram内のいずれかが ignore_mask で True なら True\n",
    "            # (bsz, num_ngrams)\n",
    "            ngram_ignore_mask = ignore_mask.unfold(dimension=1, size=n, step=1).any(dim=-1)\n",
    "        \n",
    "            for b in range(bsz):\n",
    "                # このバッチの有効な n-gram だけを抽出\n",
    "                valid_ngrams = ngrams[b][~ngram_ignore_mask[b]]\n",
    "                \n",
    "                if valid_ngrams.size(0) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # ユニークな n-gram とそのカウントを取得\n",
    "                unique_ngrams, counts_per_ngram = torch.unique(valid_ngrams, dim=0, return_counts=True)\n",
    "                \n",
    "                # 閾値以上のカウントを合計\n",
    "                mask = counts_per_ngram >= self.repeat_thresh[n-1]\n",
    "                ngram_cnt[b] += counts_per_ngram[mask].sum().float() * self.repeat_weight[n-1]\n",
    "\n",
    "        penalty = - torch.clamp( torch.pow( 2, ngram_cnt -1 ) / seq_len, max = 1.0 )    \n",
    "        \n",
    "        return penalty[:, None].expand(-1, seq_len)\n",
    "    \n",
    "    def calc_cnt_repeat( self, preds ):\n",
    "\n",
    "        B, T = preds.size()\n",
    "\n",
    "        repeat_count = torch.zeros( ( bsz, vocab_size ), device = preds.device )\n",
    "        for i, pred in enumerate( preds ):\n",
    "            repeat_count0 = torch.bincount( pred )\n",
    "            repeat_count[i,:len(repeat_count0)] = repeat_count0 \n",
    "\n",
    "        repeat_count[:,pad_token_id] = 0\n",
    "        repeat_count[:,eos_token_id] = 0\n",
    "        repeat_count[:,cls_token_id] = 0\n",
    "        repeat_count[:,sep_token_id] = 0\n",
    "        thresh_masks = repeat_count >= self.repeat_thresh\n",
    "        repeat_count = repeat_count * thresh_masks\n",
    "\n",
    "        repeat = torch.sum( repeat_count, dim = 1 )\n",
    "        \n",
    "        return - repeat[:,None].expand( -1, T ).float() / seq_len\n",
    "        '''\n",
    "        B, T = preds.size()\n",
    "\n",
    "        repeat_count = torch.zeros( ( bsz, vocab_size ), device = preds.device )\n",
    "        for i, pred in enumerate( preds ):\n",
    "            repeat_count0 = torch.bincount( pred )\n",
    "            repeat_count[i,:len(repeat_count0)] = repeat_count0 \n",
    "\n",
    "        repeat_times = torch.sum( repeat_count >= self.repeat_thresh, dim = 1 )\n",
    "        #print( \"repeat_times:\",repeat_times )\n",
    "\n",
    "        pad_count = repeat_count[:,pad_token_id]\n",
    "        pad_times = (pad_count >= self.repeat_thresh).long()\n",
    "        #print( \"pad_times:\", pad_times )\n",
    "\n",
    "        eos_count = repeat_count[:,eos_token_id]\n",
    "        eos_times = (eos_count >= self.repeat_thresh).long()\n",
    "        #print( \"eos_times:\", eos_times )\n",
    "\n",
    "        repeat = repeat_times - pad_times - eos_times\n",
    "        #print( repeat )\n",
    "\n",
    "        #print( \"repeat size:\", repeat.size() )\n",
    "        \n",
    "        return - repeat[:,None].expand( -1, T ).float()\n",
    "        '''\n",
    "        '''\n",
    "        tokens = preds\n",
    "        #tokens[0,0] = 1000\n",
    "        #tokens[0,1] = 1000\n",
    "        #print( \"tokens size:\", tokens.size() )\n",
    "        #print( \"tokens[:,0]:\", tokens[:,0] )\n",
    "    \n",
    "        cnt = torch.zeros( (B, T),  device=preds.device, dtype=torch.float16 )\n",
    "        for i in range( T ):\n",
    "            cntj = torch.zeros( (B),  device=preds.device, dtype=torch.float16 )\n",
    "            num_j = 0\n",
    "            for j in range( max( 0, i - self.c ), min(  T, i + self.c ) ):\n",
    "                if j != i:\n",
    "                    ##print( \"torch.eq\", torch.eq( tokens[:,i], tokens[:,j]))\n",
    "                    #tmp1 = torch.eq( tokens[:,i], tokens[:,j]) \n",
    "                    #tmp2 = torch.ne( tokens[:,i], eos_token_id )\n",
    "                    #tmp3 = torch.ne( tokens[:,i], tokenizer.pad_token_id )\n",
    "                    ##print( \"tmp1:\", tmp1 )\n",
    "                    ##print( \"tmp2:\", tmp2 )\n",
    "                    ##print( \"tmp3:\", tmp3 )\n",
    "                    #tmp = (torch.logical_and(torch.logical_and( tmp1 , tmp2 ),tmp3 )).to(torch.float16)\n",
    "                    if self.decode_t == 'no-endoftext':\n",
    "                        tmp = ((tokens[:,i] != tokens[:,j] ).to(torch.float) ) * 10 \\\n",
    "                            +  ((tokens[:,i] == endoftext_token_id).to(torch.float) )  * 10\n",
    "                    elif self.decode_t == 'no-pad':\n",
    "                        tmp = ((tokens[:,i] != tokens[:,j] ).to(torch.float) ) * 10 \\\n",
    "                            + ((tokens[:,i] == pad_token_id).to(torch.float) )  * 10 \\\n",
    "                            + ((tokens[:,i] == eos_token_id).to(torch.float) ) * 10\n",
    "                            # tokens[:,i] と tokens[:,j] が同じで、tokens[:,i] が　eos、pad でなければ 0 その他は 10 以上の整数 \n",
    "                    tmp = F.sigmoid( 10 - 100 * tmp ) # tokens[:,i]とtokens[:,j] が同じで eos pad ではないところだけ 1, あとは 0.\n",
    "                    #if torch.any( tmp != 0 ):\n",
    "                    #    print( \"tmp:\", tmp )\n",
    "                    cntj = cntj + tmp # repeat の数。[B]  jについて足しこんでいる。\n",
    "                    #if torch.any( cntj != 0 ):\n",
    "                    #    print( \"cntj:\", cntj )\n",
    "                    num_j = num_j + 1\n",
    "            cnt[:,i] = cntj / num_j # repeat の数。[B] i について足しこんでいる。\n",
    "        \n",
    "        #mask = cnt != 0\n",
    "        #print( \"cnt mask:\", cnt[mask] )\n",
    "        #return - torch.mean( cnt, dim = 1 ) # \n",
    "        return - torch.mean( cnt, dim = 1 )[:,None].expand(-1, T )  # B * T repeat の数が少ないほど良い。repeat の数の -1 倍が多いほどよい。\n",
    "        '''\n",
    "    def forward(self, top_probs, sampled_beam_idx, top_indices, targets, imgs2,  sources=None, masks=None):\n",
    "        \"\"\"\n",
    "        outputs: batch x len x d_model\n",
    "        targets: batch x len\n",
    "        sources: batch x len\n",
    "        masks:   batch x len\n",
    "        \"\"\"\n",
    "        self.device = sampled_beam_idx.device\n",
    "        # input to device\n",
    "        targets = targets.to(self.device)\n",
    "        bsz, seq_len, beam = top_probs.size()\n",
    "        eps = 1e-8\n",
    "\n",
    "        preds = torch.gather( top_indices, -1, sampled_beam_idx ).squeeze( -1 )\n",
    "        tmp = torch.clamp( top_probs, eps )\n",
    "        top_log_probs = torch.log( tmp )\n",
    "        sample_log_probs = torch.gather( top_log_probs, -1, sampled_beam_idx ).squeeze( -1 )\n",
    "\n",
    "        if self.reward_t == 'ordinary':\n",
    "            reward_ord = self.compute_reward(preds, targets, imgs2, sources)   #  bsz\n",
    "            reward_repeat = torch.zeros( ( bsz, seq_len ),  device = preds.device, dtype=torch.float ) # bsz * seq_len\n",
    "            reward_length = torch.zeros( ( bsz, seq_len ),  device = preds.device, dtype=torch.float ) # bsz * seq_len\n",
    "            reward_unr = torch.zeros( ( bsz, seq_len ),  device = preds.device, dtype=torch.float ) # bsz * seq_len\n",
    "        elif self.reward_t == \"ord+rep\":\n",
    "            reward_ord = self._compute_reward_ord(preds, targets, imgs2, sources)  # bsz * seq_len\n",
    "            #reward_repeat = self.calc_cnt_repeat( preds ) + self.calc_ngram_repeat_fast( preds ) # bsz * seq_len\n",
    "            reward_repeat = self.calc_ngram_repeat_fast( preds ) # bsz * seq_len\n",
    "            reward_length = torch.zeros( ( bsz, seq_len ),  device = preds.device, dtype=torch.float ) # bsz * seq_len\n",
    "            #reward = reward_ord + reward_repeat - b # bsz * seq_len\n",
    "            reward_unr = torch.zeros( ( bsz, seq_len ),  device = preds.device, dtype=torch.float ) # bsz * seq_len\n",
    "        elif self.reward_t == \"ord+rep+len\":\n",
    "            reward_ord, reward_ord2 = self._compute_reward_ord(preds, targets, imgs2, sources)  # bsz * seq_len\n",
    "            #reward_ord = self._compute_reward_ord(preds, targets, imgs2, sources)  # bsz * seq_len\n",
    "            #reward_repeat = self.calc_cnt_repeat( preds ) + self.calc_ngram_repeat_fast( preds ) # bsz * seq_len\n",
    "            reward_repeat = self.calc_ngram_repeat_fast( preds ) # bsz * seq_len\n",
    "            reward_length = self.compute_length_reward( preds, targets ) # bsz * seq_len\n",
    "            reward_unr = torch.zeros( ( bsz, seq_len ),  device = preds.device, dtype=torch.float ) # bsz * seq_len\n",
    "        elif self.reward_t == 'ord+len':\n",
    "            reward_ord = self._compute_reward_ord(preds, targets, imgs2, sources)  # bsz * seq_len\n",
    "            #reward_repeat = self.calc_cnt_repeat( preds ) + self.calc_ngram_repeat_fast( preds ) # bsz * seq_len\n",
    "            reward_repeat = self.calc_ngram_repeat_fast( preds ) # bsz * seq_len\n",
    "            reward_length = self.compute_length_reward( preds, targets ) # bsz * seq_len\n",
    "            reward_unr = torch.zeros( ( bsz, seq_len ),  device = preds.device, dtype=torch.float ) # bsz * seq_len\n",
    "        elif self.reward_t == 'ord+rep+len+unr':\n",
    "            reward_ord, reward_ord2 = self._compute_reward_ord(preds, targets, imgs2, sources)  # bsz * seq_len\n",
    "            reward_repeat = self.calc_ngram_repeat_fast( preds ) # bsz * seq_len\n",
    "            reward_length = self.compute_length_reward( preds, targets ) # bsz * seq_len\n",
    "            reward_unr = self.unique_ngram_ratio(preds)\n",
    "        \n",
    "        ## apply mask\n",
    "        #if masks is not None:\n",
    "        #    masks = masks.to(self.device)\n",
    "        #    probs, targets = probs[masks], targets[masks]\n",
    "        #    # outputs, targets = outputs[masks], targets[masks]\n",
    "        #    reward, preds = reward[masks], preds[masks]\n",
    "       \n",
    "        return reward_ord, reward_ord2, reward_repeat, reward_length, reward_unr, preds, sample_log_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ja_g99AUIJTF"
   },
   "source": [
    "### Transformerデコーダの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siyThdM4Icll"
   },
   "source": [
    "### CaptioningTransformerの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x, dim=1):\n",
    "    return torch.logsumexp(x.float(), dim=dim).type_as(x)\n",
    "\n",
    "class DynamicCRF(nn.Module):\n",
    "    def __init__(self, num_embedding, low_rank=32, beam_size=64, crf_coef=1.0, temp = 0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        #low_rank = num_embedding\n",
    "        self.E1 = nn.Embedding(num_embedding, low_rank)\n",
    "        self.E2 = nn.Embedding(num_embedding, low_rank)\n",
    "\n",
    "        self.vocb = num_embedding\n",
    "        self.rank = low_rank\n",
    "        self.beam = beam_size\n",
    "        self.crf_coef = crf_coef\n",
    "        self.temp = temp\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"vocab_size={}, low_rank={}, beam_size={}\".format(\n",
    "            self.vocb, self.rank, self.beam)\n",
    "\n",
    "    def forward(self, emissions, top_logits, top_indices, targets, masks, beam=None):\n",
    "        numerator = self._compute_score(emissions, targets, masks)\n",
    "        denominator = self._compute_normalizer(emissions, targets, masks, beam )\n",
    "        beam_probs = self._compute_normalizer2(top_logits, top_indices, targets, masks, beam)\n",
    "\n",
    "        return numerator - denominator, beam_probs\n",
    "    \n",
    "    def forward_decoder(self, emissions, masks=None, beam=None):\n",
    "        return self._viterbi_decode(emissions, masks, beam)\n",
    "\n",
    "    def _compute_score(self, emissions, targets, masks=None):\n",
    "        batch_size, seq_len = targets.size()\n",
    "\n",
    "        emission_scores = emissions.gather(2, targets[:, :, None])[:, :, 0]  # B x T\n",
    "        transition_scores = (self.E1(targets[:, :-1]) * self.E2(targets[:, 1:])).sum(2)\n",
    "       \n",
    "        scores = emission_scores\n",
    "        scores[:, 1:] += transition_scores\n",
    "        \n",
    "        if masks is not None:\n",
    "            scores = scores * masks.type_as(scores)\n",
    "\n",
    "        return scores.sum(-1)\n",
    "        \n",
    "    def _compute_normalizer(self, emissions, targets=None, masks=None, beam=None):\n",
    "\n",
    "        eps = 1e-8\n",
    "        \n",
    "        beam = beam if beam is not None else self.beam\n",
    "        batch_size, seq_len = emissions.size()[:2]\n",
    "        if targets is not None:\n",
    "            #_emissions = emissions.scatter(2, targets[:, :, None], np.float('inf'))\n",
    "            _emissions = emissions.scatter(2, targets[:, :, None], float('inf'))\n",
    "            beam_targets = _emissions.topk(beam, 2)[1]\n",
    "            beam_emission_scores = emissions.gather(2, beam_targets)\n",
    "        else:\n",
    "            beam_emission_scores, beam_targets = emissions.topk(beam, 2)\n",
    "        beam_transition_score1 = self.E1(beam_targets[:, :-1])  # B x (T-1) x K x D; position i - 1, previous step.\n",
    "        beam_transition_score2 = self.E2(beam_targets[:, 1:])   # B x (T-1) x K x D; position i, current step.\n",
    "        beam_transition_matrix = torch.bmm(\n",
    "            beam_transition_score1.view(-1, beam, self.rank),\n",
    "            beam_transition_score2.view(-1, beam, self.rank).transpose(1, 2))\n",
    "        beam_transition_matrix = beam_transition_matrix.view(batch_size, -1, beam, beam)\n",
    "\n",
    "        # compute the normalizer in the log-space\n",
    "        score = beam_emission_scores[:, 0]  # B x K\n",
    "        for i in range(1, seq_len):\n",
    "            next_score = score[:, :, None] + beam_transition_matrix[:, i-1]\n",
    "            next_score = logsumexp(next_score, dim=1) + beam_emission_scores[:, i]\n",
    "            if masks is not None:\n",
    "                score = torch.where(masks[:, i:i+1], next_score, score)\n",
    "            else:\n",
    "                score = next_score\n",
    "\n",
    "        return logsumexp(score, dim=1)\n",
    "\n",
    "    def _compute_top_probs(self, beam_emission_scores, beam_transition_matrix, targets=None, masks=None, beam=None):\n",
    "\n",
    "        eps = 1e-8\n",
    "        device = beam_emission_scores.device\n",
    "        \n",
    "        beam = beam if beam is not None else self.beam\n",
    "        batch_size, seq_len = beam_emission_scores.size()[:2]\n",
    "\n",
    "        traj_tokens, traj_scores = [], []\n",
    "        finalized_tokens, finalized_scores = [], []\n",
    "\n",
    "        # compute the normalizer in the log-space\n",
    "        score = beam_emission_scores[:, 0]  # B x K\n",
    "        \n",
    "        for i in range(1, seq_len):\n",
    "            traj_scores.append(score)\n",
    "            _score = score[:, :, None] + beam_transition_matrix[:, i-1] # bsz, beam, beam\n",
    "\n",
    "            # greedy selection\n",
    "            #_score, _index = _score.max(dim=1) # bsz, beam     bsz, beam \n",
    "\n",
    "            # multinomial selection\n",
    "            B, C, W = _score.shape\n",
    "            flat_score = _score.permute(0, 2, 1).reshape(-1, C)\n",
    "            probs = F.softmax(flat_score / self.temp, dim=-1)\n",
    "            _index_flat = torch.multinomial(probs, num_samples=1)\n",
    "            _score_flat = torch.gather(flat_score, -1, _index_flat)\n",
    "            _index = _index_flat.view(B, W)\n",
    "            _score = _score_flat.view(B, W)\n",
    "\n",
    "            _score = _score + beam_emission_scores[:, i] # bsz, beam\n",
    "            \n",
    "            #if masks is not None:\n",
    "            #    score = torch.where(masks[:, i: i+1], _score, score)\n",
    "            #    index = torch.where(masks[:, i: i+1], _index, dummy)\n",
    "            #else:\n",
    "            score, index = _score, _index\n",
    "            traj_tokens.append(index)\n",
    "        \n",
    "        all_scores = traj_scores\n",
    "        all_scores.append( score )\n",
    "        all_scores = torch.stack( all_scores, dim = 0 ).transpose( 0, 1 ).to(device)\n",
    "        #beam_probs = F.softmax( all_scores / self.temp, dim = 2 )\n",
    "        beam_probs = F.softmax( all_scores, dim = 2 )\n",
    "\n",
    "        # now running the back-tracing and find the best\n",
    "        best_score, best_index = score.max(dim=1)\n",
    "        finalized_tokens.append(best_index[:, None])\n",
    "        finalized_scores.append(best_score[:, None])\n",
    "\n",
    "        for idx, scs in zip(reversed(traj_tokens), reversed(traj_scores)):\n",
    "            previous_index = finalized_tokens[-1]\n",
    "            finalized_tokens.append(idx.gather(1, previous_index))\n",
    "            finalized_scores.append(scs.gather(1, previous_index))\n",
    "\n",
    "        finalized_tokens.reverse()\n",
    "        finalized_tokens = torch.cat(finalized_tokens, 1)\n",
    "        #finalized_tokens = beam_targets.gather(2, finalized_tokens[:, :, None])[:, :, 0]\n",
    "\n",
    "        finalized_scores.reverse()\n",
    "        finalized_scores = torch.cat(finalized_scores, 1)\n",
    "        finalized_scores[:, 1:] = finalized_scores[:, 1:] - finalized_scores[:, :-1]\n",
    "\n",
    "        return beam_probs, finalized_tokens.unsqueeze(-1)\n",
    "\n",
    "    def _compute_top_probs2(self, beam_emission_scores, beam_transition_matrix, beam_targets, n_best = 10, targets=None, masks=None, beam=None):\n",
    "\n",
    "        eps = 1e-8\n",
    "        device = beam_emission_scores.device\n",
    "        window = 5\n",
    "\n",
    "        exclude_token_id2 = torch.tensor( [pad_token_id, eos_token_id, a_token_id, the_token_id, and_token_id, in_token_id, \\\n",
    "            we_token_id, i_token_id, he_token_id, she_token_id, it_token_id, they_token_id, \\\n",
    "            period_token_id, comma_token_id, dbl_token_id, sgl_token_id], device=device )\n",
    "        \n",
    "        beam = beam if beam is not None else self.beam\n",
    "        batch_size, seq_len = beam_emission_scores.size()[:2]\n",
    "        bsz = batch_size\n",
    "        \n",
    "        traj_tokens, traj_scores = [], []\n",
    "        finalized_tokens, finalized_scores = [], []\n",
    "    \n",
    "        score = beam_emission_scores[:, 0]  # B x K\n",
    "        _score = beam_emission_scores[:, 0][:,None,:].expand(-1,beam,-1) # t = -1 → 0 への beam_transition_matrix bsz*beam C*beam W は　0 \n",
    "        #_score2, _index2 = torch.topk( _score, n_best, dim = 1 )\n",
    "        B, C, W = _score.shape\n",
    "        flat_score = _score.permute(0, 2, 1).reshape(-1, C)\n",
    "        probs = F.softmax(flat_score / self.temp, dim=-1)\n",
    "        _index_flat = torch.multinomial(probs, num_samples=n_best, replacement = False )\n",
    "        _score_flat = torch.gather(flat_score, -1, _index_flat)\n",
    "        _index2 = _index_flat.view(B, W, n_best).transpose(1,2)\n",
    "        _score2 = _score_flat.view(B, W, n_best).transpose(1,2)\n",
    "    \n",
    "        traj_scores2 = []\n",
    "        traj_tokens2 = []\n",
    "    \n",
    "        for i in range(1, seq_len):\n",
    "            traj_scores.append(score) # bsz * beam\n",
    "            traj_scores2.append( _score2 )\n",
    "            _score = score[:, :, None] + beam_transition_matrix[:, i-1] # bsz, beam, beam\n",
    "            \n",
    "            ## greedy selection\n",
    "            #_score, _index = _score.max(dim=1) # bsz, beam     bsz, beam \n",
    "            #_score2, _index2 = torch.topk( _score, n_best, dim = 1 )\n",
    "            \n",
    "            ## multinomial selection\n",
    "            B, C, W = _score.shape\n",
    "            flat_score = _score.permute(0, 2, 1).reshape(-1, C)\n",
    "            #print( \"flat_score size:\", flat_score.size() )\n",
    "            #probs = F.softmax(flat_score / self.temp, dim=-1)\n",
    "            probs = F.softmax(flat_score / self.temp, dim=-1)\n",
    "            _index_flat = torch.multinomial(probs, num_samples=n_best, replacement = False )  # C が n_best になる。\n",
    "            _score_flat = torch.gather(flat_score, -1, _index_flat)\n",
    "            _index2 = _index_flat.view(B, W, n_best).transpose(1,2)\n",
    "            _score2 = _score_flat.view(B, W, n_best).transpose(1,2)\n",
    "            \n",
    "            #_score = _score + beam_emission_scores[:, i] # bsz, beam        \n",
    "    \n",
    "            _score2 = _score2 + beam_emission_scores[:, i][:,None,:].expand(-1,beam,-1).gather( 1, _index2 ) # bsz, n_best, beam       \n",
    "            \n",
    "            #if masks is not None:\n",
    "            #    score = torch.where(masks[:, i: i+1], _score, score)\n",
    "            #    index = torch.where(masks[:, i: i+1], _index, dummy)\n",
    "            #else:\n",
    "            score, index = _score2[:,0,:], _index2[:,0,:]\n",
    "            traj_tokens.append(index)\n",
    "            traj_tokens2.append( _index2 )\n",
    "\n",
    "        # now running the back-tracing and find the best\n",
    "        best_score, best_index = score.max(dim=1)\n",
    "        finalized_tokens.append(best_index[:, None])\n",
    "        finalized_scores.append(best_score[:, None])\n",
    "\n",
    "        used_index = torch.zeros( bsz, seq_len, dtype=torch.long, device=device)\n",
    "        used_index[:,seq_len - 1] = best_index\n",
    "        beam_probs = torch.zeros( bsz, seq_len, beam, dtype=torch.float, device=device )\n",
    "        beam_probs[:,seq_len - 1,:] = score \n",
    "        for t_reverse, (idx2, scs2) in enumerate( zip( reversed(traj_tokens2), reversed(traj_scores2))):\n",
    "            t = seq_len - t_reverse - 2\n",
    "            previous_index = finalized_tokens[-1]\n",
    "            #print( \"previous_index size:\", previous_index.size() )\n",
    "            selected_idx = idx2[:,0,:].gather( 1, previous_index )\n",
    "            selected_scs = scs2[:,0,:].gather( 1, previous_index )\n",
    "            beam_probs[ :, t ,: ] = scs2[:,0,: ]\n",
    "            for n in range( 1, n_best ):\n",
    "                for b in range( bsz ):\n",
    "                    t_max = torch.min( t + window, seq_len - 1 )\n",
    "                    used_index_tmp = used_index[b,t+1:t_max]\n",
    "                    corrected_selected_idx = torch.gather( beam_targets[b,t,:], 0, selected_idx[b] )\n",
    "                    #if corrected_selected_idx in used_index[b] and corrected_selected_idx not in exclude_token_id2:\n",
    "                    if corrected_selected_idx in used_index_tmp and corrected_selected_idx not in exclude_token_id2:\n",
    "                        selected_idx[b] = idx2[b,n,:].gather( 0, previous_index[b] )\n",
    "                        selected_scs[b] = scs2[b,n,:].gather( 0, previous_index[b] )\n",
    "                        beam_probs[ b, t ,: ] = scs2[b, n,: ]\n",
    "                    else:\n",
    "                        break\n",
    "            #print( \"beam_targets[:,t,:].size():\",beam_targets[:,t,:].size())\n",
    "            #print( \"selected_idx.size():\", selected_idx.size() )\n",
    "            used_index[:,t] =  torch.gather( beam_targets[:,t,:], -1, selected_idx )[:,0] # bsz * 1 → bsz\n",
    "            #print( \"used_index[:,:]:\", used_index[:,:] )\n",
    "            #used_index[:,t] = selected_idx[:,0]\n",
    "            finalized_tokens.append( selected_idx )\n",
    "            finalized_scores.append( selected_scs )\n",
    "       \n",
    "        finalized_tokens.reverse()\n",
    "        sampled_beam_idx = torch.cat(finalized_tokens, 1)\n",
    "        #finalized_tokens = beam_targets.gather(2, sampled_beam_idx[:, :, None])[:, :, 0]\n",
    "        #print( \"finalized_tokens:\", finalized_tokens )\n",
    "        \n",
    "        finalized_scores.reverse()\n",
    "        finalized_scores = torch.cat(finalized_scores, 1)\n",
    "        finalized_scores[:, 1:] = finalized_scores[:, 1:] - finalized_scores[:, :-1]\n",
    "\n",
    "        beam_probs = F.softmax( beam_probs, dim = 2 )\n",
    "        \n",
    "        #return finalized_scores, finalized_tokens\n",
    "        return beam_probs, sampled_beam_idx.unsqueeze(-1)\n",
    "\n",
    "    def _compute_viterbi_no_repeat(self, beam_emission_scores, beam_transition_matrix, beam_targets, n_best = 10, targets=None, masks=None, beam=None):\n",
    "\n",
    "        eps = 1e-8\n",
    "        device = beam_emission_scores.device\n",
    "        exclude_token_id2 = torch.tensor( [pad_token_id, eos_token_id, a_token_id, the_token_id, and_token_id, in_token_id, \\\n",
    "            we_token_id, i_token_id, he_token_id, she_token_id, it_token_id, they_token_id, \\\n",
    "            period_token_id, comma_token_id, dbl_token_id, sgl_token_id], device=device )\n",
    "        window = 5\n",
    "        \n",
    "        beam = beam if beam is not None else self.beam\n",
    "        batch_size, seq_len = beam_emission_scores.size()[:2]\n",
    "        bsz = batch_size\n",
    "        \n",
    "        traj_tokens, traj_scores = [], []\n",
    "        finalized_tokens, finalized_scores = [], []\n",
    "    \n",
    "        score = beam_emission_scores[:, 0]  # B x K\n",
    "        _score = beam_emission_scores[:, 0][:,None,:].expand(-1,beam,-1) # t = -1 → 0 への beam_transition_matrix bsz*beam C*beam W は　0 \n",
    "        _score2, _index2 = torch.topk( _score, n_best, dim = 1 )\n",
    "        #B, C, W = _score.shape\n",
    "        #flat_score = _score.permute(0, 2, 1).reshape(-1, C)\n",
    "        #probs = F.softmax(flat_score / self.temp, dim=-1)\n",
    "        #_index_flat = torch.multinomial(probs, num_samples=n_best, replacement = False )\n",
    "        #_score_flat = torch.gather(flat_score, -1, _index_flat)\n",
    "        #_index2 = _index_flat.view(B, W, n_best).transpose(1,2)\n",
    "        #_score2 = _score_flat.view(B, W, n_best).transpose(1,2)\n",
    "    \n",
    "        traj_scores2 = []\n",
    "        traj_tokens2 = []\n",
    "    \n",
    "        for i in range(1, seq_len):\n",
    "            traj_scores.append(score) # bsz * beam\n",
    "            traj_scores2.append( _score2 )\n",
    "            _score = score[:, :, None] + beam_transition_matrix[:, i-1] # bsz, beam, beam\n",
    "            \n",
    "            ## greedy selection\n",
    "            #_score, _index = _score.max(dim=1) # bsz, beam     bsz, beam \n",
    "            _score2, _index2 = torch.topk( _score, n_best, dim = 1 )\n",
    "            \n",
    "            ### multinomial selection\n",
    "            #B, C, W = _score.shape\n",
    "            #flat_score = _score.permute(0, 2, 1).reshape(-1, C)\n",
    "            ##print( \"flat_score size:\", flat_score.size() )\n",
    "            ##probs = F.softmax(flat_score / self.temp, dim=-1)\n",
    "            #probs = F.softmax(flat_score / self.temp, dim=-1)\n",
    "            #_index_flat = torch.multinomial(probs, num_samples=n_best, replacement = False )  # C が n_best になる。\n",
    "            #_score_flat = torch.gather(flat_score, -1, _index_flat)\n",
    "            #_index2 = _index_flat.view(B, W, n_best).transpose(1,2)\n",
    "            #_score2 = _score_flat.view(B, W, n_best).transpose(1,2)\n",
    "            \n",
    "            #_score = _score + beam_emission_scores[:, i] # bsz, beam        \n",
    "    \n",
    "            _score2 = _score2 + beam_emission_scores[:, i][:,None,:].expand(-1,beam,-1).gather( 1, _index2 ) # bsz, n_best, beam       \n",
    "            \n",
    "            #if masks is not None:\n",
    "            #    score = torch.where(masks[:, i: i+1], _score, score)\n",
    "            #    index = torch.where(masks[:, i: i+1], _index, dummy)\n",
    "            #else:\n",
    "            score, index = _score2[:,0,:], _index2[:,0,:]\n",
    "            traj_tokens.append(index)\n",
    "            traj_tokens2.append( _index2 )\n",
    "\n",
    "        # now running the back-tracing and find the best\n",
    "        best_score, best_index = score.max(dim=1)\n",
    "        finalized_tokens.append(best_index[:, None])\n",
    "        finalized_scores.append(best_score[:, None])\n",
    "\n",
    "        used_index = torch.zeros( bsz, seq_len, dtype=torch.long, device=device )\n",
    "        used_index[:,seq_len - 1] = best_index\n",
    "        beam_probs = torch.zeros( bsz, seq_len, beam, dtype=torch.float, device=device )\n",
    "        beam_probs[:,seq_len - 1,:] = score \n",
    "        for t_reverse, (idx2, scs2) in enumerate( zip( reversed(traj_tokens2), reversed(traj_scores2))):\n",
    "            t = seq_len - t_reverse - 2\n",
    "            previous_index = finalized_tokens[-1]\n",
    "            #print( \"previous_index size:\", previous_index.size() )\n",
    "            selected_idx = idx2[:,0,:].gather( 1, previous_index )\n",
    "            selected_scs = scs2[:,0,:].gather( 1, previous_index )\n",
    "            beam_probs[ :, t ,: ] = scs2[:,0,: ]\n",
    "            for n in range( 1, n_best ):\n",
    "                for b in range( bsz ):\n",
    "                    t_max = torch.min( t + window, seq_len - 1 )\n",
    "                    used_index_tmp = used_index[b,t+1:t_max]\n",
    "                    corrected_selected_idx = torch.gather( beam_targets[b,t,:], 0, selected_idx[b] )\n",
    "                    #if corrected_selected_idx in used_index[b] and corrected_selected_idx not in exclude_token_id2:\n",
    "                    if corrected_selected_idx in used_index_tmp and corrected_selected_idx not in exclude_token_id2:\n",
    "                        selected_idx[b] = idx2[b,n,:].gather( 0, previous_index[b] )\n",
    "                        selected_scs[b] = scs2[b,n,:].gather( 0, previous_index[b] )\n",
    "                        beam_probs[ b, t ,: ] = scs2[b, n,: ]\n",
    "                    else:\n",
    "                        break\n",
    "            #print( \"beam_targets[:,t,:].size():\",beam_targets[:,t,:].size())\n",
    "            #print( \"selected_idx.size():\", selected_idx.size() )\n",
    "            used_index[:,t] =  torch.gather( beam_targets[:,t,:], -1, selected_idx )[:,0] # bsz * 1 → bsz\n",
    "            #print( \"used_index[:,:]:\", used_index[:,:] )\n",
    "            #used_index[:,t] = selected_idx[:,0]\n",
    "            finalized_tokens.append( selected_idx )\n",
    "            finalized_scores.append( selected_scs )\n",
    "       \n",
    "        finalized_tokens.reverse()\n",
    "        sampled_beam_idx = torch.cat(finalized_tokens, 1)\n",
    "        finalized_tokens = beam_targets.gather(2, sampled_beam_idx[:, :, None])[:, :, 0]\n",
    "        #print( \"finalized_tokens:\", finalized_tokens )\n",
    "        \n",
    "        finalized_scores.reverse()\n",
    "        finalized_scores = torch.cat(finalized_scores, 1)\n",
    "        finalized_scores[:, 1:] = finalized_scores[:, 1:] - finalized_scores[:, :-1]\n",
    "\n",
    "        #beam_probs = F.softmax( beam_probs, dim = 2 )\n",
    "        \n",
    "        return finalized_scores, finalized_tokens\n",
    "    \n",
    "    \n",
    "    def _compute_f_algorithm(self, emissions, temp = 1.0, targets=None, beam=None):\n",
    "\n",
    "        eps = 1e-8\n",
    "        beam = beam if beam is not None else self.beam\n",
    "        batch_size, seq_len = emissions.size()[:2]\n",
    "        bsz = batch_size\n",
    "        \n",
    "        beam_emission_scores, beam_targets = emissions.topk(beam, 2)\n",
    "   \n",
    "        # 結果格納用\n",
    "        scores = torch.zeros((batch_size, seq_len, beam), device=emissions.device)\n",
    "        all_preds = []\n",
    "        sampled_beam_idx = []\n",
    "        \n",
    "        # --- ステップ 0 ---\n",
    "        scores[:, 0, :] = beam_emission_scores[:, 0]\n",
    "        probs_0 = F.softmax(scores[:, 0, :] / temp, dim=-1)\n",
    "        sampled_beam_idx_0 = torch.multinomial(probs_0, 1)\n",
    "\n",
    "        # 256個中の位置から、実際のVocab IDに変換\n",
    "        all_preds.append(  torch.gather(beam_targets[:, 0], 1, sampled_beam_idx_0).squeeze(1) )\n",
    "        sampled_beam_idx.append( sampled_beam_idx_0 )\n",
    "        \n",
    "        # --- ステップ 1 以降 ---\n",
    "        for i in range(1, seq_len):\n",
    "            # 1. 直前に自分が選んだ単語(Vocab ID)を取得\n",
    "            prev_vocab_idx = all_preds[-1]\n",
    "            \n",
    "            # 2. 遷移スコアの計算\n",
    "            prev_trans_feat = self.E1(prev_vocab_idx) # B x D\n",
    "            curr_trans_feat = self.E2(beam_targets[:, i]) # B x beam x D\n",
    "        \n",
    "            # B x 1 x D  @  B x D x beam  -> B x 1 x beam\n",
    "            #D = prev_trans_feat.size(-1) # 次元のサイズ\n",
    "            #current_trans_scores = torch.bmm(\n",
    "            #    prev_trans_feat.unsqueeze(1), \n",
    "            #    curr_trans_feat.transpose(1, 2)\n",
    "            #).squeeze(1) / (D ** 0.5) \n",
    "            current_trans_scores = torch.bmm(\n",
    "                prev_trans_feat.unsqueeze(1), \n",
    "                curr_trans_feat.transpose(1, 2)\n",
    "            ).squeeze(1)\n",
    "\n",
    "            # 3. 現在のスコアを確定\n",
    "            scores[:, i, :] = beam_emission_scores[:, i] + current_trans_scores\n",
    "        \n",
    "            # 4. 次のステップのために、現在の単語をサンプリング（正規化が必要）\n",
    "            probs_i = F.softmax(scores[:, i, :] / temp , dim=-1)\n",
    "            sampled_beam_idx_i = torch.multinomial(probs_i, 1).long()\n",
    "            all_preds.append( torch.gather(beam_targets[:, i], 1, sampled_beam_idx_i).squeeze(1) )\n",
    "            sampled_beam_idx.append( sampled_beam_idx_i )\n",
    "                              \n",
    "\n",
    "        all_preds = torch.stack( all_preds, dim = 0 ).transpose(0,1)\n",
    "        sampled_beam_idx = torch.stack( sampled_beam_idx, dim = 0 ).transpose(0,1)\n",
    "        \n",
    "        ## --- 全体の log_probs 算出（ratio計算用） ---\n",
    "        #max_score, _ = torch.max(scores, dim=2, keepdim=True)\n",
    "        #exp1 = torch.exp(scores - max_score)\n",
    "        #sumof = torch.sum(exp1, dim=2, keepdim=True)\n",
    "        #denominator1 = torch.log(sumof + 1e-8) + max_score\n",
    "    \n",
    "        #beam_log_probs = scores - denominator1\n",
    "        ##sample_log_probs = torch.gather( beam_log_probs, -1, sampled_beam_idx ).squeeze(-1)\n",
    "        #beam_probs = torch.exp(beam_log_probs)\n",
    "\n",
    "        #return beam_probs, preds, sample_log_probs, sampled_beam_idx\n",
    "        return scores, all_preds\n",
    "\n",
    "    def _viterbi_decode(self, emissions, masks=None, beam=None):\n",
    "        beam = beam if beam is not None else self.beam\n",
    "        batch_size, seq_len = emissions.size()[:2]\n",
    "        beam_emission_scores, beam_targets = emissions.topk(beam, 2)\n",
    "        beam_transition_score1 = self.E1(beam_targets[:, :-1])  # B x (T-1) x K x D\n",
    "        beam_transition_score2 = self.E2(beam_targets[:, 1:])   # B x (T-1) x K x D\n",
    "        beam_transition_matrix = torch.bmm(\n",
    "            beam_transition_score1.view(-1, beam, self.rank),\n",
    "            beam_transition_score2.view(-1, beam, self.rank).transpose(1, 2))\n",
    "        beam_transition_matrix = beam_transition_matrix.view(batch_size, -1, beam, beam) # bsz, seq_len, beam, beam\n",
    "\n",
    "        traj_tokens, traj_scores = [], []\n",
    "        finalized_tokens, finalized_scores = [], []\n",
    "\n",
    "        # compute the normalizer in the log-space\n",
    "        score = beam_emission_scores[:, 0]  # B x K\n",
    "        #print( \"score size:\", score.size() )\n",
    "        dummy = torch.arange(beam, device=score.device).expand(*score.size()).contiguous()\n",
    "\n",
    "        for i in range(1, seq_len):\n",
    "            traj_scores.append(score)\n",
    "            _score = score[:, :, None] + beam_transition_matrix[:, i-1] # bsz, beam, beam\n",
    "            _score, _index = _score.max(dim=1) # bsz, beam     bsz, beam \n",
    "            _score = _score + beam_emission_scores[:, i] # bsz, beam\n",
    "\n",
    "            if masks is not None:\n",
    "                score = torch.where(masks[:, i: i+1], _score, score)\n",
    "                index = torch.where(masks[:, i: i+1], _index, dummy)\n",
    "            else:\n",
    "                score, index = _score, _index\n",
    "            traj_tokens.append(index)\n",
    "\n",
    "        # now running the back-tracing and find the best\n",
    "        best_score, best_index = score.max(dim=1)\n",
    "        finalized_tokens.append(best_index[:, None])\n",
    "        finalized_scores.append(best_score[:, None])\n",
    "\n",
    "        for idx, scs in zip(reversed(traj_tokens), reversed(traj_scores)):\n",
    "            previous_index = finalized_tokens[-1]\n",
    "            finalized_tokens.append(idx.gather(1, previous_index))\n",
    "            finalized_scores.append(scs.gather(1, previous_index))\n",
    "\n",
    "        finalized_tokens.reverse()\n",
    "        finalized_tokens = torch.cat(finalized_tokens, 1)\n",
    "        finalized_tokens = beam_targets.gather(2, finalized_tokens[:, :, None])[:, :, 0]\n",
    "\n",
    "        finalized_scores.reverse()\n",
    "        finalized_scores = torch.cat(finalized_scores, 1)\n",
    "        finalized_scores[:, 1:] = finalized_scores[:, 1:] - finalized_scores[:, :-1]\n",
    "\n",
    "        return finalized_scores, finalized_tokens\n",
    "    \n",
    "    def _compute_many_values(self, emissions, targets, top_indices = None, masks=None, beam=None):\n",
    "\n",
    "        beam = beam if beam is not None else self.beam\n",
    "        batch_size, seq_len = emissions.size()[:2]\n",
    "        \n",
    "        if top_indices == None:\n",
    "            beam_emission_scores, beam_targets = emissions.topk(beam, 2)\n",
    "        else:\n",
    "            beam_emission_scores = torch.gather( emissions, -1, top_indices )\n",
    "            beam_targets = top_indices\n",
    "        \n",
    "        beam_transition_score1 = self.E1(beam_targets[:, :-1])  # B x (T-1) x K x D\n",
    "        beam_transition_score2 = self.E2(beam_targets[:, 1:])   # B x (T-1) x K x D\n",
    "        beam_transition_matrix = torch.bmm(\n",
    "            beam_transition_score1.view(-1, beam, self.rank),\n",
    "            beam_transition_score2.view(-1, beam, self.rank).transpose(1, 2))\n",
    "        beam_transition_matrix = beam_transition_matrix.view(batch_size, -1, beam, beam) # bsz, seq_len, beam, beam\n",
    "\n",
    "        traj_tokens, traj_scores = [], []\n",
    "        finalized_tokens, finalized_scores = [], []\n",
    "\n",
    "        # compute the normalizer in the log-space\n",
    "        score = beam_emission_scores[:, 0]  # B x K\n",
    "        dummy = torch.arange(beam, device=score.device).expand(*score.size()).contiguous()\n",
    "\n",
    "        for i in range(1, seq_len):\n",
    "            traj_scores.append(score)\n",
    "            _score = score[:, :, None] + beam_transition_matrix[:, i-1] # bsz, beam, beam\n",
    "            _score, _index = _score.max(dim=1) # bsz, beam     bsz, beam  step i-1 における 256 → 256 の max から 256 への遷移確率と \n",
    "                                                # 256 → 256 の前の 256 の max のインデックストークン\n",
    "                                                # index b * 256 の 位置が i の token で、値が i-1 のtoken   \n",
    "\n",
    "            _score = _score + beam_emission_scores[:, i] # bsz, beam i における 256 の遷移確率ではない確率を加える。i における 256 の全確率。\n",
    "\n",
    "            if masks is not None:\n",
    "                score = torch.where(masks[:, i: i+1], _score, score)\n",
    "                index = torch.where(masks[:, i: i+1], _index, dummy)\n",
    "            else:\n",
    "                score, index = _score, _index\n",
    "            traj_tokens.append(index)\n",
    "\n",
    "        all_scores = traj_scores\n",
    "        all_scores.append( score )\n",
    "        all_scores = torch.stack( all_scores, dim = 0 ).transpose( 0, 1 )\n",
    "        \n",
    "        # now running the back-tracing and find the best\n",
    "        best_score, best_index = score.max(dim=1)\n",
    "        finalized_tokens.append(best_index[:, None]) # 時刻 T における b*256 の確率最大の token\n",
    "        finalized_scores.append(best_score[:, None]) #時刻 T における b*256 の確率最大の score\n",
    "\n",
    "        for idx, scs in zip(reversed(traj_tokens), reversed(traj_scores)): #idx,scs は、反転時刻 i と i-1における b * 256のトークンと確率\n",
    "            previous_index = finalized_tokens[-1] # 時刻 Tなど 求めたいトークンと確率の一個後 における token　b * 1\n",
    "            finalized_tokens.append(idx.gather(1, previous_index)) # 時刻 一個後iのトークン previou_index に至るための時刻i-1 のトークン\n",
    "                                                                    # b* 256 の token から b * 1 の previous_idnex token で gather\n",
    "            finalized_scores.append(scs.gather(1, previous_index)) # 時刻一個後 i のトークンに至るための時刻 i-1 の確率\n",
    "\n",
    "        finalized_tokens.reverse()\n",
    "        finalized_tokens = torch.cat(finalized_tokens, 1)\n",
    "        finalized_tokens = beam_targets.gather(2, finalized_tokens[:, :, None])[:, :, 0]\n",
    "\n",
    "        finalized_scores.reverse()\n",
    "        finalized_scores = torch.cat(finalized_scores, 1)\n",
    "        finalized_scores[:, 1:] = finalized_scores[:, 1:] - finalized_scores[:, :-1]\n",
    "        \n",
    "        if self.crf_coef != 0.0:\n",
    "            numerator = self._compute_score(emissions, targets)\n",
    "            denominator = self._compute_normalizer(emissions, targets)\n",
    "            crf_loss = - ( numerator - denominator ).mean() / seq_len\n",
    "        else:\n",
    "            crf_loss = torch.zeros( (1), device = emissions.device, dtype = torch.float )\n",
    "        \n",
    "        top_probs, sampled_beam_idx = self._compute_top_probs(beam_emission_scores, beam_transition_matrix)\n",
    "        \n",
    "        return finalized_scores, finalized_tokens, top_probs, beam_targets, crf_loss, sampled_beam_idx\n",
    "    '''\n",
    "    \n",
    "    def _compute_many_values(self, emissions, targets, top_indices = None, masks=None, beam=None):\n",
    "\n",
    "        beam = beam if beam is not None else self.beam\n",
    "        batch_size, seq_len = emissions.size()[:2]\n",
    "        \n",
    "        if top_indices == None:\n",
    "            beam_emission_scores, beam_targets = emissions.topk(beam, 2)\n",
    "        else:\n",
    "            beam_emission_scores = torch.gather( emissions, -1, top_indices )\n",
    "            beam_targets = top_indices\n",
    "        \n",
    "        beam_transition_score1 = self.E1(beam_targets[:, :-1])  # B x (T-1) x K x D\n",
    "        beam_transition_score2 = self.E2(beam_targets[:, 1:])   # B x (T-1) x K x D\n",
    "        beam_transition_matrix = torch.bmm(\n",
    "            beam_transition_score1.view(-1, beam, self.rank),\n",
    "            beam_transition_score2.view(-1, beam, self.rank).transpose(1, 2))\n",
    "        beam_transition_matrix = beam_transition_matrix.view(batch_size, -1, beam, beam) # bsz, seq_len, beam, beam\n",
    "        \n",
    "        if self.crf_coef != 0.0:\n",
    "            numerator = self._compute_score(emissions, targets)\n",
    "            denominator = self._compute_normalizer(emissions, targets)\n",
    "            #denominator = self._compute_normalizer2(emissions, targets)\n",
    "            crf_loss = - ( numerator - denominator ).mean() / seq_len\n",
    "        else:\n",
    "            crf_loss = torch.zeros( (1), device = emissions.device, dtype = torch.float )\n",
    "\n",
    "        finalized_scores, finalized_tokens = self._compute_viterbi_no_repeat(beam_emission_scores, beam_transition_matrix, beam_targets)\n",
    "        top_probs, sampled_beam_idx = self._compute_top_probs2(beam_emission_scores, beam_transition_matrix, beam_targets)\n",
    "        \n",
    "        return finalized_scores, finalized_tokens, top_probs, beam_targets, crf_loss, sampled_beam_idx\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopLayer(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, crf_low_rank, crf_beam_size, dropout, padding_idx,\n",
    "                crf_coef = 1.0, temp = 0.5 ):\n",
    "        super(TopLayer, self).__init__()\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dropout = dropout\n",
    "        self.padding_idx = padding_idx\n",
    "        print( \"in TopLayer:\" )\n",
    "        self.crf_layer = DynamicCRF(num_embedding = vocab_size, low_rank = crf_low_rank, \n",
    "                                    beam_size = crf_beam_size, crf_coef=crf_coef, temp=temp)\n",
    "\n",
    "        #self.one_more_layer_norm = nn.LayerNorm(embed_dim)\n",
    "        #self.tgt_word_prj = nn.Linear(self.embed_dim, self.vocab_size)\n",
    "        ## gae 学習用\n",
    "        #self.linear_critical = nn.Linear(crf_beam_size, 1 )\n",
    "\n",
    "    def forward(self, src_representation, top_logits, top_indices, src_input, tgt_input, is_training ):\n",
    "        '''\n",
    "            src_representation : bsz x seqlen x embed_dim\n",
    "            src_input : bsz x seqlen\n",
    "            tgt_input : bsz x seqlen\n",
    "        '''\n",
    "        #assert src_input.size() == tgt_input.size()\n",
    "\n",
    "        src_input = src_input.transpose(0, 1) # src_len x bsz\n",
    "        #seqlen, bsz = src_input.size()\n",
    "        seqlen, bsz = src_input.shape[:2]\n",
    "\n",
    "        src_representation = F.dropout(src_representation, p=self.dropout, training=is_training)\n",
    "        src_representation = src_representation.transpose(0, 1) # seqlen x bsz x embed_dim\n",
    "\n",
    "        src = src_representation\n",
    "\n",
    "        #emissions = self.tgt_word_prj(src.contiguous().view(-1, self.embed_dim)).view(seqlen, bsz, self.vocab_size)\n",
    "        emissions = src_representation\n",
    "        #log_probs = torch.log_softmax(emissions, -1)\n",
    "        #assert log_probs.size() == torch.Size([seqlen, bsz, self.vocab_size])\n",
    "\n",
    "        emissions = emissions.transpose(0, 1) # [bsz x src_len x vocab_size]\n",
    "        #emission_mask = ~tgt_input.eq(self.padding_idx) # [bsz x src_len] #pad のところは 0 padでないところが 1\n",
    "        emission_mask = torch.ones_like( tgt_input, dtype=torch.bool ) #全部　pad でないとして 1\n",
    "        batch_crf_loss, top_probs = self.crf_layer(emissions, top_logits, top_indices, tgt_input, emission_mask) # [bsz]\n",
    "        #critical_value = self.linear_critical( top_probs )\n",
    "        #critical_value = torch.zeros( ( 1,1,1) )\n",
    "        batch_crf_loss = - batch_crf_loss\n",
    "        assert batch_crf_loss.size() == torch.Size([bsz])\n",
    "        return batch_crf_loss, top_probs\n",
    "\n",
    "    def decoding(self, src_representation, src_input):\n",
    "        '''\n",
    "            src_representation : bsz x seqlen x embed_dim\n",
    "            src_input : bsz x seqlen\n",
    "            tgt_input : bsz x seqlen\n",
    "        '''\n",
    "        src_input = src_input.transpose(0, 1) # src_len x bsz\n",
    "        seqlen, bsz = src_input.size()\n",
    "\n",
    "        src_representation = src_representation.transpose(0, 1) # seqlen x bsz x embed_dim\n",
    "        src = src_representation\n",
    "\n",
    "        emissions = self.tgt_word_prj(src.contiguous().view(-1, self.embed_dim)).view(seqlen, bsz, self.vocab_size)\n",
    "\n",
    "        emissions = emissions.transpose(0, 1) # [bsz, seqlen, vocab_size]\n",
    "        _, finalized_tokens = self.crf_layer.forward_decoder(emissions)\n",
    "        assert finalized_tokens.size() == torch.Size([bsz, seqlen])\n",
    "        return finalized_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaptioningTransformer(nn.Module):\n",
    "    \n",
    "    #CaptioningTransformerのコンストラクタ\n",
    "    #dim_embedding  : 埋め込み次元\n",
    "    #dim_feedforward: FNNの中間特徴次元\n",
    "    #num_heads      : マルチヘッドアテンションのヘッド数\n",
    "    #num_layers     : Transformerデコーダ層の数\n",
    "    #vocab_size     : 辞書の次元\n",
    "    #null_index     : NULLのID\n",
    "    #dropout        : ドロップアウト確率\n",
    "    \n",
    "    def __init__(self, img_size: int,  dim_embedding: int, length_max: int, vocab_size: int, tokenizer, dropout: float = 0.0, \\\n",
    "                 pad_token_id: int=0, use_repeat_logits_half=False, crf_coef = 1.0, temp=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        #CLIP\n",
    "        model_id = \"openai/clip-vit-large-patch14-336\"\n",
    "        self.clip_model = CLIPVisionModel.from_pretrained(model_id )\n",
    "        memory = self.clip_model( torch.randn( 1, 3, 336, 336 ) )\n",
    "        memory = memory.last_hidden_state\n",
    "        img_length = memory.size(1)\n",
    "        clip_dim = memory.size(2)\n",
    "        self.connector_pool = nn.AdaptiveAvgPool1d(length_max - 1 )\n",
    "        self.connector_ln = nn.LayerNorm( clip_dim )\n",
    "        self.connector_linear1 = nn.Linear( clip_dim, dim_embedding )\n",
    "        self.connector_gleu = nn.GELU()\n",
    "        self.connector_linear2 = nn.Linear( dim_embedding, dim_embedding )\n",
    "\n",
    "       \n",
    "        # Connector\n",
    "        self.connector_pool = nn.AdaptiveAvgPool1d(length_max - 1 )\n",
    "       # Down Sampling\n",
    "        cls_token = memory[:, :1, :] # (bsz, 1, 1024)\n",
    "        patch_tokens = memory[:, 1:, :] # (bsz, 576, 1024)\n",
    "        # パッチ部分を 576 -> 96 に圧縮\n",
    "        patch_tokens = patch_tokens.transpose(1, 2) # (bsz, 1024, 576)\n",
    "        patch_tokens = self.connector_pool(patch_tokens)\n",
    "        patch_tokens = patch_tokens.transpose(1, 2) # (bsz, 96, 1024)\n",
    "        # CLSと結合して合計 97 トークンにする\n",
    "        memory = torch.cat([cls_token, patch_tokens], dim=1) # (bsz, 97, 1024)\n",
    "\n",
    "        self.pos_emb = PositionalEmbedding( dim_embedding )\n",
    "\n",
    "        model_id = \"google-bert/bert-large-uncased\"\n",
    "        self.bert = BertModel.from_pretrained( model_id )\n",
    "\n",
    "        ## 単語出力分布計算\n",
    "        self.ln_outputs = nn.LayerNorm( dim_embedding )\n",
    "        self.linear = nn.Linear(dim_embedding, vocab_size)\n",
    "\n",
    "        crf_low_rank = 32\n",
    "        crf_beam_size = 256\n",
    "        self.crf_beam_size = crf_beam_size\n",
    "        top_dropout = 0.0\n",
    "        tgt_padding_idx = tokenizer.pad_token_id\n",
    "        self.toplayer = TopLayer( vocab_size, dim_embedding, crf_low_rank, crf_beam_size, top_dropout, \n",
    "                                  tgt_padding_idx, crf_coef = crf_coef, temp=temp )\n",
    "        \n",
    "        ### GAE 用\n",
    "        self.ln_critical = nn.LayerNorm( crf_beam_size )\n",
    "        self.linear_critical = nn.Linear( crf_beam_size, 1)\n",
    "        \n",
    "        self.dim_embedding = dim_embedding\n",
    "        self.use_repeat_logits_half = use_repeat_logits_half\n",
    "\n",
    "\n",
    "    def mlp_connector(self, memory ):\n",
    "\n",
    "        cls_token = memory[:, :1, :] # (bsz, 1, 1024)\n",
    "        patch_tokens = memory[:, 1:, :] # (bsz, 576, 1024)\n",
    "\n",
    "        # パッチ部分を 576 -> 96 に圧縮\n",
    "        patch_tokens = patch_tokens.transpose(1, 2) # (bsz, 1024, 576)\n",
    "        patch_tokens = self.connector_pool(patch_tokens)\n",
    "        patch_tokens = patch_tokens.transpose(1, 2) # (bsz, 96, 1024)\n",
    "\n",
    "        # CLSと結合して合計 97 トークンにする\n",
    "        memory = torch.cat([cls_token, patch_tokens], dim=1) # (bsz, 97, 1024)\n",
    "\n",
    "        memory = self.connector_ln( memory )\n",
    "        memory = self.connector_linear1( memory )\n",
    "        memory = self.connector_gleu( memory )\n",
    "        memory = self.connector_linear2( memory )\n",
    "        \n",
    "        return memory\n",
    "\n",
    "    def forward(self, images: torch.Tensor, targets: torch.Tensor, top_indices = None ):\n",
    "\n",
    "        self.device = images.device\n",
    "        \n",
    "        memory = self.clip_model( images ).last_hidden_state\n",
    "        memory = self.mlp_connector( memory )\n",
    "        memory += self.pos_emb( memory )\n",
    "        \n",
    "        outputs = self.bert( inputs_embeds = memory ).last_hidden_state\n",
    "        outputs = self.ln_outputs( outputs )\n",
    "        emissions = self.linear( outputs )\n",
    "\n",
    "        if self.use_repeat_logits_half == True:\n",
    "            emissions = repeat_logits_half( emissions )\n",
    "\n",
    "\n",
    "        finalized_scores, finalized_tokens, top_probs, top_indices, crf_loss, sampled_beam_idx  = \\\n",
    "            self.toplayer.crf_layer._compute_many_values(emissions, targets, top_indices)\n",
    "            #self.crf_layer._compute_many_values(emissions, targets, top_indices)\n",
    "        \n",
    "        critical_value = self.ln_critical( top_probs )\n",
    "        critical_value = self.linear_critical( critical_value )\n",
    "\n",
    "        return finalized_scores, finalized_tokens, top_probs, top_indices, \\\n",
    "            critical_value[:,:,0], crf_loss, emissions, sampled_beam_idx\n",
    "        #return finalized_scores, finalized_tokens, top_probs, top_indices, crf_loss, emissions\n",
    "\n",
    "    def inference(self, images: torch.Tensor, inf_t = 'v' ):\n",
    "\n",
    "        self.device = images.device\n",
    "        \n",
    "        memory = self.clip_model( images ).last_hidden_state\n",
    "        memory = self.mlp_connector( memory )\n",
    "        memory += self.pos_emb( memory )\n",
    "        \n",
    "        outputs = self.bert( inputs_embeds = memory ).last_hidden_state\n",
    "        outputs = self.ln_outputs( outputs )\n",
    "        emissions = self.linear( outputs )\n",
    "\n",
    "        if self.use_repeat_logits_half == True:\n",
    "            emissions = repeat_logits_half( emissions )\n",
    "\n",
    "        if inf_t == 'v':\n",
    "            finalized_scores, finalized_tokens, = self.toplayer.crf_layer._viterbi_decode(emissions)\n",
    "            #finalized_scores, finalized_tokens, = self.crf_layer._viterbi_decode(emissions)\n",
    "        elif inf_t == 'v-nr':\n",
    "            finalized_scores, finalized_tokens, = self.toplayer.crf_layer._compute_viterbi_no_repeat(emissions)\n",
    "            #finalized_scores, finalized_tokens, = self.crf_layer._compute_viterbi_no_repeat(emissions)\n",
    "        else:\n",
    "            finalized_scores, finalized_tokens, = self.toplayer.crf_layer._compute_f_algorithm(emissions)\n",
    "            #finalized_scores, finalized_tokens, = self.crf_layer._compute_f_algorithm(emissions)\n",
    "\n",
    "        return finalized_scores, finalized_tokens\n",
    "\n",
    "    def repeat_logits_half(self, emissions ):\n",
    "        \n",
    "        penalty = 1.2\n",
    "        scores, preds = torch.max( emissions, 2 )\n",
    "        masks = emissions == scores[:,:,None]\n",
    "        masks = masks.permute( 1, 0, 2 )\n",
    "        new_mask = torch.zeros( (  masks.size(1), masks.size(2)), device = emissions.device, dtype=torch.bool )\n",
    "        new_masks = torch.zeros( ( masks.size(0), masks.size(1), masks.size(2)), device = emissions.device, dtype=torch.bool )\n",
    "        for i, mask in enumerate( masks ):\n",
    "            new_mask = torch.logical_or( mask,  new_mask  )\n",
    "            new_masks[i] = new_mask\n",
    "        new_masks = new_masks.transpose(0,1)\n",
    "        first_true_mask = ( new_masks.int().cumsum(dim = 1 ) == 1 ) & new_masks\n",
    "        new_masks = new_masks & ( ~first_true_mask )\n",
    "\n",
    "        p_masks = emissions > 0\n",
    "        m_masks = emissions < 0\n",
    "        p_new_masks = p_masks & new_masks\n",
    "        m_new_masks = m_masks & new_masks\n",
    "        emissions2 = emissions.clone()\n",
    "        emissions2[p_new_masks] = emissions[p_new_masks] / penalty\n",
    "        emissions2[m_new_masks] = emissions2[m_new_masks] * penalty\n",
    "\n",
    "        return emissions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_path: str, img_directory: str, transforms, transforms2, tokenizer, length_max = None ) -> None:\n",
    "        super().__init__()\n",
    "        self.img_directory = img_directory\n",
    "        self.transforms = transforms\n",
    "        self.transforms2 = transforms2 \n",
    "        # TODO: fix to original data\n",
    "        #画像の前処理\n",
    "        self.img_file = []\n",
    "        self.tokens = []\n",
    "        #vocab_size = len( tokenizer )\n",
    "        #c1 = torch.zeros( ( vocab_size ) )\n",
    "        #c2 = torch.zeros( ( vocab_size, vocab_size ) )\n",
    "        if length_max == None:\n",
    "            self.length_max = 0\n",
    "        else:\n",
    "            self.length_max = length_max\n",
    "        length_sum = 0\n",
    "\n",
    "        with open( file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        for i, line_data in enumerate( data ):\n",
    "            if i % 100000 == 0:\n",
    "                print( \"i:\", i )\n",
    "            self.img_file.append( line_data['img_file'] )\n",
    "            id_tokens = line_data['id_tokens']\n",
    "            id_tokens.append( eos_token_id )\n",
    "            id_tokens.append( eos_token_id )\n",
    "            length_sum += len( id_tokens )\n",
    "            if length_max != None:\n",
    "                id_tokens = torch.tensor( id_tokens )[:self.length_max]\n",
    "            else:\n",
    "                if self.length_max < len( id_tokens ):\n",
    "                    self.length_max = len( id_tokens )\n",
    "                id_tokens = torch.tensor( id_tokens )\n",
    "            self.tokens.append( id_tokens )\n",
    "        # w1, w2 を作る時は length_max = None　でお願いします。\n",
    "        #    for i2 in range( len(id_tokens) ):\n",
    "        #        if i2 == len( id_tokens ) - 1:\n",
    "        #            c1[id_tokens[i2]] += 1\n",
    "        #        else:\n",
    "        #            c1[id_tokens[i2]] += 1\n",
    "        #            c2[id_tokens[i2], id_tokens[i2+1] ] += 1\n",
    "        '''\n",
    "        c1avg = int( torch.sum( c1 ) / torch.sum( torch.ne( c1, 0 ).int()) )\n",
    "        c2avg = int( torch.sum( torch.sum( c2, dim = 1 ), dim = 0 ) / torch.sum( torch.ne( c2, 0 ).int() ) )\n",
    "\n",
    "        c1[0] = c1avg\n",
    "\n",
    "        c2[:,0] = c2avg\n",
    "        c2[0,:] = c2avg\n",
    "        \n",
    "        sumc1 = torch.sum( c1, dim = 0 )\n",
    "        sumc2 = torch.sum( torch.sum( c2, dim = 1 ), dim = 0 )\n",
    "\n",
    "        prob1 = c1 / sumc1\n",
    "        prob2 = c2 / sumc2\n",
    "\n",
    "        self.w1 = prob1 ** -0.4\n",
    "        self.w1 = torch.nan_to_num( self.w1, nan = 0.0, posinf=0.0, neginf=0.0 )\n",
    "        avg1 = torch.sum( self.w1, dim = 0 ) / torch.sum( torch.ne( self.w1, 0.0 ).int() )\n",
    "        self.w1 = self.w1 / avg1\n",
    "\n",
    "        self.w2 = prob2 ** -0.4\n",
    "        self.w2 = torch.nan_to_num( self.w2, nan = 0.0, posinf=0.0, neginf=0.0 )\n",
    "        avg2 = torch.sum( torch.sum( self.w2, dim = 1 ), dim = 0 ) / torch.sum( torch.ne( self.w2, 0.0 ).int() )\n",
    "        self.w2 = self.w2 / avg2\n",
    "\n",
    "        with open( \"/mnt/ssd2/v7/w_unigrma.pkl\", mode=\"wb\" ) as f:\n",
    "            pickle.dump( self.w1, f )\n",
    "\n",
    "        with open( \"/mnt/ssd2/v7/w_bigrma.pkl\", mode=\"wb\" ) as f:\n",
    "            pickle.dump( self.w2, f )\n",
    "        \n",
    "        '''\n",
    "\n",
    "        #with open( \"/mnt/ssd2/v7/w_unigram.pkl\", 'rb') as f:\n",
    "        #    self.w1 = pickle.load(f)\n",
    "\n",
    "        #with open( \"/mnt/ssd2/v7/w_bigram.pkl\", 'rb') as f:\n",
    "        #    self.w2 = pickle.load(f)\n",
    "        \n",
    "        if length_max == None:\n",
    "            print( \"length max:\", self.length_max )\n",
    "            print( \"avg length:\", length_sum / len( self.tokens ) )\n",
    "    \n",
    "    # ここで取り出すデータを指定している\n",
    "    def __getitem__(\n",
    "        self,\n",
    "        index: int\n",
    "    ):\n",
    "        tokens = self.tokens[index]\n",
    "        img_file = self.img_file[index] + \".jpg\"\n",
    "        img_path = os.path.join( self.img_directory, img_file ) #index番目の画像のパスを取得\n",
    "        img = Image.open(img_path) #PIL形式で画像を読み込み\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert(\"RGB\")\n",
    "        img1 = self.transforms(img)\n",
    "        img2 = self.transforms2(img)\n",
    "        \n",
    "        return img1, img2, tokens\n",
    "\n",
    "    # この method がないと DataLoader を呼び出す際にエラーを吐かれる\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.tokens)\n",
    "\n",
    "    def length_max(self):\n",
    "        return self.length_max\n",
    "\n",
    "    #def w1(self):\n",
    "    #    return self.w1\n",
    "\n",
    "    #def w2(self):\n",
    "    #    return self.w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_func(batch: Sequence[Tuple[Union[torch.Tensor, str]]], pad_index, length_max ):\n",
    "    imgs1, imgs2, tokens = zip(*batch)\n",
    "\n",
    "    max_length = length_max\n",
    "    #max_length = 0\n",
    "    #for target in tokens:\n",
    "    #    if max_length < len( target ):\n",
    "    #        max_length = len( target )\n",
    "    \n",
    "    targets = []\n",
    "    lengths = []\n",
    "    for target in tokens:\n",
    "        pad_len = max_length - len( target ) \n",
    "        #print( \"target:\", target )\n",
    "        input2= F.pad( target, (0, pad_len), mode='constant', value = pad_index)\n",
    "        targets.append( input2 )\n",
    "        lengths.append( len( target ) )\n",
    "    \n",
    "    imgs1 = torch.stack( imgs1, dim = 0 )\n",
    "    imgs2 = torch.stack( imgs2, dim = 0 )\n",
    "    targets = torch.stack( targets, dim = 0 )\n",
    "    lengths = torch.tensor( lengths, requires_grad = False  )\n",
    "    \n",
    "    return imgs1, imgs2, targets, lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4x-PO05mCS-"
   },
   "source": [
    "###学習におけるハイパーパラメータやオプションの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EQES3A8OG-V_"
   },
   "outputs": [],
   "source": [
    "class ConfigTrain(object):\n",
    "    '''\n",
    "    ハイパーパラメータ、システム共通変数の設定\n",
    "    '''\n",
    "    def __init__(self):\n",
    "\n",
    "        # ハイパーパラメータ\n",
    "        self.img_size = 336\n",
    "        self.dim_embedding = 1024   # 埋め込み層の次元\n",
    "        self.length_max = 97\n",
    "        self.lr_clip = 0.0\n",
    "        self.lr_con = 1.66e-10\n",
    "        self.lr_bert = 2.19e-8          # 学習率\n",
    "        self.lr_cri = 7.20e-5\n",
    "        self.lr_others = 5.82e-7\n",
    "        #self.clip_thresh_clip = 1\n",
    "        self.clip_thresh_con = 3.3e-4\n",
    "        self.clip_thresh_bert = 9e-3            # 学習率\n",
    "        self.clip_thresh_cri = 3.3e-4\n",
    "        self.clip_thresh_others = 3.3e-4\n",
    "        self.dropout = 0.0         # dropout確率\n",
    "        #self.batch_size = 160       # ミニバッチ数\n",
    "        self.batch_size = 128       # ミニバッチ数\n",
    "        #self.batch_size = 80       # ミニバッチ数\n",
    "        #self.batch_size = 64\n",
    "        #self.batch_size = 48\n",
    "        #self.batch_size = 40       # ミニバッチ数\n",
    "        #self.batch_size = 4       # ミニバッチ数\n",
    "        self.num_epochs = 1       # エポック数→Colab無料版でテストする際は10未満に修正を推奨\n",
    "        self.use_amp = True\n",
    "        #self.use_amp = False\n",
    "        self.use_saved_pth = True\n",
    "        #self.use_saved_pth = False\n",
    "        self.vocab_size = len( tokenizer )\n",
    "        self.weight_decay = 0.0232\n",
    "        self.betas = (0.9, 0.999 )\n",
    "        self.warmup = 0.1\n",
    "        self.metric = \"special\" # bleu, meteor, wer, rouge\n",
    "        #self.decode_t = \"ordinary\"\n",
    "        self.decode_t = \"no-pad\"\n",
    "        self.reward_t = \"ord+rep+len+unr\"\n",
    "        #self.reward_t = \"ordinary\"\n",
    "        self.clip_range = 1e-1\n",
    "        self.clip_grad_threshold = 5e-1\n",
    "        self.ord_coef = 1.0 #固定\n",
    "        self.cider_coef = 1.0 #固定\n",
    "        self.rouge_coef = 2.53\n",
    "        self.clip_coef = 1.65\n",
    "        self.bert_coef = 6.68\n",
    "        self.rep_coef = 5.84\n",
    "        self.repeat_thresh = [ 3,2,2,2]\n",
    "        self.repeat_weight = [ 1, 1, 1, 1 ]\n",
    "        self.len_coef = 0.8\n",
    "        self.unr_coef = 1.0\n",
    "        self.policy_coef = 1.0 #固定\n",
    "        self.crf_coef = 1.0\n",
    "        self.ce_coef = 0.3\n",
    "        self.ent_coef = 0.00269\n",
    "        self.cri_coef = 0.0 # モンテカルロ法\n",
    "        self.gae_coef = 3.4 # GAE\n",
    "        self.kl_coef = 0.0401\n",
    "        self.target_kl = 8.0\n",
    "        self.buffer_kl = 1.2\n",
    "        self.kl_max = 0.1\n",
    "        self.kl_min = 0.1\n",
    "        self.gamma = 0.972\n",
    "        self.lam = 0.974\n",
    "        self.ratio_clamp_max = -1.0 # -1.0 ratio is free.  0.0 ratio calmp 1.1 for mainas advantage.  value > 0 ratio clamps value  \n",
    "        self.use_repeat_logits_half = False\n",
    "        self.use_ce_bert = True\n",
    "        self.display_include_coef = True\n",
    "        self.use_adaptive_KL = False\n",
    "        self.temp = 0.710\n",
    "        \n",
    "        # パスの設定\n",
    "        self.img_directory = '/mnt/ssd2/v7/img'\n",
    "        self.anno_file = '/mnt/ssd2/v7/data.pkl'\n",
    "        self.save_directory = './model'\n",
    "        #self.PATH = \"model/model_ar_hfgpt2_v7_curr.pth\"\n",
    "        #self.PATH = \"../test/model/model_bert_large_NAR_PAD_curr.pth\"\n",
    "        self.PATH = \"../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\"\n",
    "        #self.PATH = \"model/model_bert_large_NAR_PAD_curr.pth\"\n",
    "        #self.PATH = \"model/model_bert_mask_curr.pth\"\n",
    "\n",
    "        # 検証に使う学習セット内のデータの割合\n",
    "        self.test_ratio = 0.1\n",
    "        self.val_ratio = 0.1\n",
    "        #self.val_ratio = 0.0004\n",
    "        #self.test_ratio = 0.0004\n",
    "        \n",
    "        # 学習に使うデバイス\n",
    "        #self.device = 'cuda'\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        #self.device = 'cpu'\n",
    "        \n",
    "        # データローダーに使うCPUプロセスの数\n",
    "        #self.num_workers = 4\n",
    "        self.num_workers = 0 if self.device == torch.device('cpu') else 10\n",
    "        #self.num_workers = 0 if self.device == torch.device('cpu') else 4\n",
    "        #self.num_workers = 0\n",
    "        \n",
    "        # 移動平均で計算する損失の値の数\n",
    "        self.moving_avg = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--NNWCwZI5qS"
   },
   "source": [
    "### 学習を行う関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "i: 100000\n",
      "i: 200000\n",
      "i: 300000\n",
      "i: 400000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 02:06:35,528] A new study created in Journal with name: example-study15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 500000\n",
      "config.device: cuda:0\n",
      "学習セット数: 397\n",
      "評価セット数: 397\n",
      "テストセット数: 397\n",
      "use_amp: True\n",
      "use_saved_pth: True\n",
      "num_global_steps: 397\n",
      "warmup: 0.1\n",
      "num_warmup_steps: 39.7\n",
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.16164855272362572\n",
      "clip_grad_threshold gradient norm: 1.0843746252761557\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 0.03027357439631395\n",
      "unr_coef: 0.9917829019525026\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.6041731354550595\n",
      "ce_coef: 0.4423620588195005\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 0.6530633443467854\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_020649.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0145e94b284e4f199a9c1cf6b3de2ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83181/2133460519.py:234: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  reward = torch.tensor(reward).to(self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 3.2455012798309326, policy = 5.5917759311796544e-08, entropy_loss = -0.002686543622985482, gae = 1.8095083236694336, kl_div = 0.08494411408901215, reward = 3.434079885482788, ord = 7.024675369262695, repeat = -4.1895036697387695, length = -0.00106147734913975, adv = 0.9275877475738525, rougeL = 1.2214044332504272, cider = 0.30087655782699585, clip = 0.4090419113636017, crf = 0.45766353607177734, ce = 0.8960718512535095, unr = 0.5999702215194702, ber = 5.682074069976807\n",
      "refe: [CLS] in this image we can see an insect on the flower. [SEP]\n",
      "hypo: [CLS] in this image we can see an insect on a flower flower. there is a blurry. [SEP]\n",
      "samp: [CLS] in this picture we can see an insect is a flower flower. on the background there is blurred. [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 3.876868486404419, policy = 0.25362658500671387, entropy_loss = -0.002684361767023802, gae = 1.9545705318450928, kl_div = 0.08664579689502716, reward = 3.6579208374023438, ord = 6.996513366699219, repeat = -3.9380955696105957, length = -0.0015271054580807686, adv = 0.9702560305595398, rougeL = 1.2568085193634033, cider = 0.2367689609527588, clip = 0.40382516384124756, crf = 0.6358524560928345, ce = 0.9488575458526611, unr = 0.6010310649871826, ber = 5.653483867645264\n",
      "refe: [CLS] here is a man standing and playing guitar. at the right corner of the image i can see a woman's face. these are the show lights at the top. [SEP]\n",
      "hypo: [CLS] in this image we can see a man standing on the guitar. in front of the background we can see lights. [SEP]\n",
      "samp: [CLS] in this image we can see a man and a guitar on the guitar. in his hand. [SEP] drums. [SEP]\n",
      "lr con   : 1.2962216624685136e-10\n",
      "lr bert  : 1.7100755667506296e-08\n",
      "lr cri   : 5.622166246851385e-05\n",
      "lr others: 4.544584382871536e-07\n",
      "Train epoch = 0.07556675062972293, loss = 4.059574127197266, policy = 0.3597993850708008, entropy_loss = -0.002615222241729498, gae = 2.0402491092681885, kl_div = 0.0861806869506836, reward = 3.786842107772827, ord = 7.025670528411865, repeat = -3.846341609954834, length = -0.00150069291703403, adv = 0.9936195015907288, rougeL = 1.26872718334198, cider = 0.23036231100559235, clip = 0.4031772315502167, crf = 0.638288676738739, ce = 0.9376711845397949, unr = 0.609013557434082, ber = 5.64190673828125\n",
      "refe: [CLS] in the image we can see there is a woman standing near the podium and there is mic kept on the stand. behind there is table and background of the image is little blurred. [SEP]\n",
      "hypo: [CLS] in this image there is a woman standing. in front of the podium mike. [SEP] stand. [SEP] stand. in the right side. [SEP]\n",
      "samp: [CLS] in the center of the image we can see a black color t - front of the front of her we can see the background there is a. [SEP]. [SEP]\n",
      "lr con   : 1.6307304785894207e-10\n",
      "lr bert  : 2.1513853904282117e-08\n",
      "lr cri   : 7.073047858942065e-05\n",
      "lr others: 5.717380352644836e-07\n",
      "Train epoch = 0.11335012594458438, loss = 4.2462992668151855, policy = 0.37400346994400024, entropy_loss = -0.002515549072995782, gae = 2.1861331462860107, kl_div = 0.08541102707386017, reward = 4.00429630279541, ord = 7.036707878112793, repeat = -3.6497178077697754, length = -0.0015072259120643139, adv = 1.031084656715393, rougeL = 1.2996509075164795, cider = 0.21307799220085144, clip = 0.40314483642578125, crf = 0.6780383586883545, ce = 0.9252289533615112, unr = 0.6188134551048279, ber = 5.643939971923828\n",
      "refe: [CLS] there are plants and there is a girl. [SEP]\n",
      "hypo: [CLS] in this image, we can see a smile on the background we can see a tree. [SEP]\n",
      "samp: [CLS] in this image there is a woman sitting on the background. in the background there are trees. [SEP]\n",
      "lr con   : 1.561041141897565e-10\n",
      "lr bert  : 2.0594458438287153e-08\n",
      "lr cri   : 6.770780856423173e-05\n",
      "lr others: 5.473047858942065e-07\n",
      "Train epoch = 0.15113350125944586, loss = 4.101225852966309, policy = 0.32151204347610474, entropy_loss = -0.0025256709195673466, gae = 2.1444854736328125, kl_div = 0.08513558655977249, reward = 3.9637789726257324, ord = 7.042749404907227, repeat = -3.6985738277435303, length = -0.0014954258222132921, adv = 1.015616774559021, rougeL = 1.2978718280792236, cider = 0.21164560317993164, clip = 0.40407031774520874, crf = 0.6309188604354858, ce = 0.9216995239257812, unr = 0.6210988163948059, ber = 5.648992538452148\n",
      "refe: [CLS] here we see 6 people standing and the left most person is in front of a microphone which is being held by another person. behind we can see a building and also behind the person we have a banner on which some matter is written like casino....... [SEP]\n",
      "hypo: [CLS] in this picture we can see a few people standing in front of the front of this image. in front of the background there are few people. in the background. [SEP]\n",
      "samp: [CLS] in this picture we see a group of people standing and a man in front of the left side of him there are few people. in front of him there is a microphone. [SEP]\n",
      "lr con   : 1.4913518052057094e-10\n",
      "lr bert  : 1.9675062972292192e-08\n",
      "lr cri   : 6.468513853904282e-05\n",
      "lr others: 5.228715365239295e-07\n",
      "Train epoch = 0.1889168765743073, loss = 4.170108795166016, policy = 0.2879014015197754, entropy_loss = -0.0024753063917160034, gae = 2.2276923656463623, kl_div = 0.0840008556842804, reward = 4.114771366119385, ord = 7.04485559463501, repeat = -3.5594992637634277, length = -0.0015289309667423368, adv = 1.0374362468719482, rougeL = 1.3095589876174927, cider = 0.19683031737804413, clip = 0.40305984020233154, crf = 0.6576818823814392, ce = 0.915307879447937, unr = 0.6309449076652527, ber = 5.642050266265869\n",
      "refe: [CLS] it is a black and white picture. in this picture i can see two people are sitting. something is written at the bottom of the picture. [SEP]\n",
      "hypo: [CLS] in this image i can see a painting of this image there is a man sitting\n",
      "samp: [CLS] this is a black and white picture, in this image, there is a table. [SEP]\n",
      "lr con   : 1.4216624685138537e-10\n",
      "lr bert  : 1.8755667506297228e-08\n",
      "lr cri   : 6.16624685138539e-05\n",
      "lr others: 4.984382871536523e-07\n",
      "Train epoch = 0.22670025188916876, loss = 4.227863311767578, policy = 0.2693500518798828, entropy_loss = -0.0024441916029900312, gae = 2.278752088546753, kl_div = 0.08319653570652008, reward = 4.201246738433838, ord = 7.053038120269775, repeat = -3.485361099243164, length = -0.0015521572204306722, adv = 1.0455617904663086, rougeL = 1.3236545324325562, cider = 0.19980846345424652, clip = 0.4038154184818268, crf = 0.6819918155670166, ce = 0.9170168042182922, unr = 0.6351220011711121, ber = 5.641841888427734\n",
      "refe: [CLS] in this image, we can see husky and dog are running on the snow. in the background, we can see mesh, poles, trees and few objects. [SEP]\n",
      "hypo: [CLS] in this image we can see two dogs. in the snow. [SEP]\n",
      "samp: [CLS] in this image we can see two dogs are covered with the ground. [SEP]\n",
      "lr con   : 1.3519731318219982e-10\n",
      "lr bert  : 1.7836272040302267e-08\n",
      "lr cri   : 5.863979848866499e-05\n",
      "lr others: 4.740050377833753e-07\n",
      "Train epoch = 0.26448362720403024, loss = 4.236135959625244, policy = 0.2506207227706909, entropy_loss = -0.0024297446943819523, gae = 2.280928611755371, kl_div = 0.08346717804670334, reward = 4.228664398193359, ord = 7.053571701049805, repeat = -3.45992112159729, length = -0.0015815134393051267, adv = 1.0413329601287842, rougeL = 1.3304070234298706, cider = 0.19742931425571442, clip = 0.40448614954948425, crf = 0.7018585801124573, ce = 0.9216905832290649, unr = 0.6365957260131836, ber = 5.638949871063232\n",
      "refe: [CLS] we can see animal sitting on a branch and tree trunks. we can see wall and mesh, behind this mess we can see plants. we can see light. [SEP]\n",
      "hypo: [CLS] in this image we can see an animal is a tree. i can see a tree. [SEP]\n",
      "samp: [CLS] in this picture we can see an animal. on the branch monkey i can see [SEP]\n",
      "lr con   : 1.2822837951301427e-10\n",
      "lr bert  : 1.6916876574307306e-08\n",
      "lr cri   : 5.561712846347607e-05\n",
      "lr others: 4.495717884130982e-07\n",
      "Train epoch = 0.3022670025188917, loss = 4.245927333831787, policy = 0.27858245372772217, entropy_loss = -0.0024186887312680483, gae = 2.2586607933044434, kl_div = 0.08325299620628357, reward = 4.232071399688721, ord = 7.056502819061279, repeat = -3.4606986045837402, length = -0.0015636072494089603, adv = 1.0325539112091064, rougeL = 1.3306747674942017, cider = 0.19588646292686462, clip = 0.40400269627571106, crf = 0.7095587253570557, ce = 0.9182908535003662, unr = 0.6378320455551147, ber = 5.640801906585693\n",
      "refe: [CLS] in this image in front there are three people sitting inside the helicopter. behind them there are seats. in the background of the image there are trees and sky. [SEP]\n",
      "hypo: [CLS] in this image we can see a man sitting on the vehicle. in the background there is a. [SEP]\n",
      "samp: [CLS] in the foreground of the group of people sitting on the road. in their hands. [SEP]\n",
      "lr con   : 1.2125944584382872e-10\n",
      "lr bert  : 1.5997481108312342e-08\n",
      "lr cri   : 5.2594458438287154e-05\n",
      "lr others: 4.2513853904282117e-07\n",
      "Train epoch = 0.34005037783375314, loss = 4.2339653968811035, policy = 0.2604350745677948, entropy_loss = -0.00240955944173038, gae = 2.2594454288482666, kl_div = 0.0829080194234848, reward = 4.252800941467285, ord = 7.063590049743652, repeat = -3.447089672088623, length = -0.0015554785495623946, adv = 1.027199625968933, rougeL = 1.3338243961334229, cider = 0.19975535571575165, clip = 0.4037034809589386, crf = 0.7167893052101135, ce = 0.9167966842651367, unr = 0.6378563642501831, ber = 5.643233776092529\n",
      "refe: [CLS] in the center of the image, we can see a person sitting on the chair and wearing glasses and a hat and holding a marker and a book. in the background, there are some other people, books, boards, lights, rods, posters on the wall. at the bottom, there is a table and we can see books on it and there is a bottle. [SEP]\n",
      "hypo: [CLS] in this image there is a man sitting on the person is a book. in front of him there is a table there are sitting on the table, there are sitting on the table. [SEP]\n",
      "samp: [CLS] in this image there are two persons standing and holding a person sitting on the chairs and in front of him there is written on the left side of him there is a table, we can see number of the background. [SEP]\n",
      "lr con   : 1.1429051217464315e-10\n",
      "lr bert  : 1.507808564231738e-08\n",
      "lr cri   : 4.957178841309823e-05\n",
      "lr others: 4.0070528967254406e-07\n",
      "Train epoch = 0.3778337531486146, loss = 4.21571159362793, policy = 0.28309956192970276, entropy_loss = -0.002413240261375904, gae = 2.2320189476013184, kl_div = 0.08265168964862823, reward = 4.239548206329346, ord = 7.054554462432861, repeat = -3.452653169631958, length = -0.0015367495361715555, adv = 1.0156595706939697, rougeL = 1.3287286758422852, cider = 0.19704286754131317, clip = 0.40324485301971436, crf = 0.7066370844841003, ce = 0.9137170910835266, unr = 0.6391836404800415, ber = 5.642669200897217\n",
      "refe: [CLS] in this picture i can see trees and i can see a house and grass on the ground and i can see blue sky. [SEP]\n",
      "hypo: [CLS] in the foreground of this image there are trees, trees, in the sky. [SEP]\n",
      "samp: [CLS] in this image we can see a house. there are trees, in the sky. [SEP]\n",
      "lr con   : 1.073215785054576e-10\n",
      "lr bert  : 1.4158690176322418e-08\n",
      "lr cri   : 4.654911838790932e-05\n",
      "lr others: 3.76272040302267e-07\n",
      "Train epoch = 0.4156171284634761, loss = 4.22056770324707, policy = 0.2764848470687866, entropy_loss = -0.0023915974888950586, gae = 2.2240240573883057, kl_div = 0.08262933790683746, reward = 4.245856761932373, ord = 7.0560760498046875, repeat = -3.4487059116363525, length = -0.001536627416498959, adv = 1.00811767578125, rougeL = 1.3297271728515625, cider = 0.19796296954154968, clip = 0.4026610553264618, crf = 0.727603018283844, ce = 0.9122181534767151, unr = 0.6400235891342163, ber = 5.639500617980957\n",
      "refe: [CLS] in this picture we can see a girl, she is smiling, she is holding a tray, on this tray we can see food items and in the background we can see people. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman standing. in the chair. in front of her. in front. there is a table. [SEP]\n",
      "samp: [CLS] in this picture we can see a woman standing in front of chair. in front of this holding an object. in front there is a chair. on it. [SEP]\n",
      "lr con   : 1.0035264483627203e-10\n",
      "lr bert  : 1.3239294710327456e-08\n",
      "lr cri   : 4.35264483627204e-05\n",
      "lr others: 3.518387909319899e-07\n",
      "Train epoch = 0.4534005037783375, loss = 4.208911895751953, policy = 0.2646961808204651, entropy_loss = -0.0023905786219984293, gae = 2.218984842300415, kl_div = 0.08265244215726852, reward = 4.266895294189453, ord = 7.052656650543213, repeat = -3.4249258041381836, length = -0.0015346214640885592, adv = 1.003597378730774, rougeL = 1.3322932720184326, cider = 0.1967623233795166, clip = 0.40301620960235596, crf = 0.7324967384338379, ce = 0.9124716520309448, unr = 0.6406993269920349, ber = 5.6409912109375\n",
      "refe: [CLS] in this picture i can see the drawing of a monkey and it is on the brown color thing. i can also see something is written on the bottom and top right corner of this picture. [SEP]\n",
      "hypo: [CLS] in this picture, we can see a painting. we can see an animal and some text. [SEP]\n",
      "samp: [CLS] in this picture we can see depiction of this image there is an animal. in his pig\n",
      "lr con   : 9.338371116708649e-11\n",
      "lr bert  : 1.2319899244332495e-08\n",
      "lr cri   : 4.0503778337531486e-05\n",
      "lr others: 3.2740554156171283e-07\n",
      "Train epoch = 0.491183879093199, loss = 4.168339729309082, policy = 0.2624301016330719, entropy_loss = -0.002396912779659033, gae = 2.188673973083496, kl_div = 0.08266331255435944, reward = 4.244751930236816, ord = 7.04681921005249, repeat = -3.4411773681640625, length = -0.0015249826246872544, adv = 0.9907123446464539, rougeL = 1.3313076496124268, cider = 0.19823017716407776, clip = 0.40306368470191956, crf = 0.7250829935073853, ce = 0.9118866920471191, unr = 0.6406346559524536, ber = 5.6408281326293945\n",
      "refe: [CLS] in this picture there is an insect on the marble and the insect is in green and in brown color. [SEP]\n",
      "hypo: [CLS] in this image we can see an insect on the surface. [SEP]\n",
      "samp: [CLS] in the center of the image there is an insect. [SEP]\n",
      "lr con   : 8.641477749790091e-11\n",
      "lr bert  : 1.140050377833753e-08\n",
      "lr cri   : 3.7481108312342564e-05\n",
      "lr others: 3.029722921914357e-07\n",
      "Train epoch = 0.5289672544080605, loss = 4.112571716308594, policy = 0.25529202818870544, entropy_loss = -0.0024082481395453215, gae = 2.1604416370391846, kl_div = 0.08288786560297012, reward = 4.225687026977539, ord = 7.042196750640869, repeat = -3.4552650451660156, length = -0.0014956053346395493, adv = 0.9785746335983276, rougeL = 1.3276079893112183, cider = 0.20025350153446198, clip = 0.40281665325164795, crf = 0.7071905136108398, ce = 0.9091677069664001, unr = 0.6402507424354553, ber = 5.641438007354736\n",
      "refe: [CLS] in this image we can see a man standing. [SEP]\n",
      "hypo: [CLS] in this picture we can see a man standing. he is wearing a wall. [SEP] on the wall. [SEP]\n",
      "samp: [CLS] in this picture, we can see a person wearing black color t - shirt and on the background we can see a wall. [SEP]\n",
      "lr con   : 7.944584382871536e-11\n",
      "lr bert  : 1.048110831234257e-08\n",
      "lr cri   : 3.4458438287153655e-05\n",
      "lr others: 2.785390428211587e-07\n",
      "Train epoch = 0.5667506297229219, loss = 4.105949878692627, policy = 0.26628491282463074, entropy_loss = -0.0024027640465646982, gae = 2.136019468307495, kl_div = 0.08266623318195343, reward = 4.2116498947143555, ord = 7.044098377227783, repeat = -3.470383644104004, length = -0.0015014541568234563, adv = 0.9680506587028503, rougeL = 1.3295584917068481, cider = 0.20112846791744232, clip = 0.4029638171195984, crf = 0.7133163809776306, ce = 0.9100658297538757, unr = 0.6394351124763489, ber = 5.642294406890869\n",
      "refe: [CLS] in the picture there is a room in that room two persons are sitting on a sofa side by side in which one person is talking another person is writing something on the paper there is a table near the sofa on the table there are house plants there is a photo frame on the wall. [SEP]\n",
      "hypo: [CLS] in this image, we can see a person sitting on the sofa and sitting on the man is a book. in his hand and sitting on the table. in his hand. [SEP]\n",
      "samp: [CLS] in this picture, we can see a man sitting on the man sitting on the chair is a book. in his hand and there is wearing a table. in his frame. [SEP]\n",
      "lr con   : 7.24769101595298e-11\n",
      "lr bert  : 9.561712846347607e-09\n",
      "lr cri   : 3.143576826196473e-05\n",
      "lr others: 2.541057934508816e-07\n",
      "Train epoch = 0.6045340050377834, loss = 4.107779502868652, policy = 0.2623803913593292, entropy_loss = -0.0024000743869692087, gae = 2.13466477394104, kl_div = 0.08252370357513428, reward = 4.23216438293457, ord = 7.0456862449646, repeat = -3.452462673187256, length = -0.001520227757282555, adv = 0.9644386172294617, rougeL = 1.3337072134017944, cider = 0.2009611278772354, clip = 0.4029195308685303, crf = 0.7195125222206116, ce = 0.9110977649688721, unr = 0.6404622197151184, ber = 5.642467498779297\n",
      "refe: [CLS] there are two women sitting on the chair and holding food item in their hands. on the table there are food items in two plates. in the background there are books in a stand, bag, house plant and a wall. [SEP]\n",
      "hypo: [CLS] in this image we can see two women and there are sitting and smiling. in their hands. on the table we can see a table we can see some other objects on it. [SEP]\n",
      "samp: [CLS] in this image we can see two women and sitting on the sofas. on the front of the table, we can see the table i can see some other objects on it. [SEP]\n",
      "lr con   : 6.550797649034425e-11\n",
      "lr bert  : 8.642317380352645e-09\n",
      "lr cri   : 2.8413098236775818e-05\n",
      "lr others: 2.2967254408060454e-07\n",
      "Train epoch = 0.6423173803526449, loss = 4.122385025024414, policy = 0.25694364309310913, entropy_loss = -0.002390999812632799, gae = 2.142491340637207, kl_div = 0.08230943977832794, reward = 4.269646644592285, ord = 7.042476177215576, repeat = -3.4135305881500244, length = -0.0015266912523657084, adv = 0.9644730091094971, rougeL = 1.3344571590423584, cider = 0.1979193538427353, clip = 0.40292632579803467, crf = 0.7318524718284607, ce = 0.9111790060997009, unr = 0.6422275900840759, ber = 5.641664981842041\n",
      "refe: [CLS] in this image, i can see the man standing. this is the mike. the background looks blurry. at the bottom of the image, i think this is an object. at the top right corner of the image, i can see the watermark. [SEP]\n",
      "hypo: [CLS] in this picture we can see a man in front of the podium, a microphone, in front of him there is the background we can see a man. [SEP]\n",
      "samp: [CLS] in this picture we can see a person in front of the podium, a podium, in front of him there is in front of him there is a microphone. [SEP]. [SEP]\n",
      "lr con   : 5.853904282115869e-11\n",
      "lr bert  : 7.722921914357682e-09\n",
      "lr cri   : 2.5390428211586902e-05\n",
      "lr others: 2.0523929471032745e-07\n",
      "Train epoch = 0.6801007556675063, loss = 4.088229656219482, policy = 0.24657250940799713, entropy_loss = -0.002385667059570551, gae = 2.1122488975524902, kl_div = 0.08229171484708786, reward = 4.240174293518066, ord = 7.042683124542236, repeat = -3.442826986312866, length = -0.001529304776340723, adv = 0.9518160820007324, rougeL = 1.334445834159851, cider = 0.1989172399044037, clip = 0.4027227461338043, crf = 0.7369558811187744, ce = 0.9125462174415588, unr = 0.6418478488922119, ber = 5.642055988311768\n",
      "refe: [CLS] in this picture these five members are standing. this person holding musical instrument and glass. there is a bed. on the bed we can see cloth. on the background we can see curtains and glass window. from this glass window we can see building. there is a drum plate [SEP]\n",
      "hypo: [CLS] in this image we can see a woman wearing clothes and there is a woman there is standing. we can see floor. [SEP]\n",
      "samp: [CLS] in this image we can see a room. in the image there is a person there is a table we can see there is a person wearing a woman is holding a blue color. [SEP]. [SEP]\n",
      "lr con   : 5.157010915197313e-11\n",
      "lr bert  : 6.8035264483627206e-09\n",
      "lr cri   : 2.2367758186397984e-05\n",
      "lr others: 1.8080604534005037e-07\n",
      "Train epoch = 0.7178841309823678, loss = 4.0843119621276855, policy = 0.24017609655857086, entropy_loss = -0.002382709877565503, gae = 2.1138696670532227, kl_div = 0.08214662969112396, reward = 4.2629194259643555, ord = 7.047013759613037, repeat = -3.425905227661133, length = -0.0015279862564057112, adv = 0.9495829939842224, rougeL = 1.3366249799728394, cider = 0.19865532219409943, clip = 0.4024101793766022, crf = 0.7391344308853149, ce = 0.9113681316375732, unr = 0.6433397531509399, ber = 5.642317295074463\n",
      "refe: [CLS] in the middle of this image, there is a woman in a gray color t - shirt, holding two sticks with both hands and walking on a path. on both sides of this path, there are plants. in the background, there are trees. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman wearing a person standing and holding a person is a bag. [SEP]\n",
      "samp: [CLS] in this picture we can see a lady holding a person standing and holding a person wearing hands. [SEP]\n",
      "lr con   : 4.460117548278757e-11\n",
      "lr bert  : 5.884130982367758e-09\n",
      "lr cri   : 1.9345088161209068e-05\n",
      "lr others: 1.563727959697733e-07\n",
      "Train epoch = 0.7556675062972292, loss = 4.077915668487549, policy = 0.24413205683231354, entropy_loss = -0.002381877740845084, gae = 2.1012837886810303, kl_div = 0.0822155624628067, reward = 4.260995388031006, ord = 7.05086612701416, repeat = -3.4319450855255127, length = -0.001522523700259626, adv = 0.9426825046539307, rougeL = 1.3358172178268433, cider = 0.19936823844909668, clip = 0.4023016691207886, crf = 0.741694986820221, ce = 0.9109712243080139, unr = 0.6435977816581726, ber = 5.6436848640441895\n",
      "refe: [CLS] in this picture there is a woman who is wearing red dress and holding a black bag, beside her we can see a man who is wearing blazer, trouser and shoe. on the right there is another man who is wearing cap, jacket and jeans. in the background we can see the group of persons. in the top left there is a man who is standing near the door, wall and desk. on the table we can see the water glass and jug. at\n",
      "hypo: [CLS] in this image we can see group of people walking. on the background i can see the background we can see the background we can see [SEP]\n",
      "samp: [CLS] in this picture we can see group of people walking. on the background i can see the background we can see the background we can see [SEP] standing. [SEP]\n",
      "lr con   : 3.7632241813602014e-11\n",
      "lr bert  : 4.964735516372796e-09\n",
      "lr cri   : 1.632241813602015e-05\n",
      "lr others: 1.3193954659949622e-07\n",
      "Train epoch = 0.7934508816120907, loss = 4.066196441650391, policy = 0.23600853979587555, entropy_loss = -0.002379784593358636, gae = 2.0928468704223633, kl_div = 0.08212088793516159, reward = 4.266539573669434, ord = 7.049922943115234, repeat = -3.426262617111206, length = -0.0015291767194867134, adv = 0.9377318620681763, rougeL = 1.3363393545150757, cider = 0.19790250062942505, clip = 0.40240833163261414, crf = 0.7455588579177856, ce = 0.9120411276817322, unr = 0.6444091796875, ber = 5.6431379318237305\n",
      "refe: [CLS] in this image, we can see a pillars, gates, grills and arch. at the bottom, we can see a platform. background there are few buildings, trees and sky. [SEP]\n",
      "hypo: [CLS] in this image we can see a building there is a building, there is a building. in front of the building. in the building. [SEP]\n",
      "samp: [CLS] in the foreground of this image there is a building, there is a pole and in the building. in the background there is a building. [SEP]\n",
      "lr con   : 3.066330814441645e-11\n",
      "lr bert  : 4.045340050377834e-09\n",
      "lr cri   : 1.3299748110831234e-05\n",
      "lr others: 1.0750629722921913e-07\n",
      "Train epoch = 0.8312342569269522, loss = 4.07432222366333, policy = 0.23178289830684662, entropy_loss = -0.0023733587004244328, gae = 2.0946426391601562, kl_div = 0.08189040422439575, reward = 4.284347057342529, ord = 7.053659915924072, repeat = -3.413015365600586, length = -0.0015375924995169044, adv = 0.9354982376098633, rougeL = 1.3396997451782227, cider = 0.19856178760528564, clip = 0.4023376703262329, crf = 0.7551827430725098, ce = 0.9131967425346375, unr = 0.6452406644821167, ber = 5.644144058227539\n",
      "refe: [CLS] there are three people sitting. this looks like a table with few objects on it. these are the plants. i can see a name board, which is attached to the building wall. these are the trees. i can see a person behind this man. in the background, that looks like a building. [SEP]\n",
      "hypo: [CLS] in this image we can see there are people sitting on the right side. there is sitting on the background there are two persons sitting on the right side of the background there is sky. [SEP]\n",
      "samp: [CLS] in this picture we can see people sitting in the right side. at the back there is sitting on the right side of the right side of the background there are lights. [SEP]\n",
      "lr con   : 2.3694374475230897e-11\n",
      "lr bert  : 3.1259445843828713e-09\n",
      "lr cri   : 1.0277078085642317e-05\n",
      "lr others: 8.307304785894206e-08\n",
      "Train epoch = 0.8690176322418136, loss = 4.040306091308594, policy = 0.22631222009658813, entropy_loss = -0.0023805706296116114, gae = 2.0755720138549805, kl_div = 0.08197245746850967, reward = 4.272575855255127, ord = 7.050739288330078, repeat = -3.4215962886810303, length = -0.0015344504499807954, adv = 0.9278172254562378, rougeL = 1.3361124992370605, cider = 0.1975250095129013, clip = 0.4021756947040558, crf = 0.7450203895568848, ce = 0.9138097763061523, unr = 0.6449670791625977, ber = 5.643989086151123\n",
      "refe: [CLS] in this image we can see a few people standing, among them one is holding an object and some are wearing the caps. we can see a pole. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman is a woman is a woman is a medal dress. [SEP]\n",
      "samp: [CLS] in the foreground of this image we can see the image there is a medal dress and a woman is blurred. [SEP] ribbon. behind her hand. [SEP]\n",
      "lr con   : 1.6725440806045338e-11\n",
      "lr bert  : 2.206549118387909e-09\n",
      "lr cri   : 7.2544080604534e-06\n",
      "lr others: 5.863979848866498e-08\n",
      "Train epoch = 0.906801007556675, loss = 4.026758670806885, policy = 0.22350698709487915, entropy_loss = -0.002375624608248472, gae = 2.0623974800109863, kl_div = 0.08200456202030182, reward = 4.2659759521484375, ord = 7.0478949546813965, repeat = -3.425786018371582, length = -0.0015330410096794367, adv = 0.9214187264442444, rougeL = 1.3340877294540405, cider = 0.19668489694595337, clip = 0.4021986722946167, crf = 0.7470955848693848, ce = 0.9141294956207275, unr = 0.6453999280929565, ber = 5.644068241119385\n",
      "refe: [CLS] in this image in the center there is one car, and on the right side and left side there are poles, lights and some plants and grass. at the bottom there is road, and in the background there are mountains. at the top there is sky and at the bottom of the image there is text. [SEP]\n",
      "hypo: [CLS] in this picture we can see a car on the road. at the road. at the road. at the background there is sky. [SEP]\n",
      "samp: [CLS] in this image we can see a car on the road. at the road. at the sky. at the background there is the background i can see at the sky. [SEP]\n",
      "lr con   : 9.75650713685978e-12\n",
      "lr bert  : 1.287153652392947e-09\n",
      "lr cri   : 4.231738035264483e-06\n",
      "lr others: 3.4206549118387904e-08\n",
      "Train epoch = 0.9445843828715366, loss = 4.021694183349609, policy = 0.22140036523342133, entropy_loss = -0.002373114228248596, gae = 2.0549709796905518, kl_div = 0.08188068121671677, reward = 4.2682061195373535, ord = 7.0462164878845215, repeat = -3.4227135181427, length = -0.0015443727606907487, adv = 0.9170387387275696, rougeL = 1.333753228187561, cider = 0.1970469355583191, clip = 0.4021849036216736, crf = 0.7505336403846741, ce = 0.9152818918228149, unr = 0.6462475657463074, ber = 5.644357681274414\n",
      "refe: [CLS] in this image we can see these people are walking on the road. here we can see the grass, plants, wooden house, fence, stairs, trees and the sky with clouds in the background. [SEP]\n",
      "hypo: [CLS] in this image we can see few people are walking on the right side, we can see a pathway. i can see a way. we can see the sky. we can see number of the sky. [SEP]\n",
      "samp: [CLS] in this image i can see a lane in the footpath there are walking on the image there is a lane in the either sides of the center of the background i can see a house. [SEP] pots. [SEP]\n",
      "lr con   : 2.787573467674223e-12\n",
      "lr bert  : 3.677581863979849e-10\n",
      "lr cri   : 1.2090680100755668e-06\n",
      "lr others: 9.773299748110832e-09\n",
      "Train epoch = 0.982367758186398, loss = 3.9842677116394043, policy = 0.22087576985359192, entropy_loss = -0.002383953193202615, gae = 2.0297658443450928, kl_div = 0.08190757781267166, reward = 4.240854740142822, ord = 7.044991493225098, repeat = -3.4477152824401855, length = -0.0015294294571503997, adv = 0.9071457386016846, rougeL = 1.3291220664978027, cider = 0.1992330402135849, clip = 0.40235453844070435, crf = 0.739778459072113, ce = 0.9143241047859192, unr = 0.6451075673103333, ber = 5.6446075439453125\n",
      "refe: [CLS] in this picture, it looks like a table. on the table there is a cat, steel object, glass, box and some items. behind the cat there is a wall and some blurred objects. [SEP]\n",
      "hypo: [CLS] in this image we can see a cat. on the image there is a table, there is a table on the right side of the right side of the right side of the right side of the image. [SEP]\n",
      "samp: [CLS] in this image we can observe a cat the cat. on the right side of the background there is a table in the top of the left side of the left side of the image. [SEP]\n",
      "bsz 56 is not batch_size 128. skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 03:04:15,327] Trial 0 finished with value: 1.5353256464004517 and parameters: {'config.betas': 0, 'config.len_coef': 0.03027357439631395, 'config.unr_coef': 0.9917829019525026, 'config.crf_coef': 0.6041731354550595, 'config.ce_coef': 0.4423620588195005, 'config.gae_coef': 0.6530633443467854, 'config.clip_range': 0.16164855272362572, 'clip_grad_threshold': 1.0843746252761557}. Best is trial 0 with value: 1.5353256464004517.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, avg_reward = 1.5353256464004517\n",
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.26827004328509585\n",
      "clip_grad_threshold gradient norm: 0.3991059977403756\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 4.89637884624154\n",
      "unr_coef: 2.4844571089669905\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.8241203992806698\n",
      "ce_coef: 0.8486986047824512\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 3.8415729582465277\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_030428.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ecdd0cf50c448c951524fe5882d2e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 18.72069549560547, policy = -6.1448086619009246e-09, entropy_loss = -0.002768987324088812, gae = 16.238849639892578, kl_div = 0.07570348680019379, reward = 4.2799882888793945, ord = 7.0734148025512695, repeat = -4.070972919464111, length = -0.19142334163188934, adv = 1.240662932395935, rougeL = 1.2459954023361206, cider = 0.2813379168510437, clip = 0.4047127664089203, crf = 0.6557484269142151, ce = 1.7531650066375732, unr = 1.4689700603485107, ber = 5.690400123596191\n",
      "refe: [CLS] there is a road near grass on the ground. in the background, there are animals eating grass on the ground, there are trees and there are clouds in the blue sky. [SEP]\n",
      "hypo: [CLS] in this image we can see grass. on the ground, grass, we can also we can see the sky. [SEP]\n",
      "samp: [CLS] in this image i can see grass on the road, we can also there is greene we can see the sky. [SEP] field there are trees. [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 21.255218505859375, policy = 0.11354588717222214, entropy_loss = -0.002571197459474206, gae = 18.412837982177734, kl_div = 0.07363930344581604, reward = 4.662524223327637, ord = 7.090236663818359, repeat = -3.716262102127075, length = -0.2483006715774536, adv = 1.31257963180542, rougeL = 1.3154221773147583, cider = 0.2279921919107437, clip = 0.3990515470504761, crf = 0.934180736541748, ce = 1.7235865592956543, unr = 1.5368505716323853, ber = 5.662688732147217\n",
      "refe: [CLS] in this image i can see two people with black and red color dresses. to the right i can see the table. in the back there is a screen. [SEP]\n",
      "hypo: [CLS] in this image we can see two people standing on the background there is a black color. [SEP]\n",
      "samp: [CLS] in this image i can see two people standing. at the background there is a curtain. [SEP]\n",
      "lr con   : 1.2962216624685136e-10\n",
      "lr bert  : 1.7100755667506296e-08\n",
      "lr cri   : 5.622166246851385e-05\n",
      "lr others: 4.544584382871536e-07\n",
      "Train epoch = 0.07556675062972293, loss = 21.72292709350586, policy = 0.09561655670404434, entropy_loss = -0.002528408309444785, gae = 18.745237350463867, kl_div = 0.07075460255146027, reward = 4.682888031005859, ord = 7.109690189361572, repeat = -3.660482406616211, length = -0.28395286202430725, adv = 1.306958556175232, rougeL = 1.3395346403121948, cider = 0.21109271049499512, clip = 0.3959503769874573, crf = 1.0839160680770874, ce = 1.7299314737319946, unr = 1.5176331996917725, ber = 5.653400897979736\n",
      "refe: [CLS] in this image, we can see a person is riding a horse on the ground. he wore a hat on his head. top of the image, we can see a group of people are standing near the railing. [SEP]\n",
      "hypo: [CLS] in this image we can see a horse, we can see the horse. [SEP]\n",
      "samp: [CLS] in this image we can see a person. we can see the horse. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (83 > 77). Running this sequence through the model will result in indexing errors\n",
      "/home/uchiyats/.venv/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Encountered caption longer than max_position_embeddings=77. Will truncate captions to thislength. If longer captions are needed, initialize argument `model_name_or_path` with a model thatsupports longer sequences.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 1.6307304785894207e-10\n",
      "lr bert  : 2.1513853904282117e-08\n",
      "lr cri   : 7.073047858942065e-05\n",
      "lr others: 5.717380352644836e-07\n",
      "Train epoch = 0.11335012594458438, loss = 21.55515480041504, policy = 0.23708371818065643, entropy_loss = -0.0025935040321201086, gae = 18.463932037353516, kl_div = 0.07232801616191864, reward = 4.66867733001709, ord = 7.087897300720215, repeat = -3.668626070022583, length = -0.2728274464607239, adv = 1.2918415069580078, rougeL = 1.3209713697433472, cider = 0.21713201701641083, clip = 0.39785751700401306, crf = 1.033793568611145, ce = 1.7506091594696045, unr = 1.5222339630126953, ber = 5.64989709854126\n",
      "refe: [CLS] in this image there is a tram. right side few vehicles are on the road. left side there is a pole and a street light on the pavement. there is a board attached to the poles. left side there are plants and few objects. behind there is a building. background there are trees. [SEP]\n",
      "hypo: [CLS] in this image we can see there is a car on the road, there is a pole, we can see trees, poles, poles, poles, poles, trees, poles. [SEP]\n",
      "samp: [CLS] in this image we can see there is a road. in the background there is a pole, we can see trees, we can see the background there are trees, poles. [SEP]\n",
      "lr con   : 1.561041141897565e-10\n",
      "lr bert  : 2.0594458438287153e-08\n",
      "lr cri   : 6.770780856423173e-05\n",
      "lr others: 5.473047858942065e-07\n",
      "Train epoch = 0.15113350125944586, loss = 20.825496673583984, policy = 0.28381121158599854, entropy_loss = -0.0026598067488521338, gae = 17.740835189819336, kl_div = 0.07325467467308044, reward = 4.537168025970459, ord = 7.075357437133789, repeat = -3.767463445663452, length = -0.2705952823162079, adv = 1.251279592514038, rougeL = 1.3117599487304688, cider = 0.21188929677009583, clip = 0.3973698019981384, crf = 0.9914271831512451, ce = 1.738824725151062, unr = 1.499869704246521, ber = 5.648986339569092\n",
      "refe: [CLS] in this image i can see the cover page of the book. on the book i can see few people, trees and the house. i can also see mountains, clouds and the sky. and there is something is written on it. [SEP]\n",
      "hypo: [CLS] this is a poster. in this image there is a poster and some text written on the sky. in the image there is a person is a person is a sky. [SEP]\n",
      "samp: [CLS] this is a poster. in this image there is written on which are some text and the sky. i can see some text written on the top there is a tree. [SEP]\n",
      "lr con   : 1.4913518052057094e-10\n",
      "lr bert  : 1.9675062972292192e-08\n",
      "lr cri   : 6.468513853904282e-05\n",
      "lr others: 5.228715365239295e-07\n",
      "Train epoch = 0.1889168765743073, loss = 21.09008026123047, policy = 0.2596476972103119, entropy_loss = -0.002634319243952632, gae = 17.975435256958008, kl_div = 0.07130260765552521, reward = 4.596349716186523, ord = 7.0836501121521, repeat = -3.700240135192871, length = -0.28451499342918396, adv = 1.2513480186462402, rougeL = 1.3238568305969238, cider = 0.2079038769006729, clip = 0.39786574244499207, crf = 1.0455554723739624, ce = 1.7407715320587158, unr = 1.49745512008667, ber = 5.649971008300781\n",
      "refe: [CLS] this image consists of three persons. they are wearing white t - shirts. in the background, we can see a building along with the tree. [SEP]\n",
      "hypo: [CLS] in this image we can see few people, he wore t - shirt, the background there are trees. [SEP]\n",
      "samp: [CLS] in this picture we can see a few people standing and smiling. in the background. in the background there are trees. [SEP] trees, trees. [SEP]\n",
      "lr con   : 1.4216624685138537e-10\n",
      "lr bert  : 1.8755667506297228e-08\n",
      "lr cri   : 6.16624685138539e-05\n",
      "lr others: 4.984382871536523e-07\n",
      "Train epoch = 0.22670025188916876, loss = 21.166479110717773, policy = 0.23021884262561798, entropy_loss = -0.0026387684047222137, gae = 18.075347900390625, kl_div = 0.07078191637992859, reward = 4.636999130249023, ord = 7.088555812835693, repeat = -3.6621053218841553, length = -0.28836512565612793, adv = 1.2471328973770142, rougeL = 1.328271508216858, cider = 0.21395625174045563, clip = 0.39750397205352783, crf = 1.0530978441238403, ce = 1.739670753479004, unr = 1.498915195465088, ber = 5.650295734405518\n",
      "refe: [CLS] in this image, there are a few people on the bridge. we can see some trees, plants and the sky. [SEP]\n",
      "hypo: [CLS] in this picture we can see there is a person standing. she is a\n",
      "samp: [CLS] in this picture we can see a person wearing a bridge, i can also there are trees. [SEP]\n",
      "lr con   : 1.3519731318219982e-10\n",
      "lr bert  : 1.7836272040302267e-08\n",
      "lr cri   : 5.863979848866499e-05\n",
      "lr others: 4.740050377833753e-07\n",
      "Train epoch = 0.26448362720403024, loss = 21.001527786254883, policy = 0.23000158369541168, entropy_loss = -0.0026635269168764353, gae = 17.917421340942383, kl_div = 0.07214788347482681, reward = 4.640486240386963, ord = 7.084815502166748, repeat = -3.6654794216156006, length = -0.28433769941329956, adv = 1.236303687095642, rougeL = 1.3279236555099487, cider = 0.20918001234531403, clip = 0.3975238502025604, crf = 1.0371434688568115, ce = 1.747473955154419, unr = 1.5054879188537598, ber = 5.651132583618164\n",
      "refe: [CLS] in this image in the center there is one pole and there are a pair of earrings, in the background there is a wall. [SEP]\n",
      "hypo: [CLS] in this image we can see bracelet. on the background we can see there is a white color. [SEP]\n",
      "samp: [CLS] in this image we can see bracelet. on the background we can see that i can see a surface. [SEP]\n",
      "lr con   : 1.2822837951301427e-10\n",
      "lr bert  : 1.6916876574307306e-08\n",
      "lr cri   : 5.561712846347607e-05\n",
      "lr others: 4.495717884130982e-07\n",
      "Train epoch = 0.3022670025188917, loss = 20.989273071289062, policy = 0.22295917570590973, entropy_loss = -0.0026342386845499277, gae = 17.883886337280273, kl_div = 0.07251925766468048, reward = 4.670867443084717, ord = 7.093039035797119, repeat = -3.6561708450317383, length = -0.2773329019546509, adv = 1.2321053743362427, rougeL = 1.3294529914855957, cider = 0.2131536900997162, clip = 0.3970589339733124, crf = 1.0667308568954468, ce = 1.745813250541687, unr = 1.5113327503204346, ber = 5.65324592590332\n",
      "refe: [CLS] there are two bags and a shoe placed over it. [SEP]\n",
      "hypo: [CLS] in this image we can see a bag. [SEP]\n",
      "samp: [CLS] in this picture i can see a bag. [SEP] mannequin\n",
      "lr con   : 1.2125944584382872e-10\n",
      "lr bert  : 1.5997481108312342e-08\n",
      "lr cri   : 5.2594458438287154e-05\n",
      "lr others: 4.2513853904282117e-07\n",
      "Train epoch = 0.34005037783375314, loss = 20.938371658325195, policy = 0.20672307908535004, entropy_loss = -0.002613226417452097, gae = 17.818761825561523, kl_div = 0.07324963063001633, reward = 4.688746452331543, ord = 7.090085029602051, repeat = -3.635443925857544, length = -0.2791235148906708, adv = 1.2252129316329956, rougeL = 1.3300176858901978, cider = 0.20970824360847473, clip = 0.39694610238075256, crf = 1.0942518711090088, ce = 1.7479972839355469, unr = 1.5132282972335815, ber = 5.651609897613525\n",
      "refe: [CLS] in the center of the image, we can see a sculpture on the building. [SEP]\n",
      "hypo: [CLS] in this image we can see a building. on the [SEP]\n",
      "samp: [CLS] this image consists of the image we can see a building. [SEP]\n",
      "lr con   : 1.1429051217464315e-10\n",
      "lr bert  : 1.507808564231738e-08\n",
      "lr cri   : 4.957178841309823e-05\n",
      "lr others: 4.0070528967254406e-07\n",
      "Train epoch = 0.3778337531486146, loss = 20.87972068786621, policy = 0.19403547048568726, entropy_loss = -0.002606515772640705, gae = 17.772645950317383, kl_div = 0.07397647947072983, reward = 4.711206436157227, ord = 7.089720249176025, repeat = -3.6204657554626465, length = -0.2743797302246094, adv = 1.2194545269012451, rougeL = 1.3313122987747192, cider = 0.20748251676559448, clip = 0.39706289768218994, crf = 1.095371961593628, ce = 1.7462995052337646, unr = 1.5163320302963257, ber = 5.652622699737549\n",
      "refe: [CLS] in this image in front there is a concrete fence. in the background of the image there are buildings. on top of the image there is an object hanging from the crane and there are cables passing. at the top of the image there is sky. [SEP]\n",
      "hypo: [CLS] in this image we can see buildings. in this image there are buildings. in the background i can see a sky. [SEP]\n",
      "samp: [CLS] in this image i can see there is a building. at the sky. in the background i can see a tower. [SEP]\n",
      "lr con   : 1.073215785054576e-10\n",
      "lr bert  : 1.4158690176322418e-08\n",
      "lr cri   : 4.654911838790932e-05\n",
      "lr others: 3.76272040302267e-07\n",
      "Train epoch = 0.4156171284634761, loss = 20.652921676635742, policy = 0.18896768987178802, entropy_loss = -0.0026230167131870985, gae = 17.57052993774414, kl_div = 0.07477615773677826, reward = 4.702496528625488, ord = 7.087467193603516, repeat = -3.6340420246124268, length = -0.26931631565093994, adv = 1.2075461149215698, rougeL = 1.3300392627716064, cider = 0.20852375030517578, clip = 0.3972284197807312, crf = 1.0768365859985352, ce = 1.7444350719451904, unr = 1.518388032913208, ber = 5.653477191925049\n",
      "refe: [CLS] in this picture i can see group of people standing, there are trees, and in the background there is sky. [SEP]\n",
      "hypo: [CLS] in this image i can see a group of persons standing on the background i can see few people, there are trees. we can see the sky. [SEP]\n",
      "samp: [CLS] in the foreground we can see group of the bottom of the background i can see few people, there are trees. on the sky in the sky. [SEP]\n",
      "lr con   : 1.0035264483627203e-10\n",
      "lr bert  : 1.3239294710327456e-08\n",
      "lr cri   : 4.35264483627204e-05\n",
      "lr others: 3.518387909319899e-07\n",
      "Train epoch = 0.4534005037783375, loss = 20.60760498046875, policy = 0.1892784833908081, entropy_loss = -0.002619743812829256, gae = 17.523202896118164, kl_div = 0.07522790879011154, reward = 4.7204742431640625, ord = 7.086649417877197, repeat = -3.6239521503448486, length = -0.26670101284980774, adv = 1.2015018463134766, rougeL = 1.3309223651885986, cider = 0.20701873302459717, clip = 0.3975561261177063, crf = 1.0786510705947876, ce = 1.7438637018203735, unr = 1.5244784355163574, ber = 5.653592586517334\n",
      "refe: [CLS] in this picture we can see a group of people, one person is holding an object and in the background we can see a projector screen, lights. [SEP]\n",
      "hypo: [CLS] in this image there is a person is a person standing and the chairs and in their hands. behind them are two persons standing and i can see the background. [SEP]\n",
      "samp: [CLS] in this image there are two persons wearing black color. at the chairs and in their hands. behind them are two persons standing and i can see a floor. [SEP]. [SEP]\n",
      "lr con   : 9.338371116708649e-11\n",
      "lr bert  : 1.2319899244332495e-08\n",
      "lr cri   : 4.0503778337531486e-05\n",
      "lr others: 3.2740554156171283e-07\n",
      "Train epoch = 0.491183879093199, loss = 20.370563507080078, policy = 0.18303075432777405, entropy_loss = -0.0026396512985229492, gae = 17.31882095336914, kl_div = 0.07588030397891998, reward = 4.706151008605957, ord = 7.085158348083496, repeat = -3.642885684967041, length = -0.2621954679489136, adv = 1.189117431640625, rougeL = 1.3308136463165283, cider = 0.20655551552772522, clip = 0.39779922366142273, crf = 1.0508503913879395, ce = 1.7446224689483643, unr = 1.5260741710662842, ber = 5.6540656089782715\n",
      "refe: [CLS] in the image in the center, we can see two persons are standing and they are smiling. and the woman is holding a knife. in front of them, there is a table. on the table, we can see one cloth, flowers, tissue papers and one cake. in the background there is a wall, roof, windows, fences, trees, pots, poles etc. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman is a woman standing on the right side of the right side of the back there is a flower bouquet, there is an object. we can see a flower bouquet. [SEP]\n",
      "samp: [CLS] in this image i can see a woman is a woman standing and i can see a woman standing and holding an object. [SEP]\n",
      "lr con   : 8.641477749790091e-11\n",
      "lr bert  : 1.140050377833753e-08\n",
      "lr cri   : 3.7481108312342564e-05\n",
      "lr others: 3.029722921914357e-07\n",
      "Train epoch = 0.5289672544080605, loss = 20.427753448486328, policy = 0.17648263275623322, entropy_loss = -0.00263412669301033, gae = 17.37928581237793, kl_div = 0.07602039724588394, reward = 4.741064071655273, ord = 7.087396621704102, repeat = -3.6157946586608887, length = -0.2621535062789917, adv = 1.1870942115783691, rougeL = 1.3323779106140137, cider = 0.20674552023410797, clip = 0.39768317341804504, crf = 1.0544209480285645, ce = 1.7441776990890503, unr = 1.5316165685653687, ber = 5.653834342956543\n",
      "refe: [CLS] in this image there is a girl wearing orange jacket. here there is a cloth. on the ground there are plastic cups. in the background there is wall, frame. this is a chair. [SEP]\n",
      "hypo: [CLS] in the center of the image there is a girl who is standing and behind the background there is a wall. [SEP]\n",
      "samp: [CLS] in this image i can see a girl wearing t - shirt. at the background i can see a cupboard. [SEP]\n",
      "lr con   : 7.944584382871536e-11\n",
      "lr bert  : 1.048110831234257e-08\n",
      "lr cri   : 3.4458438287153655e-05\n",
      "lr others: 2.785390428211587e-07\n",
      "Train epoch = 0.5667506297229219, loss = 20.537919998168945, policy = 0.1707247495651245, entropy_loss = -0.0026151074562221766, gae = 17.489952087402344, kl_div = 0.07615352421998978, reward = 4.7945170402526855, ord = 7.093445301055908, repeat = -3.57824444770813, length = -0.25938236713409424, adv = 1.1893622875213623, rougeL = 1.3371500968933105, cider = 0.2067652940750122, clip = 0.3977830708026886, crf = 1.0651990175247192, ce = 1.7385075092315674, unr = 1.5386993885040283, ber = 5.654935836791992\n",
      "refe: [CLS] in this image i can see a girl is sitting, she is wearing trouser, sweater, spectacles. in the background there is the children play equipment and there are trees, at the top there is the sky. [SEP]\n",
      "hypo: [CLS] in this image i can see a boy sitting on the swing we can also there is a fence, there is a fence, there is a fence, there is a sky. [SEP]\n",
      "samp: [CLS] in this picture, we can see a person is a red color t - shirt. there is a fence, there is a fence, behind the background there is a building. [SEP]\n",
      "lr con   : 7.24769101595298e-11\n",
      "lr bert  : 9.561712846347607e-09\n",
      "lr cri   : 3.143576826196473e-05\n",
      "lr others: 2.541057934508816e-07\n",
      "Train epoch = 0.6045340050377834, loss = 20.417367935180664, policy = 0.16602422297000885, entropy_loss = -0.002613948890939355, gae = 17.36554527282715, kl_div = 0.07652627676725388, reward = 4.792508125305176, ord = 7.092788219451904, repeat = -3.582613468170166, length = -0.258660227060318, adv = 1.181087613105774, rougeL = 1.3382686376571655, cider = 0.20400941371917725, clip = 0.3977980613708496, crf = 1.0697617530822754, ce = 1.7421236038208008, unr = 1.540994644165039, ber = 5.655226230621338\n",
      "refe: [CLS] in this picture we can see board and cloth on a stroller. we can see legs of people on the ground. [SEP]\n",
      "hypo: [CLS] in this picture we can see a person sitting on the road. [SEP]\n",
      "samp: [CLS] in this picture we can see a person sitting on the middle of the right side of the left side of people standing. [SEP]\n",
      "lr con   : 6.550797649034425e-11\n",
      "lr bert  : 8.642317380352645e-09\n",
      "lr cri   : 2.8413098236775818e-05\n",
      "lr others: 2.2967254408060454e-07\n",
      "Train epoch = 0.6423173803526449, loss = 20.320289611816406, policy = 0.16959823668003082, entropy_loss = -0.002611872274428606, gae = 17.25406837463379, kl_div = 0.07679074257612228, reward = 4.794206619262695, ord = 7.090266227722168, repeat = -3.5787129402160645, length = -0.25911587476730347, adv = 1.1738452911376953, rougeL = 1.338355541229248, cider = 0.20323508977890015, clip = 0.3977779150009155, crf = 1.075467824935913, ce = 1.7469761371612549, unr = 1.5417709350585938, ber = 5.6545209884643555\n",
      "refe: [CLS] in this image are four persons who are sitting on chairs and there is one cupboard beside them. on that cupboard there are some books, bottles, cloth, and some objects are there on the table and on top there is one glass window and some trees are there on the background. and in the center there is another table on that table there are two laptops and some books and papers are there and on the floor there are some bags. [SEP]\n",
      "hypo: [CLS] in this image i can see group of people sitting on the chair. on the table. in front. on the table\n",
      "samp: [CLS] in this image we can see group of people are sitting on the chairs and the table and there is a table\n",
      "lr con   : 5.853904282115869e-11\n",
      "lr bert  : 7.722921914357682e-09\n",
      "lr cri   : 2.5390428211586902e-05\n",
      "lr others: 2.0523929471032745e-07\n",
      "Train epoch = 0.6801007556675063, loss = 20.359827041625977, policy = 0.1677490621805191, entropy_loss = -0.002597157610580325, gae = 17.284292221069336, kl_div = 0.07693284004926682, reward = 4.823049068450928, ord = 7.090943336486816, repeat = -3.5557568073272705, length = -0.2580246925354004, adv = 1.1724592447280884, rougeL = 1.341299057006836, cider = 0.2026066929101944, clip = 0.39782723784446716, crf = 1.0875564813613892, ce = 1.7458951473236084, unr = 1.5458879470825195, ber = 5.655477523803711\n",
      "refe: [CLS] in the foreground of this image, there are two men and a man is wearing a headset. in the background, there is a sculpture, few objects, lights, bottles, two people standing and arches to the wall and we can also see a chandelier at the top. [SEP]\n",
      "hypo: [CLS] in this image we can see two persons wearing a man standing and smiling and goggles. in the right side of the right side there are lights. [SEP]\n",
      "samp: [CLS] in this picture we can see a person is a man standing and smiling and goggles and smiling. in - shirt, we can see few people. [SEP]\n",
      "lr con   : 5.157010915197313e-11\n",
      "lr bert  : 6.8035264483627206e-09\n",
      "lr cri   : 2.2367758186397984e-05\n",
      "lr others: 1.8080604534005037e-07\n",
      "Train epoch = 0.7178841309823678, loss = 20.33115005493164, policy = 0.1624998152256012, entropy_loss = -0.002585721667855978, gae = 17.254413604736328, kl_div = 0.07684696465730667, reward = 4.836945533752441, ord = 7.09434175491333, repeat = -3.5482354164123535, length = -0.2575029730796814, adv = 1.1684463024139404, rougeL = 1.3436882495880127, cider = 0.2048124372959137, clip = 0.3977329134941101, crf = 1.0969535112380981, ce = 1.7430225610733032, unr = 1.5483424663543701, ber = 5.655416488647461\n",
      "refe: [CLS] in the foreground of this picture, there is a man standing and wearing a bag pack. in the background, there are persons standing and wearing backpacks and few of them are covers with covers over their heads, stairs, a vehicle, building, trees and the sky. [SEP]\n",
      "hypo: [CLS] in this image i can see a group of people standing. on the right side, we can see the background, trees. in the building. [SEP]\n",
      "samp: [CLS] in this image i can see a group of people standing. in front i can see few trees, we can see some trees. in the building. [SEP]\n",
      "lr con   : 4.460117548278757e-11\n",
      "lr bert  : 5.884130982367758e-09\n",
      "lr cri   : 1.9345088161209068e-05\n",
      "lr others: 1.563727959697733e-07\n",
      "Train epoch = 0.7556675062972292, loss = 20.27224349975586, policy = 0.1658875048160553, entropy_loss = -0.0025816992856562138, gae = 17.197690963745117, kl_div = 0.07693435251712799, reward = 4.845388412475586, ord = 7.097357273101807, repeat = -3.5467476844787598, length = -0.25502294301986694, adv = 1.1635569334030151, rougeL = 1.344780683517456, cider = 0.2051437497138977, clip = 0.3979138135910034, crf = 1.0947469472885132, ce = 1.7395645380020142, unr = 1.5498026609420776, ber = 5.656248569488525\n",
      "refe: [CLS] in this picture i can see few people standing in the ground and few boys are holding banners with some text and a flag, i can see audience few are seated and few are standing and i can see few of them holding flags in their hands and i can see few camera men on the right side. [SEP]\n",
      "hypo: [CLS] in this picture we can see a group of people, we can also there are standing and i can see a person. [SEP]\n",
      "samp: [CLS] in this picture we can see the group of people standing. behind there are few people are few people standing. [SEP]\n",
      "lr con   : 3.7632241813602014e-11\n",
      "lr bert  : 4.964735516372796e-09\n",
      "lr cri   : 1.632241813602015e-05\n",
      "lr others: 1.3193954659949622e-07\n",
      "Train epoch = 0.7934508816120907, loss = 20.279420852661133, policy = 0.16077828407287598, entropy_loss = -0.002567446790635586, gae = 17.20541000366211, kl_div = 0.07689937949180603, reward = 4.867339611053467, ord = 7.098515510559082, repeat = -3.5302305221557617, length = -0.25436702370643616, adv = 1.1617906093597412, rougeL = 1.346374750137329, cider = 0.20597213506698608, clip = 0.398281991481781, crf = 1.102357029914856, ce = 1.73654305934906, unr = 1.553422212600708, ber = 5.65624475479126\n",
      "refe: [CLS] in this image in the center there is water. in the background there are trees and there's grass on the ground and there is a house. [SEP]\n",
      "hypo: [CLS] in this image, we can see a bridge, water, there is a water and the sky. on the sky. [SEP]\n",
      "samp: [CLS] in the image, we can see a bridge and water, trees. [SEP] on the sky. on the sky. [SEP]\n",
      "lr con   : 3.066330814441645e-11\n",
      "lr bert  : 4.045340050377834e-09\n",
      "lr cri   : 1.3299748110831234e-05\n",
      "lr others: 1.0750629722921913e-07\n",
      "Train epoch = 0.8312342569269522, loss = 20.27245330810547, policy = 0.15770982205867767, entropy_loss = -0.0025646821595728397, gae = 17.20467185974121, kl_div = 0.07694785296916962, reward = 4.8837409019470215, ord = 7.103257179260254, repeat = -3.5219738483428955, length = -0.25297367572784424, adv = 1.1590726375579834, rougeL = 1.3476229906082153, cider = 0.20572221279144287, clip = 0.39859047532081604, crf = 1.1007739305496216, ce = 1.7349148988723755, unr = 1.5554317235946655, ber = 5.657134056091309\n",
      "refe: [CLS] in this picture we can see houses with windows, tables, flags, ladders, gate and in the background we can see the sky. [SEP]\n",
      "hypo: [CLS] in this picture we can see a building with the chairs, plants, plants, plants, plants, we can see the right side of the sky. in the sky. [SEP]\n",
      "samp: [CLS] in this picture we can see a balconys, plants, plants, plants, plants, plants, we can see the right side of the chairs on the right side there is a fence. [SEP]\n",
      "lr con   : 2.3694374475230897e-11\n",
      "lr bert  : 3.1259445843828713e-09\n",
      "lr cri   : 1.0277078085642317e-05\n",
      "lr others: 8.307304785894206e-08\n",
      "Train epoch = 0.8690176322418136, loss = 20.247852325439453, policy = 0.1538742333650589, entropy_loss = -0.0025608669966459274, gae = 17.186525344848633, kl_div = 0.07700782269239426, reward = 4.898948669433594, ord = 7.103178024291992, repeat = -3.510957717895508, length = -0.2508017122745514, adv = 1.1563798189163208, rougeL = 1.3484224081039429, cider = 0.20574244856834412, clip = 0.3988341689109802, crf = 1.0996469259262085, ce = 1.7333582639694214, unr = 1.5575300455093384, ber = 5.6570143699646\n",
      "refe: [CLS] in this image, we can see some horses and there are some people riding the horses, at the right side there is a car parked, we can see some green trees and there is a house. [SEP]\n",
      "hypo: [CLS] in this picture there are three people sitting on the road. i can see a road. on the background there is sitting on the background i can see trees. [SEP]\n",
      "samp: [CLS] in this picture there are three people on the road. in the left side of the horse on the background i can see a woman standing on the background i can see a black color. [SEP]\n",
      "lr con   : 1.6725440806045338e-11\n",
      "lr bert  : 2.206549118387909e-09\n",
      "lr cri   : 7.2544080604534e-06\n",
      "lr others: 5.863979848866498e-08\n",
      "Train epoch = 0.906801007556675, loss = 20.131996154785156, policy = 0.15234868228435516, entropy_loss = -0.0025625089183449745, gae = 17.06725311279297, kl_div = 0.07729599624872208, reward = 4.890327453613281, ord = 7.101503849029541, repeat = -3.5173256397247314, length = -0.2511206865310669, adv = 1.1494288444519043, rougeL = 1.3466614484786987, cider = 0.20494650304317474, clip = 0.3989455997943878, crf = 1.1021795272827148, ce = 1.735480546951294, unr = 1.55726957321167, ber = 5.656482219696045\n",
      "refe: [CLS] in this image there is a plant truncated towards the top of the image, there is a bird, there is an object truncated towards the bottom of the image, the background of the image is blurred. [SEP]\n",
      "hypo: [CLS] in this image we can see a bird on the branch\n",
      "samp: [CLS] in this picture we can see a bird on the grass. [SEP]\n",
      "lr con   : 9.75650713685978e-12\n",
      "lr bert  : 1.287153652392947e-09\n",
      "lr cri   : 4.231738035264483e-06\n",
      "lr others: 3.4206549118387904e-08\n",
      "Train epoch = 0.9445843828715366, loss = 20.114320755004883, policy = 0.14883390069007874, entropy_loss = -0.0025552960578352213, gae = 17.045886993408203, kl_div = 0.077517069876194, reward = 4.901004791259766, ord = 7.102777004241943, repeat = -3.5111536979675293, length = -0.24950508773326874, adv = 1.146654486656189, rougeL = 1.3465156555175781, cider = 0.20533500611782074, clip = 0.39879241585731506, crf = 1.1092250347137451, ce = 1.7354122400283813, unr = 1.5588866472244263, ber = 5.654921531677246\n",
      "refe: [CLS] in the center of the image we can see one woman is standing and she is smiling, which we can see on her face. and we can see she is wearing a backpack, which is in blue color. in the background we can see a few people are standing, two persons are wearing caps and a few other objects. [SEP]\n",
      "hypo: [CLS] in this image there is a woman. [SEP]\n",
      "samp: [CLS] in the image there is a woman is a woman is smiling. [SEP]\n",
      "lr con   : 2.787573467674223e-12\n",
      "lr bert  : 3.677581863979849e-10\n",
      "lr cri   : 1.2090680100755668e-06\n",
      "lr others: 9.773299748110832e-09\n",
      "Train epoch = 0.982367758186398, loss = 20.08819580078125, policy = 0.14549696445465088, entropy_loss = -0.0025469474494457245, gae = 17.01572608947754, kl_div = 0.0775587260723114, reward = 4.910120010375977, ord = 7.104248046875, repeat = -3.504309892654419, length = -0.2496565282344818, adv = 1.1439979076385498, rougeL = 1.3475911617279053, cider = 0.20696693658828735, clip = 0.398786723613739, crf = 1.1166269779205322, ce = 1.7353343963623047, unr = 1.559838891029358, ber = 5.655519962310791\n",
      "refe: [CLS] in this image we can see two women standing on the ground. in the background we can see group of trees, buildings, a person and sky. [SEP]\n",
      "hypo: [CLS] in this image i can see a person is a woman, there is a group of people walking on the background there are trees. in the sky. [SEP]\n",
      "samp: [CLS] in this image we can see a person is a woman and there is a road. we can see plants. in the sky. in the image there are trees. on the sky. [SEP]\n",
      "bsz 56 is not batch_size 128. skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 04:01:50,159] Trial 1 finished with value: 1.5319545269012451 and parameters: {'config.betas': 1, 'config.len_coef': 4.89637884624154, 'config.unr_coef': 2.4844571089669905, 'config.crf_coef': 0.8241203992806698, 'config.ce_coef': 0.8486986047824512, 'config.gae_coef': 3.8415729582465277, 'config.clip_range': 0.26827004328509585, 'clip_grad_threshold': 0.3991059977403756}. Best is trial 0 with value: 1.5353256464004517.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, avg_reward = 1.5319545269012451\n",
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.13822635653670384\n",
      "clip_grad_threshold gradient norm: 1.660771538904844\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.8243974872273343\n",
      "unr_coef: 1.475783929127104\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.8324272226514612\n",
      "ce_coef: 0.02642922773328238\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 0.11384604718772118\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_040203.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21862d7f5f0439691080aa9f757745f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 1.0347145795822144, policy = 1.7205463720415537e-08, entropy_loss = -0.0028857355937361717, gae = 0.20732854306697845, kl_div = 0.08355899900197983, reward = 2.9679689407348633, ord = 6.904253005981445, repeat = -4.657747745513916, length = -0.13877169787883759, adv = 0.6351703405380249, rougeL = 1.2061352729797363, cider = 0.21346385776996613, clip = 0.4090528190135956, crf = 0.6917106509208679, ce = 0.05500210449099541, unr = 0.8602359294891357, ber = 5.658883571624756\n",
      "refe: [CLS] in this image i see a cycle and i see there are few plants over here and it is totally green in the background. [SEP]\n",
      "hypo: [CLS] in the center of the image there is a bicycle. i can see the background there are trees. [SEP]\n",
      "samp: [CLS] in the middle of the image there is a bicycle. there is a tree. in front of the background there is blurred. [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 1.3155124187469482, policy = 0.05900387093424797, entropy_loss = -0.002645813627168536, gae = 0.3047311007976532, kl_div = 0.08067285269498825, reward = 3.9128928184509277, ord = 6.991428852081299, repeat = -3.796046733856201, length = -0.1856505274772644, adv = 0.8185303211212158, rougeL = 1.299431562423706, cider = 0.19375079870224, clip = 0.4091285467147827, crf = 0.8193440437316895, ce = 0.054406337440013885, unr = 0.9031614661216736, ber = 5.6414947509765625\n",
      "refe: [CLS] in this picture we can see so many people are standing and watching, few people are doing cycling on a slope thing, around we can see fencing, behind we can see vehicles and some grass. [SEP]\n",
      "hypo: [CLS] in this image i can see a group of people standing. in the foreground of them there are some people standing. [SEP]\n",
      "samp: [CLS] in this picture we can see people, at the foreground of the foreground of them there are some barricades and there are so many people. [SEP]\n",
      "lr con   : 1.2962216624685136e-10\n",
      "lr bert  : 1.7100755667506296e-08\n",
      "lr cri   : 5.622166246851385e-05\n",
      "lr others: 4.544584382871536e-07\n",
      "Train epoch = 0.07556675062972293, loss = 1.539023756980896, policy = 0.18024025857448578, entropy_loss = -0.002601498970761895, gae = 0.30116087198257446, kl_div = 0.07992292940616608, reward = 3.8898520469665527, ord = 7.02834415435791, repeat = -3.8476860523223877, length = -0.18820352852344513, adv = 0.8076982498168945, rougeL = 1.3102859258651733, cider = 0.21392247080802917, clip = 0.4073821008205414, crf = 0.9259642958641052, ce = 0.05433692783117294, unr = 0.8973971009254456, ber = 5.64627742767334\n",
      "refe: [CLS] in this image we can see a person wearing black color suit, bracelet keeping his hand on the designed sheet on which it is written as help me. [SEP]\n",
      "hypo: [CLS] in this image we can see a person standing. in the wall. in the back there is a wall. [SEP]\n",
      "samp: [CLS] in the center of the image there is a person wearing clothes and there is a wall. [SEP] pant. [SEP]\n",
      "lr con   : 1.6307304785894207e-10\n",
      "lr bert  : 2.1513853904282117e-08\n",
      "lr cri   : 7.073047858942065e-05\n",
      "lr others: 5.717380352644836e-07\n",
      "Train epoch = 0.11335012594458438, loss = 1.5129015445709229, policy = 0.272264301776886, entropy_loss = -0.0026142180431634188, gae = 0.2800504267215729, kl_div = 0.08198519051074982, reward = 3.740356922149658, ord = 7.007723808288574, repeat = -3.983250856399536, length = -0.17159093916416168, adv = 0.7738171815872192, rougeL = 1.2874852418899536, cider = 0.21950188279151917, clip = 0.4074923098087311, crf = 0.8276101350784302, ce = 0.05360572785139084, unr = 0.8874747157096863, ber = 5.644985675811768\n",
      "refe: [CLS] as we can see in the image there is a mic, banner and a woman wearing red color jacket. the background is dark. [SEP]\n",
      "hypo: [CLS] in this image i can see a woman in the front of the bottom of the front of the podium, we can see a microphone. [SEP]\n",
      "samp: [CLS] in this image we can see a lady a woman standing near a podium. in front of the podium with the podium. behind her hand of the background. [SEP]\n",
      "lr con   : 1.561041141897565e-10\n",
      "lr bert  : 2.0594458438287153e-08\n",
      "lr cri   : 6.770780856423173e-05\n",
      "lr others: 5.473047858942065e-07\n",
      "Train epoch = 0.15113350125944586, loss = 1.5754643678665161, policy = 0.27188241481781006, entropy_loss = -0.002577123697847128, gae = 0.2957136332988739, kl_div = 0.08222880959510803, reward = 3.8935232162475586, ord = 7.021578788757324, repeat = -3.851513385772705, length = -0.17215944826602936, adv = 0.7954080104827881, rougeL = 1.2986928224563599, cider = 0.2229824662208557, clip = 0.4073984920978546, crf = 0.8745942711830139, ce = 0.0536225289106369, unr = 0.8956169486045837, ber = 5.647485733032227\n",
      "refe: [CLS] in this image there is a building, windows, lights, statue and objects. [SEP]\n",
      "hypo: [CLS] in the center of the image there is a glass window and some text. [SEP]\n",
      "samp: [CLS] in the center of the image there is a building with window. [SEP]\n",
      "lr con   : 1.4913518052057094e-10\n",
      "lr bert  : 1.9675062972292192e-08\n",
      "lr cri   : 6.468513853904282e-05\n",
      "lr others: 5.228715365239295e-07\n",
      "Train epoch = 0.1889168765743073, loss = 1.5801241397857666, policy = 0.2928839325904846, entropy_loss = -0.0025603913236409426, gae = 0.297687292098999, kl_div = 0.08280092477798462, reward = 3.9298226833343506, ord = 7.029115200042725, repeat = -3.8365564346313477, length = -0.1670856922864914, adv = 0.7949037551879883, rougeL = 1.2889947891235352, cider = 0.22468121349811554, clip = 0.40686866641044617, crf = 0.8561949729919434, ce = 0.05311749875545502, unr = 0.9043505191802979, ber = 5.651422023773193\n",
      "refe: [CLS] in the center of the image we can see the vintage doll carriage is present on the surface. [SEP]\n",
      "hypo: [CLS] in this image we can see a toy on the surface. [SEP]\n",
      "samp: [CLS] in this picture we can see a toy on which there is made up\n",
      "lr con   : 1.4216624685138537e-10\n",
      "lr bert  : 1.8755667506297228e-08\n",
      "lr cri   : 6.16624685138539e-05\n",
      "lr others: 4.984382871536523e-07\n",
      "Train epoch = 0.22670025188916876, loss = 1.550520896911621, policy = 0.26737844944000244, entropy_loss = -0.0025569815188646317, gae = 0.29547038674354553, kl_div = 0.08295279741287231, reward = 3.9221298694610596, ord = 7.033043384552002, repeat = -3.8474273681640625, length = -0.16525354981422424, adv = 0.7857126593589783, rougeL = 1.291337013244629, cider = 0.23102444410324097, clip = 0.407247930765152, crf = 0.8542326092720032, ce = 0.05304376035928726, unr = 0.901768147945404, ber = 5.653783321380615\n",
      "refe: [CLS] we can see plants and grass. background we can see trees and sky is cloudy. [SEP]\n",
      "hypo: [CLS] in the foreground of this image, plants, hills and the background we can see the sky. [SEP]\n",
      "samp: [CLS] in the foreground of this image, plants, we can see the background we can see the background. [SEP]\n",
      "lr con   : 1.3519731318219982e-10\n",
      "lr bert  : 1.7836272040302267e-08\n",
      "lr cri   : 5.863979848866499e-05\n",
      "lr others: 4.740050377833753e-07\n",
      "Train epoch = 0.26448362720403024, loss = 1.568078637123108, policy = 0.24909768998622894, entropy_loss = -0.0025482019409537315, gae = 0.29892781376838684, kl_div = 0.08202417194843292, reward = 3.9629011154174805, ord = 7.025613307952881, repeat = -3.7950098514556885, length = -0.1733980029821396, adv = 0.7854613661766052, rougeL = 1.2918140888214111, cider = 0.22235475480556488, clip = 0.4067084491252899, crf = 0.887211799621582, ce = 0.05336533859372139, unr = 0.9056957364082336, ber = 5.6488847732543945\n",
      "refe: [CLS] there are two women standing. this woman is holding a mike and a paper in her hands. i can see a person holding a mike and sitting on the chair. this looks like a banner. [SEP]\n",
      "hypo: [CLS] in this image i can see a group of people. here we can see the front of them we can see standing on the background we can see the background we can see [SEP]\n",
      "samp: [CLS] in this picture we can see a woman is a woman standing and i can see two persons standing on the background i can see the background we can see the background we can see a screen and we can see one\n",
      "lr con   : 1.2822837951301427e-10\n",
      "lr bert  : 1.6916876574307306e-08\n",
      "lr cri   : 5.561712846347607e-05\n",
      "lr others: 4.495717884130982e-07\n",
      "Train epoch = 0.3022670025188917, loss = 1.5802143812179565, policy = 0.2356211096048355, entropy_loss = -0.002532689366489649, gae = 0.30133458971977234, kl_div = 0.08166183531284332, reward = 4.01060676574707, ord = 7.027735710144043, repeat = -3.750600576400757, length = -0.17508207261562347, adv = 0.7867515683174133, rougeL = 1.2973626852035522, cider = 0.21406930685043335, clip = 0.4064241051673889, crf = 0.9106204509735107, ce = 0.05350923910737038, unr = 0.9085545539855957, ber = 5.646327018737793\n",
      "refe: [CLS] this image consists of few persons sitting in the chairs. at the bottom, there is a table on which there are glasses and mug. in the background, we can see a wall and a door. [SEP]\n",
      "hypo: [CLS] in this image we can see few people are sitting on the table and there is a table there is a table there is a table. [SEP]\n",
      "samp: [CLS] in this image there are two persons sitting on the table on the table there is a table i can see the background i can see the background there is a black color. [SEP]\n",
      "lr con   : 1.2125944584382872e-10\n",
      "lr bert  : 1.5997481108312342e-08\n",
      "lr cri   : 5.2594458438287154e-05\n",
      "lr others: 4.2513853904282117e-07\n",
      "Train epoch = 0.34005037783375314, loss = 1.5944621562957764, policy = 0.22527514398097992, entropy_loss = -0.0025282849092036486, gae = 0.303504079580307, kl_div = 0.08161500841379166, reward = 4.05129861831665, ord = 7.026691436767578, repeat = -3.7109532356262207, length = -0.17681826651096344, adv = 0.7865318655967712, rougeL = 1.3010950088500977, cider = 0.21219170093536377, clip = 0.4056214690208435, crf = 0.9328246116638184, ce = 0.053771644830703735, unr = 0.9123793840408325, ber = 5.643721103668213\n",
      "refe: [CLS] at the bottom of the image we can see two people sitting on the floor. there is a mat. on the left we can see a person and a bag. in the background there is a wall, curtain and trees. [SEP]\n",
      "hypo: [CLS] in this image there are three people are sitting on the ground. on the right side there is sitting on the right side there are trees. [SEP]\n",
      "samp: [CLS] in this picture, we can see a boy sitting on the sitting on the right side there is sitting on the left side there are few objects. [SEP] on the ground. [SEP]\n",
      "lr con   : 1.1429051217464315e-10\n",
      "lr bert  : 1.507808564231738e-08\n",
      "lr cri   : 4.957178841309823e-05\n",
      "lr others: 4.0070528967254406e-07\n",
      "Train epoch = 0.3778337531486146, loss = 1.5875718593597412, policy = 0.22558501362800598, entropy_loss = -0.0025278811808675528, gae = 0.3032068908214569, kl_div = 0.08163487166166306, reward = 4.0704026222229, ord = 7.032235622406006, repeat = -3.7010719776153564, length = -0.17664648592472076, adv = 0.7824003100395203, rougeL = 1.3049588203430176, cider = 0.20778614282608032, clip = 0.4056697487831116, crf = 0.9259031414985657, ce = 0.053769953548908234, unr = 0.9158862233161926, ber = 5.644443511962891\n",
      "refe: [CLS] in this picture there is a person standing and holding the bag. at the back there are trees. at the bottom there are coconuts and stones on the sand. [SEP]\n",
      "hypo: [CLS] in this image we can see a person wearing clothes and there is a person in the background there are plants. [SEP]\n",
      "samp: [CLS] in this picture we can see a person standing and i can see a person in the background there are plants. [SEP]\n",
      "lr con   : 1.073215785054576e-10\n",
      "lr bert  : 1.4158690176322418e-08\n",
      "lr cri   : 4.654911838790932e-05\n",
      "lr others: 3.76272040302267e-07\n",
      "Train epoch = 0.4156171284634761, loss = 1.630078673362732, policy = 0.23106685280799866, entropy_loss = -0.0025116954930126667, gae = 0.30665943026542664, kl_div = 0.08104593306779861, reward = 4.1159234046936035, ord = 7.032459259033203, repeat = -3.654447555541992, length = -0.1810068041086197, adv = 0.7835759520530701, rougeL = 1.3119257688522339, cider = 0.20342908799648285, clip = 0.4052630364894867, crf = 0.9597872495651245, ce = 0.05403095856308937, unr = 0.9189183712005615, ber = 5.642998695373535\n",
      "refe: [CLS] in this image we can see a car on the grass. [SEP]\n",
      "hypo: [CLS] in this image i can see a car on the road. [SEP]\n",
      "samp: [CLS] in this image i can see a car on the road. [SEP]\n",
      "lr con   : 1.0035264483627203e-10\n",
      "lr bert  : 1.3239294710327456e-08\n",
      "lr cri   : 4.35264483627204e-05\n",
      "lr others: 3.518387909319899e-07\n",
      "Train epoch = 0.4534005037783375, loss = 1.6267131567001343, policy = 0.21886010468006134, entropy_loss = -0.0025065410882234573, gae = 0.3052247166633606, kl_div = 0.08074604719877243, reward = 4.118723392486572, ord = 7.034580707550049, repeat = -3.6490015983581543, length = -0.18539109826087952, adv = 0.7769662737846375, rougeL = 1.313942790031433, cider = 0.20518963038921356, clip = 0.4053047299385071, crf = 0.9702776074409485, ce = 0.0541113056242466, unr = 0.9185363054275513, ber = 5.644744873046875\n",
      "refe: [CLS] in this image there is a beach, in that beach there are people are standing, few are lying on chairs and there are umbrellas, tent and the sea. [SEP]\n",
      "hypo: [CLS] in this image we can see few people sitting on the beach. in the image there are few people. [SEP]op there are few people. [SEP]\n",
      "samp: [CLS] in this image i can see people, we can see the umbrellas, i can also we can see some umbrellas, there is a beach. [SEP] shore. [SEP]\n",
      "lr con   : 9.338371116708649e-11\n",
      "lr bert  : 1.2319899244332495e-08\n",
      "lr cri   : 4.0503778337531486e-05\n",
      "lr others: 3.2740554156171283e-07\n",
      "Train epoch = 0.491183879093199, loss = 1.609474539756775, policy = 0.22517342865467072, entropy_loss = -0.0025216159410774708, gae = 0.3041549623012543, kl_div = 0.08101820945739746, reward = 4.1248860359191895, ord = 7.036070823669434, repeat = -3.6457080841064453, length = -0.18520352244377136, adv = 0.7712023854255676, rougeL = 1.313126802444458, cider = 0.20731642842292786, clip = 0.4053121507167816, crf = 0.9475218653678894, ce = 0.05412774533033371, unr = 0.9197260737419128, ber = 5.645370006561279\n",
      "refe: [CLS] in the foreground i can see a person is sitting on the chair and is playing a musical instrument and a stand. in the background i can see three persons are standing on the floor, posters, wall, door, table and a rooftop. this image is taken may be in a hall. [SEP]\n",
      "hypo: [CLS] in this image we can see a person is a chair and a chair and playing guitar. in front of him there is standing. [SEP]\n",
      "samp: [CLS] in this image i can see a person is a chair and holding a chair and playing musical instrument. [SEP] in front of him there is a chair and there is a chair. [SEP]. [SEP]\n",
      "lr con   : 8.641477749790091e-11\n",
      "lr bert  : 1.140050377833753e-08\n",
      "lr cri   : 3.7481108312342564e-05\n",
      "lr others: 3.029722921914357e-07\n",
      "Train epoch = 0.5289672544080605, loss = 1.6224242448806763, policy = 0.21321327984333038, entropy_loss = -0.0025079266633838415, gae = 0.307981938123703, kl_div = 0.08063273131847382, reward = 4.173089504241943, ord = 7.041595935821533, repeat = -3.6034395694732666, length = -0.18773679435253143, adv = 0.7736417055130005, rougeL = 1.3177381753921509, cider = 0.21053212881088257, clip = 0.4049883484840393, crf = 0.9690039157867432, ce = 0.05410031974315643, unr = 0.9226700663566589, ber = 5.64557409286499\n",
      "refe: [CLS] in this picture i can see rocks, trees and grass. in the background i can see water and the sky. [SEP]\n",
      "hypo: [CLS] in this image we can see there is a rock. at the background i can see water. [SEP]\n",
      "samp: [CLS] in this picture we can see water, there are trees, stones. at the background we can see the background we can see the sky. [SEP]\n",
      "lr con   : 7.944584382871536e-11\n",
      "lr bert  : 1.048110831234257e-08\n",
      "lr cri   : 3.4458438287153655e-05\n",
      "lr others: 2.785390428211587e-07\n",
      "Train epoch = 0.5667506297229219, loss = 1.6292107105255127, policy = 0.21699635684490204, entropy_loss = -0.0025043722707778215, gae = 0.30634573101997375, kl_div = 0.08074158430099487, reward = 4.175356388092041, ord = 7.0430006980896, repeat = -3.603245258331299, length = -0.1863652467727661, adv = 0.7676612138748169, rougeL = 1.3190048933029175, cider = 0.21093882620334625, clip = 0.4048265516757965, crf = 0.9736214280128479, ce = 0.054010141640901566, unr = 0.9219653010368347, ber = 5.64643669128418\n",
      "refe: [CLS] there is a compartment and it has two windows on the either side and in front of the compartment there are two plants. [SEP]\n",
      "hypo: [CLS] in this image we can see a door and a board and we can see a board there is a board. [SEP]\n",
      "samp: [CLS] in this picture we can see a board and some text and we can see a wall. we can see some text on the sky. [SEP]\n",
      "lr con   : 7.24769101595298e-11\n",
      "lr bert  : 9.561712846347607e-09\n",
      "lr cri   : 3.143576826196473e-05\n",
      "lr others: 2.541057934508816e-07\n",
      "Train epoch = 0.6045340050377834, loss = 1.6266037225723267, policy = 0.2088487148284912, entropy_loss = -0.0024997303262352943, gae = 0.30639562010765076, kl_div = 0.0805465430021286, reward = 4.195254802703857, ord = 7.044439792633057, repeat = -3.585973024368286, length = -0.1866033673286438, adv = 0.7652267217636108, rougeL = 1.319587230682373, cider = 0.2099626362323761, clip = 0.4046528935432434, crf = 0.9793359637260437, ce = 0.053976599127054214, unr = 0.9233912825584412, ber = 5.645910263061523\n",
      "refe: [CLS] in this image in front there are four people wearing a smile on their faces. in the background of the image there are lights. [SEP]\n",
      "hypo: [CLS] in this image, we can see a group of the background. in the background, we can see the left side. [SEP]\n",
      "samp: [CLS] in this picture, we can see a group of the image there are smiling. at the background, we can see a black color t - shirt. [SEP]\n",
      "lr con   : 6.550797649034425e-11\n",
      "lr bert  : 8.642317380352645e-09\n",
      "lr cri   : 2.8413098236775818e-05\n",
      "lr others: 2.2967254408060454e-07\n",
      "Train epoch = 0.6423173803526449, loss = 1.6128771305084229, policy = 0.20408707857131958, entropy_loss = -0.00250821840018034, gae = 0.30208587646484375, kl_div = 0.08070222288370132, reward = 4.165802478790283, ord = 7.0458502769470215, repeat = -3.614727258682251, length = -0.18544793128967285, adv = 0.7538195252418518, rougeL = 1.3174011707305908, cider = 0.21122847497463226, clip = 0.4046880304813385, crf = 0.9744546413421631, ce = 0.05405566841363907, unr = 0.9201279878616333, ber = 5.646890640258789\n",
      "refe: [CLS] in the image we can see a woman wearing clothes and holding a camera in hand. this is a floor. [SEP]\n",
      "hypo: [CLS] in this image we can see a person's. [SEP]\n",
      "samp: [CLS] in this image i can see a person's. [SEP]\n",
      "lr con   : 5.853904282115869e-11\n",
      "lr bert  : 7.722921914357682e-09\n",
      "lr cri   : 2.5390428211586902e-05\n",
      "lr others: 2.0523929471032745e-07\n",
      "Train epoch = 0.6801007556675063, loss = 1.6146178245544434, policy = 0.20156201720237732, entropy_loss = -0.002507550409063697, gae = 0.3029656410217285, kl_div = 0.0801507830619812, reward = 4.183988094329834, ord = 7.049177646636963, repeat = -3.599769353866577, length = -0.18640755116939545, adv = 0.751721978187561, rougeL = 1.3226895332336426, cider = 0.2108708918094635, clip = 0.40460124611854553, crf = 0.9784058332443237, ce = 0.05404115840792656, unr = 0.9209874272346497, ber = 5.647763729095459\n",
      "refe: [CLS] here i can see a bee on a flower. the petals are in pink and yellow colors. the background is blurred. [SEP]\n",
      "hypo: [CLS] in this image we can see a flower is a flower. on the flower. [SEP]\n",
      "samp: [CLS] in the image we can see a flower is a flower. at the background there is a dragon\n",
      "lr con   : 5.157010915197313e-11\n",
      "lr bert  : 6.8035264483627206e-09\n",
      "lr cri   : 2.2367758186397984e-05\n",
      "lr others: 1.8080604534005037e-07\n",
      "Train epoch = 0.7178841309823678, loss = 1.599932074546814, policy = 0.19832900166511536, entropy_loss = -0.002518847119063139, gae = 0.29785048961639404, kl_div = 0.0803893581032753, reward = 4.145450592041016, ord = 7.04858922958374, repeat = -3.6364691257476807, length = -0.1842956691980362, adv = 0.7394090294837952, rougeL = 1.3203316926956177, cider = 0.21266935765743256, clip = 0.40471822023391724, crf = 0.9718771576881409, ce = 0.0540047250688076, unr = 0.9176255464553833, ber = 5.648702621459961\n",
      "refe: [CLS] in this image i can see few plants in pots. i can also see few toys in these pots and in the background i can see white colour wall. [SEP]\n",
      "hypo: [CLS] in this image we can see a houseplants is a table on the background there is a pot. in the wall. [SEP]\n",
      "samp: [CLS] in this picture we can see a houseplants and we can see the background there is a wall, we can see a [SEP]\n",
      "lr con   : 4.460117548278757e-11\n",
      "lr bert  : 5.884130982367758e-09\n",
      "lr cri   : 1.9345088161209068e-05\n",
      "lr others: 1.563727959697733e-07\n",
      "Train epoch = 0.7556675062972292, loss = 1.5925779342651367, policy = 0.19413182139396667, entropy_loss = -0.002523902803659439, gae = 0.29602545499801636, kl_div = 0.080401711165905, reward = 4.138194561004639, ord = 7.0473103523254395, repeat = -3.642254590988159, length = -0.18466907739639282, adv = 0.7330318093299866, rougeL = 1.3204935789108276, cider = 0.21310117840766907, clip = 0.4047726094722748, crf = 0.9704337120056152, ce = 0.05410906672477722, unr = 0.9178075194358826, ber = 5.648976802825928\n",
      "refe: [CLS] in the image i can see a plate in which there is some food item. [SEP]\n",
      "hypo: [CLS] in this image we can see a plate food item. [SEP]\n",
      "samp: [CLS] in this image we can see a plate food item. [SEP]\n",
      "lr con   : 3.7632241813602014e-11\n",
      "lr bert  : 4.964735516372796e-09\n",
      "lr cri   : 1.632241813602015e-05\n",
      "lr others: 1.3193954659949622e-07\n",
      "Train epoch = 0.7934508816120907, loss = 1.595518708229065, policy = 0.19387832283973694, entropy_loss = -0.0025247696321457624, gae = 0.2943776547908783, kl_div = 0.0802357941865921, reward = 4.1314496994018555, ord = 7.050094127655029, repeat = -3.651822566986084, length = -0.18420599400997162, adv = 0.7272335290908813, rougeL = 1.3206576108932495, cider = 0.21246105432510376, clip = 0.40498086810112, crf = 0.9754370450973511, ce = 0.054114751517772675, unr = 0.9173842072486877, ber = 5.648822784423828\n",
      "refe: [CLS] in this image we can see a few buildings, there are some trees, gates, doors, windows, poles and lights, in the background we can see the sky. [SEP]\n",
      "hypo: [CLS] in this image, we can see the bottom of the right side, we can see a pole, we can see the bottom of the right side, we can see the [SEP]\n",
      "samp: [CLS] in the right side i can see the bottom of this image there is a building. in the middle of a pole. in the sky. in the sky. we can see the sky. in the sky. in the sky. [SEP]\n",
      "lr con   : 3.066330814441645e-11\n",
      "lr bert  : 4.045340050377834e-09\n",
      "lr cri   : 1.3299748110831234e-05\n",
      "lr others: 1.0750629722921913e-07\n",
      "Train epoch = 0.8312342569269522, loss = 1.597841501235962, policy = 0.19195519387722015, entropy_loss = -0.002523884642869234, gae = 0.2948734164237976, kl_div = 0.07999712228775024, reward = 4.150351524353027, ord = 7.049386978149414, repeat = -3.6326844692230225, length = -0.18509544432163239, adv = 0.726438581943512, rougeL = 1.3217288255691528, cider = 0.21094921231269836, clip = 0.40501606464385986, crf = 0.9794105291366577, ce = 0.05412915349006653, unr = 0.918743908405304, ber = 5.648468494415283\n",
      "refe: [CLS] in the center of the image there is a woman in car. at the bottom of the image there is road. on the right side of the image we can see persons, traffic signals and building. on the left side of the image we can see building, persons, plants and vehicle. in the background we can see sky and clouds. [SEP]\n",
      "hypo: [CLS] in this image we can see few people sitting on the road, in the background there are two persons sitting on the right side of the background i can see buildings, there is the sky. [SEP]\n",
      "samp: [CLS] in this image i can see few people sitting on the image there are sitting on the background there are few people sitting on the background there is walking on the background there are walking on the top of the background there is sky. [SEP]\n",
      "lr con   : 2.3694374475230897e-11\n",
      "lr bert  : 3.1259445843828713e-09\n",
      "lr cri   : 1.0277078085642317e-05\n",
      "lr others: 8.307304785894206e-08\n",
      "Train epoch = 0.8690176322418136, loss = 1.6051247119903564, policy = 0.2030433863401413, entropy_loss = -0.0025253668427467346, gae = 0.2952142655849457, kl_div = 0.0800200030207634, reward = 4.160783290863037, ord = 7.0514349937438965, repeat = -3.6228063106536865, length = -0.18665088713169098, adv = 0.7243086099624634, rougeL = 1.3232789039611816, cider = 0.21168965101242065, clip = 0.4049259424209595, crf = 0.975214958190918, ce = 0.05415742099285126, unr = 0.9188054800033569, ber = 5.647985935211182\n",
      "refe: [CLS] in this picture i can see group of people standing. i can see houses, trees, and in the background there is the sky. [SEP]\n",
      "hypo: [CLS] in this image we can see there is a house, few people. on the background there is a few houses, we can see the sky. on the sky. on the sky. [SEP]\n",
      "samp: [CLS] in this picture we can see there is a building, few people walking. there are few people walking on the top there is walking on the image we can see the sky. on the sky. [SEP]\n",
      "lr con   : 1.6725440806045338e-11\n",
      "lr bert  : 2.206549118387909e-09\n",
      "lr cri   : 7.2544080604534e-06\n",
      "lr others: 5.863979848866498e-08\n",
      "Train epoch = 0.906801007556675, loss = 1.6038250923156738, policy = 0.2048167884349823, entropy_loss = -0.0025292050559073687, gae = 0.2940765917301178, kl_div = 0.07993341982364655, reward = 4.157455921173096, ord = 7.0538649559021, repeat = -3.6275644302368164, length = -0.1876387745141983, adv = 0.7198012471199036, rougeL = 1.3246912956237793, cider = 0.21060146391391754, clip = 0.4049183130264282, crf = 0.9732680916786194, ce = 0.054259493947029114, unr = 0.9187943935394287, ber = 5.648130893707275\n",
      "refe: [CLS] in the background we can see the trees, plants and lights. in this picture we can see traffic cones, vehicles, road and people. we can see a man holding a cloth and there is some information on it. at the bottom portion of the picture we can see the partial part of a motorbike. [SEP]\n",
      "hypo: [CLS] in this image, we can see a person standing. behind him there is standing. in the road. in the background there is a road. at the background there is a road. at the background there is a few people. at the road. [SEP]\n",
      "samp: [CLS] in this image, we can see a person is a person standing. in his hand. background i can see the background there is a fence. at the background there is a person is a man standing. at the background there is holding a road. [SEP]\n",
      "lr con   : 9.75650713685978e-12\n",
      "lr bert  : 1.287153652392947e-09\n",
      "lr cri   : 4.231738035264483e-06\n",
      "lr others: 3.4206549118387904e-08\n",
      "Train epoch = 0.9445843828715366, loss = 1.6114274263381958, policy = 0.19911666214466095, entropy_loss = -0.0025213430635631084, gae = 0.2962205708026886, kl_div = 0.07942254841327667, reward = 4.184174060821533, ord = 7.057531356811523, repeat = -3.605529308319092, length = -0.18877732753753662, adv = 0.7211907505989075, rougeL = 1.3277069330215454, cider = 0.2110060602426529, clip = 0.4048287570476532, crf = 0.9849821329116821, ce = 0.054206885397434235, unr = 0.9209491610527039, ber = 5.647912502288818\n",
      "refe: [CLS] in the center of the image we can see the name board, sign board, door are present. on the right side of the image a person is standing. on the left side of the image we can see a air conditioner is present. at the bottom of the image floor is there. at the top of the image light, wall are present. in the middle of the image some objects and a table are present. [SEP]\n",
      "hypo: [CLS] in this image we can see a store there is a building. [SEP]\n",
      "samp: [CLS] in this image we can see a shopping can see a building. i can see a building with some other objects. i can see some other objects. there are lights. [SEP]\n",
      "lr con   : 2.787573467674223e-12\n",
      "lr bert  : 3.677581863979849e-10\n",
      "lr cri   : 1.2090680100755668e-06\n",
      "lr others: 9.773299748110832e-09\n",
      "Train epoch = 0.982367758186398, loss = 1.6208900213241577, policy = 0.19627590477466583, entropy_loss = -0.002513143001124263, gae = 0.2958921194076538, kl_div = 0.07932615280151367, reward = 4.1901421546936035, ord = 7.058135509490967, repeat = -3.600942373275757, length = -0.18902429938316345, adv = 0.7187656164169312, rougeL = 1.3298007249832153, cider = 0.20890870690345764, clip = 0.4045795798301697, crf = 0.997661828994751, ce = 0.054247282445430756, unr = 0.9219731092453003, ber = 5.647354602813721\n",
      "refe: [CLS] in this image i can see a person sitting in a red car. there is another car and trees at the back. [SEP]\n",
      "hypo: [CLS] in this image we can see a person sitting in the car. he is a car. [SEP]\n",
      "samp: [CLS] in this image i can see a person sitting in the car. in this [SEP]\n",
      "bsz 56 is not batch_size 128. skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 04:59:15,826] Trial 2 finished with value: 1.4960142374038696 and parameters: {'config.betas': 1, 'config.len_coef': 3.8243974872273343, 'config.unr_coef': 1.475783929127104, 'config.crf_coef': 0.8324272226514612, 'config.ce_coef': 0.02642922773328238, 'config.gae_coef': 0.11384604718772118, 'config.clip_range': 0.13822635653670384, 'clip_grad_threshold': 1.660771538904844}. Best is trial 0 with value: 1.5353256464004517.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, avg_reward = 1.4960142374038696\n",
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.12226931047522582\n",
      "clip_grad_threshold gradient norm: 1.1971234625898288\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 0.7111835244321407\n",
      "unr_coef: 4.7328418691965926\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.5854894243586819\n",
      "ce_coef: 0.21226686581523735\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.815766647872646\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_045928.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50eb13317ae640c39d5be587903da5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 22.748455047607422, policy = 1.7205463720415537e-08, entropy_loss = -0.002643350511789322, gae = 21.89891815185547, kl_div = 0.07810596376657486, reward = 5.58515739440918, ord = 7.06235933303833, repeat = -4.275815010070801, length = -0.02304116077721119, adv = 1.1089352369308472, rougeL = 1.2279809713363647, cider = 0.2749638259410858, clip = 0.4045167863368988, crf = 0.37298911809921265, ce = 0.40108227729797363, unr = 2.8216543197631836, ber = 5.675326347351074\n",
      "refe: [CLS] in this picture i can observe a path in the middle of the picture. on either sides of the path i can observe trees and some grass on the ground. in the background there are some clouds in the sky. [SEP]\n",
      "hypo: [CLS] in this image there is a road, trees and trees. there are trees. there are trees. [SEP]\n",
      "samp: [CLS] in this image there are trees. in the bottom right side there are trees. in the sky. [SEP] [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 25.28856658935547, policy = 0.0756339430809021, entropy_loss = -0.0025017703883349895, gae = 24.081573486328125, kl_div = 0.07892901450395584, reward = 5.897792339324951, ord = 7.075751304626465, repeat = -4.021467208862305, length = -0.029797198250889778, adv = 1.1710976362228394, rougeL = 1.305169701576233, cider = 0.24049890041351318, clip = 0.4021318256855011, crf = 0.6358468532562256, ce = 0.4190823435783386, unr = 2.8733057975769043, ber = 5.68140983581543\n",
      "refe: [CLS] in this picture we can see a car and a man in the front, there are some people standing in the middle, some of those people are holding mobile phones, on the right side there are trees, we can see buildings in the background. [SEP]\n",
      "hypo: [CLS] in this image, we can see a person wearing a man standing and there is a few people are trees, at the background there are standing. [SEP]\n",
      "samp: [CLS] in this image there is a man who is a man who is a person wearing a person wearing a few people are trees, we can also see a person. [SEP]\n",
      "lr con   : 1.2962216624685136e-10\n",
      "lr bert  : 1.7100755667506296e-08\n",
      "lr cri   : 5.622166246851385e-05\n",
      "lr others: 4.544584382871536e-07\n",
      "Train epoch = 0.07556675062972293, loss = 26.267581939697266, policy = 0.3136443495750427, entropy_loss = -0.002459913259372115, gae = 24.845687866210938, kl_div = 0.08032230287790298, reward = 6.035072326660156, ord = 7.062316417694092, repeat = -3.9274792671203613, length = -0.03207851201295853, adv = 1.194477915763855, rougeL = 1.3045616149902344, cider = 0.22439922392368317, clip = 0.4047611653804779, crf = 0.609136164188385, ce = 0.42124971747398376, unr = 2.932313919067383, ber = 5.666970252990723\n",
      "refe: [CLS] in this image there is grass towards the bottom of the image, there are cars on the grass, there are a group of persons walking, there are three men sitting on the chair, there is an object towards the right of the image, there are objects on the grass, there are objects towards the top of the image, there is a woman walking, she is wearing a bag, there is a man walking, he is wearing a bag. [SEP]\n",
      "hypo: [CLS] in this image we can see the road. in the image, there are few people standing. there are few people. in the ground. [SEP]\n",
      "samp: [CLS] in this image i can see the road. in this image there is a few people standing on the left side we can see the left side. in the road. [SEP]\n",
      "lr con   : 1.6307304785894207e-10\n",
      "lr bert  : 2.1513853904282117e-08\n",
      "lr cri   : 7.073047858942065e-05\n",
      "lr others: 5.717380352644836e-07\n",
      "Train epoch = 0.11335012594458438, loss = 26.834415435791016, policy = 0.592314600944519, entropy_loss = -0.002459373790770769, gae = 25.123857498168945, kl_div = 0.08151433616876602, reward = 6.101612091064453, ord = 7.048138618469238, repeat = -3.860227584838867, length = -0.03337664157152176, adv = 1.2022783756256104, rougeL = 1.303041696548462, cider = 0.21796925365924835, clip = 0.40472307801246643, crf = 0.6115058660507202, ce = 0.4276804029941559, unr = 2.947077989578247, ber = 5.658144474029541\n",
      "refe: [CLS] in this image we can see a tree with fruits and leaves. on the tree there is a person. in the back there is a wooden fencing. [SEP]\n",
      "hypo: [CLS] in this image we can see a person wearing clothes, we can see a tree. [SEP]\n",
      "samp: [CLS] in this image we can see a man sitting on the plants. in front of this image there are trees. [SEP]\n",
      "lr con   : 1.561041141897565e-10\n",
      "lr bert  : 2.0594458438287153e-08\n",
      "lr cri   : 6.770780856423173e-05\n",
      "lr others: 5.473047858942065e-07\n",
      "Train epoch = 0.15113350125944586, loss = 28.786876678466797, policy = 0.47204098105430603, entropy_loss = -0.0023775165900588036, gae = 27.134674072265625, kl_div = 0.08029739558696747, reward = 6.395217418670654, ord = 7.072280406951904, repeat = -3.6563496589660645, length = -0.03533351048827171, adv = 1.2512402534484863, rougeL = 1.321090817451477, cider = 0.221193328499794, clip = 0.40376028418540955, crf = 0.6750370264053345, ce = 0.4272080063819885, unr = 3.0146212577819824, ber = 5.65557336807251\n",
      "refe: [CLS] in this image in the front there are persons smiling. [SEP]\n",
      "hypo: [CLS] in this image i can see a man and one person is a woman. [SEP]\n",
      "samp: [CLS] in this picture we can see a man in the image there are smiling. [SEP] smiling. [SEP] we can see a wall. [SEP]\n",
      "lr con   : 1.4913518052057094e-10\n",
      "lr bert  : 1.9675062972292192e-08\n",
      "lr cri   : 6.468513853904282e-05\n",
      "lr others: 5.228715365239295e-07\n",
      "Train epoch = 0.1889168765743073, loss = 29.47769546508789, policy = 0.4624086916446686, entropy_loss = -0.0023378070909529924, gae = 27.797067642211914, kl_div = 0.07987982034683228, reward = 6.511870861053467, ord = 7.080617904663086, repeat = -3.5763297080993652, length = -0.034979045391082764, adv = 1.2649500370025635, rougeL = 1.3351356983184814, cider = 0.21436703205108643, clip = 0.40330588817596436, crf = 0.7140428423881531, ce = 0.4266323149204254, unr = 3.042562484741211, ber = 5.657876968383789\n",
      "refe: [CLS] there is a man sitting and holding a steering of a red color vehicle. in the back there are vehicles. there is a road. also there is a poster with graffiti. in the background there are trees and buildings with windows. [SEP]\n",
      "hypo: [CLS] in this image we can see a person is a person is a road. he is a road. i can see the trees, trees. [SEP]\n",
      "samp: [CLS] in this image we can see a person is a vehicle. here we can see a road. in the background i can see the background there is a pole and plants, trees. [SEP]\n",
      "lr con   : 1.4216624685138537e-10\n",
      "lr bert  : 1.8755667506297228e-08\n",
      "lr cri   : 6.16624685138539e-05\n",
      "lr others: 4.984382871536523e-07\n",
      "Train epoch = 0.22670025188916876, loss = 29.908126831054688, policy = 0.4043503403663635, entropy_loss = -0.0023001059889793396, gae = 28.248531341552734, kl_div = 0.07999477535486221, reward = 6.598966598510742, ord = 7.082683563232422, repeat = -3.5125062465667725, length = -0.03616141527891159, adv = 1.2726056575775146, rougeL = 1.3432196378707886, cider = 0.21311722695827484, clip = 0.4028070271015167, crf = 0.7485038638114929, ce = 0.42904362082481384, unr = 3.064950942993164, ber = 5.655602931976318\n",
      "refe: [CLS] this is looking like a meeting hall. there are many people sitting on chairs. in the background there are many people holding cameras are standing. in the top right corner there is a big door. in the background there are curtains, painting, window. in the right side there are few chairs which are empty. in the front line three men are sitting wearing suit along with a lady who is wearing black dress. [SEP]\n",
      "hypo: [CLS] in this image we can see some people sitting on the chairs in the background there is a projector attention, in the background there is wall. [SEP]\n",
      "samp: [CLS] in this image there is a group of people are sitting on the chairs in the back there is a frame. [SEP] blazers. [SEP]\n",
      "lr con   : 1.3519731318219982e-10\n",
      "lr bert  : 1.7836272040302267e-08\n",
      "lr cri   : 5.863979848866499e-05\n",
      "lr others: 4.740050377833753e-07\n",
      "Train epoch = 0.26448362720403024, loss = 29.09251594543457, policy = 0.38044893741607666, entropy_loss = -0.0023095624055713415, gae = 27.46373176574707, kl_div = 0.08004236966371536, reward = 6.517068862915039, ord = 7.073196887969971, repeat = -3.5841598510742188, length = -0.03596198186278343, adv = 1.2473456859588623, rougeL = 1.3374629020690918, cider = 0.21104350686073303, clip = 0.40258315205574036, crf = 0.7386804223060608, ce = 0.43192097544670105, unr = 3.0639939308166504, ber = 5.655851364135742\n",
      "refe: [CLS] in this picture we can see a vehicle and a board and in the background we can see the road, buildings, trees, poles and the sky. [SEP]\n",
      "hypo: [CLS] in this image we can see buildings, there is a pole, sign board on the road. on the road. on the road. [SEP] on the sky. [SEP]\n",
      "samp: [CLS] in this image we can see buildings, there is a pole, trees, we can see number of the road. on the road. [SEP] on the sky. on the image. [SEP]. [SEP] sky. [SEP]\n",
      "lr con   : 1.2822837951301427e-10\n",
      "lr bert  : 1.6916876574307306e-08\n",
      "lr cri   : 5.561712846347607e-05\n",
      "lr others: 4.495717884130982e-07\n",
      "Train epoch = 0.3022670025188917, loss = 28.921998977661133, policy = 0.38537919521331787, entropy_loss = -0.002306043403223157, gae = 27.30429458618164, kl_div = 0.08001960813999176, reward = 6.527101039886475, ord = 7.067021369934082, repeat = -3.573481559753418, length = -0.03556273877620697, adv = 1.2401607036590576, rougeL = 1.3329013586044312, cider = 0.2141353189945221, clip = 0.40246129035949707, crf = 0.7235115766525269, ce = 0.4310961961746216, unr = 3.069124460220337, ber = 5.6535563468933105\n",
      "refe: [CLS] to the right bottom of the image there is a platform with green and red painting. and to the left side of the image there is a blue train with windows. inside the train there are rods, seats and posters. and to the right top corner of the image there is a roof with clock and also there are rods. [SEP]\n",
      "hypo: [CLS] in this image, we can see a train. we can see a train. i can see a train lights. [SEP] we can see a rooftop, lights. [SEP]\n",
      "samp: [CLS] in this image, we can see a train we can see a train. i can see a train. [SEP] platform. i can see a man and the image. [SEP]\n",
      "lr con   : 1.2125944584382872e-10\n",
      "lr bert  : 1.5997481108312342e-08\n",
      "lr cri   : 5.2594458438287154e-05\n",
      "lr others: 4.2513853904282117e-07\n",
      "Train epoch = 0.34005037783375314, loss = 28.539831161499023, policy = 0.38899579644203186, entropy_loss = -0.002305899281054735, gae = 26.949586868286133, kl_div = 0.0797562375664711, reward = 6.503931999206543, ord = 7.063530445098877, repeat = -3.598402738571167, length = -0.03530742973089218, adv = 1.227570652961731, rougeL = 1.332724928855896, cider = 0.21527671813964844, clip = 0.40248021483421326, crf = 0.6939965486526489, ce = 0.42979878187179565, unr = 3.0741121768951416, ber = 5.654012203216553\n",
      "refe: [CLS] in the image in the center we can see poles, fences, banners, vehicles, shops and few people. in the background we can see the sky, clouds, buildings and trees. [SEP]\n",
      "hypo: [CLS] in this image we can see a building, buildings, windows, we can see a pole, we can see sky. [SEP] sky. [SEP]\n",
      "samp: [CLS] in this image i can see a building foreground there is a building. [SEP] we can see a pole, there are trees. [SEP]. [SEP]. [SEP] sky. [SEP]\n",
      "lr con   : 1.1429051217464315e-10\n",
      "lr bert  : 1.507808564231738e-08\n",
      "lr cri   : 4.957178841309823e-05\n",
      "lr others: 4.0070528967254406e-07\n",
      "Train epoch = 0.3778337531486146, loss = 28.434755325317383, policy = 0.37942808866500854, entropy_loss = -0.0023030852898955345, gae = 26.861156463623047, kl_div = 0.07992473244667053, reward = 6.512385368347168, ord = 7.063821792602539, repeat = -3.5949525833129883, length = -0.03524786978960037, adv = 1.221134066581726, rougeL = 1.334571361541748, cider = 0.2172473818063736, clip = 0.40227124094963074, crf = 0.6864354610443115, ce = 0.43010765314102173, unr = 3.0787642002105713, ber = 5.653728008270264\n",
      "refe: [CLS] in the picture there is a person present, in front of a person there is people present, behind the person there is a curtain. [SEP]\n",
      "hypo: [CLS] in this image we can see a man standing and he is a screen. in the background there is standing. [SEP]\n",
      "samp: [CLS] in this image i can see a person wearing black blazer with the left side, in the background there is the image. [SEP]\n",
      "lr con   : 1.073215785054576e-10\n",
      "lr bert  : 1.4158690176322418e-08\n",
      "lr cri   : 4.654911838790932e-05\n",
      "lr others: 3.76272040302267e-07\n",
      "Train epoch = 0.4156171284634761, loss = 28.40867042541504, policy = 0.3718526065349579, entropy_loss = -0.0022973958402872086, gae = 26.853145599365234, kl_div = 0.08001178503036499, reward = 6.543406963348389, ord = 7.0638933181762695, repeat = -3.5757105350494385, length = -0.0350969173014164, adv = 1.2183107137680054, rougeL = 1.3350510597229004, cider = 0.21730384230613708, clip = 0.40258777141571045, crf = 0.676954448223114, ce = 0.42900073528289795, unr = 3.090320110321045, ber = 5.655251979827881\n",
      "refe: [CLS] as we can see in he image there is a man, television and bottles on table. [SEP]\n",
      "hypo: [CLS] in this image we can see a bottles and there are bottles. [SEP]. [SEP]\n",
      "samp: [CLS] in this image we can see a bottles and there are placed on the background i can see a bottle. [SEP]\n",
      "lr con   : 1.0035264483627203e-10\n",
      "lr bert  : 1.3239294710327456e-08\n",
      "lr cri   : 4.35264483627204e-05\n",
      "lr others: 3.518387909319899e-07\n",
      "Train epoch = 0.4534005037783375, loss = 28.119510650634766, policy = 0.35840967297554016, entropy_loss = -0.002300580497831106, gae = 26.590606689453125, kl_div = 0.07989952713251114, reward = 6.529869079589844, ord = 7.056591033935547, repeat = -3.585801839828491, length = -0.03555179759860039, adv = 1.2072901725769043, rougeL = 1.3318111896514893, cider = 0.217582568526268, clip = 0.40266796946525574, crf = 0.6624768972396851, ce = 0.4304144084453583, unr = 3.094633102416992, ber = 5.654472351074219\n",
      "refe: [CLS] in this image i can see group of people are standing among them some are carrying bags. in the background buildings, poles, trees and the sky. [SEP]\n",
      "hypo: [CLS] in this image we can see many people standing on the road, there are trees, in the right side. at the background there are trees, in the sky. [SEP]\n",
      "samp: [CLS] in this picture we can see many people standing. in front of them are trees, poles, trees, poles, there are mountains, in the background there are trees, a mountain. [SEP]\n",
      "lr con   : 9.338371116708649e-11\n",
      "lr bert  : 1.2319899244332495e-08\n",
      "lr cri   : 4.0503778337531486e-05\n",
      "lr others: 3.2740554156171283e-07\n",
      "Train epoch = 0.491183879093199, loss = 28.028167724609375, policy = 0.3733838200569153, entropy_loss = -0.0022911238484084606, gae = 26.49005126953125, kl_div = 0.07980762422084808, reward = 6.541756629943848, ord = 7.054909706115723, repeat = -3.576629638671875, length = -0.03560839220881462, adv = 1.201505422592163, rougeL = 1.3303419351577759, cider = 0.2191358059644699, clip = 0.40258845686912537, crf = 0.6573126912117004, ce = 0.429901123046875, unr = 3.0990850925445557, ber = 5.655261039733887\n",
      "refe: [CLS] in this picture there is a man who is standing on the stone. on the left there is a woman who is standing near the tree. in the background we can see waterfall and the stone mountains. [SEP]\n",
      "hypo: [CLS] in this image there is the image we can see a person standing and there are rocks. [SEP]\n",
      "samp: [CLS] in this image there is a man i can see a man standing and they are few people. i can see a man standing. [SEP] standing. [SEP]\n",
      "lr con   : 8.641477749790091e-11\n",
      "lr bert  : 1.140050377833753e-08\n",
      "lr cri   : 3.7481108312342564e-05\n",
      "lr others: 3.029722921914357e-07\n",
      "Train epoch = 0.5289672544080605, loss = 28.162700653076172, policy = 0.35387566685676575, entropy_loss = -0.002277028514072299, gae = 26.63361930847168, kl_div = 0.07980809360742569, reward = 6.586544513702393, ord = 7.050633430480957, repeat = -3.538234233856201, length = -0.03619026765227318, adv = 1.2021857500076294, rougeL = 1.3334931135177612, cider = 0.21831007301807404, clip = 0.402371346950531, crf = 0.667041003704071, ce = 0.430629700422287, unr = 3.1103355884552, ber = 5.653167724609375\n",
      "refe: [CLS] in this picture i can see buildings, trees and i can see few people walking and i can see grass on the ground and it looks like an arch and i can see sky. [SEP]\n",
      "hypo: [CLS] in this image we can see a fort. in the image there is a building. in the sky. [SEP] architecture. in the sky. [SEP]. [SEP]. [SEP]\n",
      "samp: [CLS] in this image we can see a fort with windows, trees, trees, trees, we can see a railing. [SEP]. [SEP] sky. [SEP]\n",
      "lr con   : 7.944584382871536e-11\n",
      "lr bert  : 1.048110831234257e-08\n",
      "lr cri   : 3.4458438287153655e-05\n",
      "lr others: 2.785390428211587e-07\n",
      "Train epoch = 0.5667506297229219, loss = 28.31532859802246, policy = 0.3611396253108978, entropy_loss = -0.002270678523927927, gae = 26.77755355834961, kl_div = 0.07966435700654984, reward = 6.624039173126221, ord = 7.050048828125, repeat = -3.507899522781372, length = -0.0365673191845417, adv = 1.2019318342208862, rougeL = 1.336949348449707, cider = 0.21554669737815857, clip = 0.40192124247550964, crf = 0.667656421661377, ce = 0.4315843880176544, unr = 3.1184589862823486, ber = 5.650042533874512\n",
      "refe: [CLS] in the image we can see a lizard, brown and pale brown in color. [SEP]\n",
      "hypo: [CLS] in this image we can see a frog. in the surface. [SEP]\n",
      "samp: [CLS] in this picture we can see a frog. [SEP] smoke. [SEP]. [SEP]\n",
      "lr con   : 7.24769101595298e-11\n",
      "lr bert  : 9.561712846347607e-09\n",
      "lr cri   : 3.143576826196473e-05\n",
      "lr others: 2.541057934508816e-07\n",
      "Train epoch = 0.6045340050377834, loss = 28.160634994506836, policy = 0.34391289949417114, entropy_loss = -0.0022620505187660456, gae = 26.627670288085938, kl_div = 0.07965385913848877, reward = 6.618890285491943, ord = 7.0457892417907715, repeat = -3.504922389984131, length = -0.03708014264702797, adv = 1.1935887336730957, rougeL = 1.3363758325576782, cider = 0.2126656323671341, clip = 0.4018764793872833, crf = 0.678184986114502, ce = 0.43347153067588806, unr = 3.1151034832000732, ber = 5.647490978240967\n",
      "refe: [CLS] in this image there are people standing on the grass. in the center of the image there is water. in the background of the image there are trees, mountains and sky. [SEP]\n",
      "hypo: [CLS] in this image in the image we can see few persons standing, in the bottom of people, grass, grass. [SEP] grass. [SEP]\n",
      "samp: [CLS] in this image in the image we can see few persons standing. in the bottom of people walking on the image. [SEP]\n",
      "lr con   : 6.550797649034425e-11\n",
      "lr bert  : 8.642317380352645e-09\n",
      "lr cri   : 2.8413098236775818e-05\n",
      "lr others: 2.2967254408060454e-07\n",
      "Train epoch = 0.6423173803526449, loss = 28.20281982421875, policy = 0.3776099979877472, entropy_loss = -0.002256021834909916, gae = 26.62754249572754, kl_div = 0.07975440472364426, reward = 6.638775825500488, ord = 7.044942378997803, repeat = -3.4875986576080322, length = -0.03734372928738594, adv = 1.1901979446411133, rougeL = 1.3377797603607178, cider = 0.21086256206035614, clip = 0.4018693268299103, crf = 0.6857480406761169, ce = 0.43441951274871826, unr = 3.1187760829925537, ber = 5.645534038543701\n",
      "refe: [CLS] in this picture there is a mountain and there are few plants around it in the image. [SEP]\n",
      "hypo: [CLS] in this image we can see a mountain and trees. [SEP]\n",
      "samp: [CLS] in this image i can see a rock. [SEP]. [SEP]\n",
      "lr con   : 5.853904282115869e-11\n",
      "lr bert  : 7.722921914357682e-09\n",
      "lr cri   : 2.5390428211586902e-05\n",
      "lr others: 2.0523929471032745e-07\n",
      "Train epoch = 0.6801007556675063, loss = 28.491886138916016, policy = 0.37218835949897766, entropy_loss = -0.0022381937596946955, gae = 26.911733627319336, kl_div = 0.07959838956594467, reward = 6.698122978210449, ord = 7.049436092376709, repeat = -3.440005302429199, length = -0.037196822464466095, adv = 1.1944530010223389, rougeL = 1.3421911001205444, cider = 0.2107958197593689, clip = 0.4021975100040436, crf = 0.6970012784004211, ce = 0.4335995018482208, unr = 3.1258890628814697, ber = 5.645651340484619\n",
      "refe: [CLS] in this image there is a lady statue on the white table. in the background there is a wall. [SEP]\n",
      "hypo: [CLS] in this image we can see a sculpture of sculpture. [SEP]\n",
      "samp: [CLS] in this image we can see a sculpture there is a sculpture. [SEP]\n",
      "lr con   : 5.157010915197313e-11\n",
      "lr bert  : 6.8035264483627206e-09\n",
      "lr cri   : 2.2367758186397984e-05\n",
      "lr others: 1.8080604534005037e-07\n",
      "Train epoch = 0.7178841309823678, loss = 28.572145462036133, policy = 0.36731961369514465, entropy_loss = -0.002227925695478916, gae = 26.99525260925293, kl_div = 0.07939445227384567, reward = 6.7315473556518555, ord = 7.049469947814941, repeat = -3.4133718013763428, length = -0.037196770310401917, adv = 1.1942510604858398, rougeL = 1.3442540168762207, cider = 0.20936022698879242, clip = 0.40220361948013306, crf = 0.6993054151535034, ce = 0.43310418725013733, unr = 3.132646322250366, ber = 5.646917343139648\n",
      "refe: [CLS] in this picture we can see a wall, there are three boards pasted on the wall, we can see pictures of bottles and some text on these boards, there is the ceiling at the top of the picture. [SEP]\n",
      "hypo: [CLS] in this image we can see a wall. [SEP]\n",
      "samp: [CLS] in this image we can see these are different color. [SEP]\n",
      "lr con   : 4.460117548278757e-11\n",
      "lr bert  : 5.884130982367758e-09\n",
      "lr cri   : 1.9345088161209068e-05\n",
      "lr others: 1.563727959697733e-07\n",
      "Train epoch = 0.7556675062972292, loss = 28.237306594848633, policy = 0.37501829862594604, entropy_loss = -0.0022281515412032604, gae = 26.653947830200195, kl_div = 0.07951492816209793, reward = 6.697625637054443, ord = 7.046701908111572, repeat = -3.4388697147369385, length = -0.03735734894871712, adv = 1.1815413236618042, rougeL = 1.3431191444396973, cider = 0.2087898552417755, clip = 0.40249329805374146, crf = 0.697086751461029, ce = 0.43396809697151184, unr = 3.1271512508392334, ber = 5.647089004516602\n",
      "refe: [CLS] in this image i can see a group of people who are sitting on the chair in front of a table. i can also see there is a board on the road and a tree. [SEP]\n",
      "hypo: [CLS] in this image, we can see a activities we can see tables, there is a chair. here we can see tables. [SEP]\n",
      "samp: [CLS] in this image, we can see a building with some text and i can also see a person is a chair. i can see a bench. we can see a person is a vehicle. [SEP]\n",
      "lr con   : 3.7632241813602014e-11\n",
      "lr bert  : 4.964735516372796e-09\n",
      "lr cri   : 1.632241813602015e-05\n",
      "lr others: 1.3193954659949622e-07\n",
      "Train epoch = 0.7934508816120907, loss = 28.32928466796875, policy = 0.36019304394721985, entropy_loss = -0.0022146040573716164, gae = 26.74874496459961, kl_div = 0.07957956194877625, reward = 6.732423782348633, ord = 7.046786785125732, repeat = -3.4072346687316895, length = -0.0375470295548439, adv = 1.1822073459625244, rougeL = 1.3445075750350952, cider = 0.2064831703901291, clip = 0.4024697542190552, crf = 0.7085745930671692, ce = 0.4344070553779602, unr = 3.1304190158843994, ber = 5.6467413902282715\n",
      "refe: [CLS] in this image there are group of people and some of them are standing and some of them are sitting on the stage there are some people who are standing on the right side there is one woman who is standing and she is holding a guitar. beside her there is another woman who is standing and she is holding a mike and it seems that she is singing. on the left side there is another woman who is standing and she is holding a guitar in front of her there is one mike\n",
      "hypo: [CLS] in this image we can see a group of persons standing on the stage and in their hands. [SEP]. [SEP]\n",
      "samp: [CLS] in this picture we can see a group of persons standing on the stage. in their hands. [SEP] there is a person. [SEP]. [SEP]\n",
      "lr con   : 3.066330814441645e-11\n",
      "lr bert  : 4.045340050377834e-09\n",
      "lr cri   : 1.3299748110831234e-05\n",
      "lr others: 1.0750629722921913e-07\n",
      "Train epoch = 0.8312342569269522, loss = 28.188520431518555, policy = 0.34815454483032227, entropy_loss = -0.0022088084369897842, gae = 26.61603355407715, kl_div = 0.07941584289073944, reward = 6.727406978607178, ord = 7.0432586669921875, repeat = -3.4083850383758545, length = -0.037470221519470215, adv = 1.1756584644317627, rougeL = 1.3437997102737427, cider = 0.20487815141677856, clip = 0.40231937170028687, crf = 0.7123647332191467, ce = 0.4347589313983917, unr = 3.1300036907196045, ber = 5.646078586578369\n",
      "refe: [CLS] in this image there are paintings on the boards which are on the grass, there is a tent with iron poles, iron grills, car, trees, and in the background there is sky. [SEP]\n",
      "hypo: [CLS] in this image we can see a board, we can see a tent, there are some other objects. [SEP] we can see grass. [SEP]\n",
      "samp: [CLS] in this image i can see a board, we can see a tent, there are some other objects. the background i can see i can see a chair. [SEP]\n",
      "lr con   : 2.3694374475230897e-11\n",
      "lr bert  : 3.1259445843828713e-09\n",
      "lr cri   : 1.0277078085642317e-05\n",
      "lr others: 8.307304785894206e-08\n",
      "Train epoch = 0.8690176322418136, loss = 28.065576553344727, policy = 0.33685699105262756, entropy_loss = -0.0022050896659493446, gae = 26.5020694732666, kl_div = 0.07944346219301224, reward = 6.725371360778809, ord = 7.041604042053223, repeat = -3.4066550731658936, length = -0.03736726567149162, adv = 1.1697890758514404, rougeL = 1.3436119556427002, cider = 0.20339179039001465, clip = 0.40255823731422424, crf = 0.7147799730300903, ce = 0.43462786078453064, unr = 3.1277894973754883, ber = 5.645872592926025\n",
      "refe: [CLS] there is one woman standing and wearing a black color dress in the middle of this image. we can see a group of people at the bottom of this image. we can a wall and a curtain in the background. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman is a woman is a woman is a woman is a woman standing and smiling. in front of people. in the background. [SEP]\n",
      "samp: [CLS] in this image we can see a person is a woman is a woman is a woman is a woman standing and smiling. in front of people are some people. in the image. [SEP]\n",
      "lr con   : 1.6725440806045338e-11\n",
      "lr bert  : 2.206549118387909e-09\n",
      "lr cri   : 7.2544080604534e-06\n",
      "lr others: 5.863979848866498e-08\n",
      "Train epoch = 0.906801007556675, loss = 28.031293869018555, policy = 0.333166241645813, entropy_loss = -0.0021989967208355665, gae = 26.46999740600586, kl_div = 0.07937420904636383, reward = 6.735784530639648, ord = 7.041998863220215, repeat = -3.3978288173675537, length = -0.037508077919483185, adv = 1.1665513515472412, rougeL = 1.344495415687561, cider = 0.20251257717609406, clip = 0.4026114046573639, crf = 0.7162596583366394, ce = 0.4346935451030731, unr = 3.129122734069824, ber = 5.645737648010254\n",
      "refe: [CLS] in this image we can see some buildings and some people. on the left side of the image we can see a person sitting on a bench. on the right side of the image we can see some poles. at the top of the image there is the sky. [SEP]\n",
      "hypo: [CLS] in this image i can see buildings, in the image in the bottom of people, trees, poles, in the image. [SEP]\n",
      "samp: [CLS] in this image i can see buildings, in the image. on the image, we can also there is the background there is the image. [SEP]\n",
      "lr con   : 9.75650713685978e-12\n",
      "lr bert  : 1.287153652392947e-09\n",
      "lr cri   : 4.231738035264483e-06\n",
      "lr others: 3.4206549118387904e-08\n",
      "Train epoch = 0.9445843828715366, loss = 28.3237361907959, policy = 0.3224141597747803, entropy_loss = -0.002187359146773815, gae = 26.76690673828125, kl_div = 0.07933250069618225, reward = 6.796379566192627, ord = 7.0454325675964355, repeat = -3.349996566772461, length = -0.03763390704989433, adv = 1.1733291149139404, rougeL = 1.3478363752365112, cider = 0.20205645263195038, clip = 0.4026382267475128, crf = 0.7231003046035767, ce = 0.4341716170310974, unr = 3.138577461242676, ber = 5.6465277671813965\n",
      "refe: [CLS] in the picture i can see two women and there is a smile on their face. [SEP]\n",
      "hypo: [CLS] in this image we can see two women smiling. [SEP]\n",
      "samp: [CLS] in this image i can see two persons and smiling. [SEP]\n",
      "lr con   : 2.787573467674223e-12\n",
      "lr bert  : 3.677581863979849e-10\n",
      "lr cri   : 1.2090680100755668e-06\n",
      "lr others: 9.773299748110832e-09\n",
      "Train epoch = 0.982367758186398, loss = 28.60004425048828, policy = 0.3141038119792938, entropy_loss = -0.002176930196583271, gae = 27.043336868286133, kl_div = 0.07917585223913193, reward = 6.853634834289551, ord = 7.0475616455078125, repeat = -3.30405855178833, length = -0.03791946917772293, adv = 1.1797319650650024, rougeL = 1.3506081104278564, cider = 0.20028367638587952, clip = 0.40251150727272034, crf = 0.7310693860054016, ce = 0.43453386425971985, unr = 3.1480519771575928, ber = 5.646111965179443\n",
      "refe: [CLS] here men are sitting wearing red color clothes, this is a photo frame. [SEP]\n",
      "hypo: [CLS] in this image we can see group of people are three people standing. [SEP]\n",
      "samp: [CLS] in this picture we can see group of people standing in their hands. [SEP] them we can see a wall. [SEP]\n",
      "bsz 56 is not batch_size 128. skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 05:56:42,054] Trial 3 finished with value: 1.574016809463501 and parameters: {'config.betas': 2, 'config.len_coef': 0.7111835244321407, 'config.unr_coef': 4.7328418691965926, 'config.crf_coef': 0.5854894243586819, 'config.ce_coef': 0.21226686581523735, 'config.gae_coef': 4.815766647872646, 'config.clip_range': 0.12226931047522582, 'clip_grad_threshold': 1.1971234625898288}. Best is trial 3 with value: 1.574016809463501.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, avg_reward = 1.574016809463501\n",
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.12066350268297439\n",
      "clip_grad_threshold gradient norm: 1.7242104401200835\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.5629865708781714\n",
      "unr_coef: 3.280174676212547\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.08943129344455958\n",
      "ce_coef: 0.6582918721091665\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 2.8799846933084483\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_055654.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3971de81f9b4f4591112ad5f2f6b6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 14.198251724243164, policy = 1.4440300510898396e-08, entropy_loss = -0.002952299313619733, gae = 12.659467697143555, kl_div = 0.08351895958185196, reward = 4.43446159362793, ord = 6.940316200256348, repeat = -4.352248668670654, length = -0.08152766525745392, adv = 1.1734042167663574, rougeL = 1.1911410093307495, cider = 0.17609338462352753, clip = 0.41070041060447693, crf = 0.0739143118262291, ce = 1.3843028545379639, unr = 1.9279221296310425, ber = 5.667821884155273\n",
      "refe: [CLS] in this image we can see a girl. behind one man is there who is wearing black color dress. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman and a woman is blurred. behind her hand. [SEP]\n",
      "samp: [CLS] in this picture we can see a woman and a person wearing spectacles. behind her hand. [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 17.71131134033203, policy = 0.13200853765010834, entropy_loss = -0.0027483394369482994, gae = 16.085765838623047, kl_div = 0.07965147495269775, reward = 5.235701560974121, ord = 7.033124923706055, repeat = -3.7117934226989746, length = -0.10384083539247513, adv = 1.335340142250061, rougeL = 1.282305359840393, cider = 0.19564974308013916, clip = 0.4049997329711914, crf = 0.06971608847379684, ce = 1.3469163179397583, unr = 2.0182106494903564, ber = 5.639760971069336\n",
      "refe: [CLS] there are group of people here sitting on the chair at their tables. on the table we can see water bottles, files. here a woman is holding mic in her hand. [SEP]\n",
      "hypo: [CLS] in this image there is a room. in front of the chairs. in front of the front of them there is a table we can see the table. in the background i can see the background. [SEP]\n",
      "samp: [CLS] in this picture we can see number of people sitting in front of the chairs. in front of the front of them we can see the front of them sitting on the background i can see the background. [SEP]\n",
      "lr con   : 1.2962216624685136e-10\n",
      "lr bert  : 1.7100755667506296e-08\n",
      "lr cri   : 5.622166246851385e-05\n",
      "lr others: 4.544584382871536e-07\n",
      "Train epoch = 0.07556675062972293, loss = 18.644241333007812, policy = 0.2995581030845642, entropy_loss = -0.002667252440005541, gae = 16.825925827026367, kl_div = 0.080909863114357, reward = 5.4376444816589355, ord = 7.027130126953125, repeat = -3.547259569168091, length = -0.11872357875108719, adv = 1.3782888650894165, rougeL = 1.2949148416519165, cider = 0.18322201073169708, clip = 0.40282171964645386, crf = 0.07265167683362961, ce = 1.3678638935089111, unr = 2.0764975547790527, ber = 5.62432336807251\n",
      "refe: [CLS] this picture is clicked outside. in the foreground we can see a vehicle parked on the pavement and we can see the group of persons standing on the ground and we can see the group of vehicles parked on the ground. in the background we can see the buildings, windows of the buildings and boards attached to the poles and the staircase, handrail and some other objects. [SEP]\n",
      "hypo: [CLS] in this image we can see a bicycle. in the bicycle. on the background there are trees, we can see number of this image there are trees, there are walking on the road. [SEP]\n",
      "samp: [CLS] in this image i can see a bicycle. in the footpath and i can see number of this image we can see the left corner of this image there is walking. [SEP] outside. [SEP]\n",
      "lr con   : 1.6307304785894207e-10\n",
      "lr bert  : 2.1513853904282117e-08\n",
      "lr cri   : 7.073047858942065e-05\n",
      "lr others: 5.717380352644836e-07\n",
      "Train epoch = 0.11335012594458438, loss = 18.543954849243164, policy = 0.35450479388237, entropy_loss = -0.0026461451780050993, gae = 16.672657012939453, kl_div = 0.08336729556322098, reward = 5.4329729080200195, ord = 7.017668724060059, repeat = -3.5378658771514893, length = -0.1194932609796524, adv = 1.368839979171753, rougeL = 1.2940104007720947, cider = 0.18860185146331787, clip = 0.40287843346595764, crf = 0.07270092517137527, ce = 1.3633756637573242, unr = 2.0726633071899414, ber = 5.628050804138184\n",
      "refe: [CLS] in this image there are people walking on the road by holding banners, flags. there are cars on the road. beside the road there are street lights. in the background of the image there are buildings, trees, boards. [SEP]\n",
      "hypo: [CLS] in this image there are group of people walking on the road. in the road. on the right side there are trees, trees. on the right side there are trees. there are trees. on the top there are buildings. [SEP]\n",
      "samp: [CLS] in this picture there are group of people walking on the road. at the road walking on the right side there is a sign board there is a sign board, there is a pole, there is a pole, there is a few buildings. [SEP]\n",
      "lr con   : 1.561041141897565e-10\n",
      "lr bert  : 2.0594458438287153e-08\n",
      "lr cri   : 6.770780856423173e-05\n",
      "lr others: 5.473047858942065e-07\n",
      "Train epoch = 0.15113350125944586, loss = 18.43258285522461, policy = 0.5424655079841614, entropy_loss = -0.0026523261331021786, gae = 16.376522064208984, kl_div = 0.08366747945547104, reward = 5.381945610046387, ord = 7.039098262786865, repeat = -3.605496406555176, length = -0.1167086511850357, adv = 1.3496310710906982, rougeL = 1.3027691841125488, cider = 0.19699431955814362, clip = 0.4037717282772064, crf = 0.07292991876602173, ce = 1.3596503734588623, unr = 2.065054178237915, ber = 5.6410722732543945\n",
      "refe: [CLS] in this picture we can see grass at the bottom, there are two poles in the middle, in the background there are some trees, we can see a house here, there is the sky at the top of the picture. [SEP]\n",
      "hypo: [CLS] in this image in the image there is a fence. in the ground. in the background, in the background. in the background. in the sky. [SEP]\n",
      "samp: [CLS] in this image i can see a football can see grass. in the background there is grass and sky. in the background there is a sky. [SEP]\n",
      "lr con   : 1.4913518052057094e-10\n",
      "lr bert  : 1.9675062972292192e-08\n",
      "lr cri   : 6.468513853904282e-05\n",
      "lr others: 5.228715365239295e-07\n",
      "Train epoch = 0.1889168765743073, loss = 18.34135627746582, policy = 0.5481932759284973, entropy_loss = -0.002657493343576789, gae = 16.27582359313965, kl_div = 0.0838940441608429, reward = 5.382966995239258, ord = 7.0468268394470215, repeat = -3.6159725189208984, length = -0.11819583177566528, adv = 1.340954303741455, rougeL = 1.3051279783248901, cider = 0.20475687086582184, clip = 0.40316683053970337, crf = 0.07391292601823807, ce = 1.362189769744873, unr = 2.070307731628418, ber = 5.642955780029297\n",
      "refe: [CLS] in the picture we can see some tins with grains and names on each one of it and behind it we can see some jars with some liquids in it and beside it we can see a plate with some powder in it. [SEP]\n",
      "hypo: [CLS] in this image we can see a table on the center there is a table. in the food items. at the food items. [SEP]\n",
      "samp: [CLS] in this picture we can see a group of the center there is a table. in the food items. at the food items. [SEP]\n",
      "lr con   : 1.4216624685138537e-10\n",
      "lr bert  : 1.8755667506297228e-08\n",
      "lr cri   : 6.16624685138539e-05\n",
      "lr others: 4.984382871536523e-07\n",
      "Train epoch = 0.22670025188916876, loss = 18.41925621032715, policy = 0.518004298210144, entropy_loss = -0.0026598218828439713, gae = 16.386388778686523, kl_div = 0.08416686207056046, reward = 5.431778907775879, ord = 7.050333023071289, repeat = -3.5793344974517822, length = -0.11912901699542999, adv = 1.3410813808441162, rougeL = 1.3060930967330933, cider = 0.20402061939239502, clip = 0.4027308523654938, crf = 0.07395140081644058, ce = 1.3594067096710205, unr = 2.079908847808838, ber = 5.644249439239502\n",
      "refe: [CLS] building with windows. sky is cloudy. here we can see curtains and board. [SEP]\n",
      "hypo: [CLS] in this image in the picture we can see a building with windows, there is a building there is a building. [SEP]\n",
      "samp: [CLS] in this image i can observe a building which is a building attached to it on the top there is a building, lights. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (80 > 77). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 1.3519731318219982e-10\n",
      "lr bert  : 1.7836272040302267e-08\n",
      "lr cri   : 5.863979848866499e-05\n",
      "lr others: 4.740050377833753e-07\n",
      "Train epoch = 0.26448362720403024, loss = 18.471162796020508, policy = 0.5102854371070862, entropy_loss = -0.0026637078262865543, gae = 16.43811798095703, kl_div = 0.08392564952373505, reward = 5.472706317901611, ord = 7.05070686340332, repeat = -3.5433671474456787, length = -0.1211337074637413, adv = 1.3396035432815552, rougeL = 1.3102288246154785, cider = 0.20486925542354584, clip = 0.40286198258399963, crf = 0.07520666718482971, ce = 1.366292119026184, unr = 2.0864992141723633, ber = 5.647006511688232\n",
      "refe: [CLS] in this image, there is a bird on the grass. in the background, image is blurred. [SEP]\n",
      "hypo: [CLS] in this image i can see a bird. [SEP]\n",
      "samp: [CLS] in this image i can see a bird. [SEP]\n",
      "lr con   : 1.2822837951301427e-10\n",
      "lr bert  : 1.6916876574307306e-08\n",
      "lr cri   : 5.561712846347607e-05\n",
      "lr others: 4.495717884130982e-07\n",
      "Train epoch = 0.3022670025188917, loss = 18.46961212158203, policy = 0.4934422969818115, entropy_loss = -0.002660890808328986, gae = 16.45667266845703, kl_div = 0.08384080976247787, reward = 5.502748012542725, ord = 7.054588794708252, repeat = -3.5239615440368652, length = -0.12214082479476929, adv = 1.3350815773010254, rougeL = 1.3133960962295532, cider = 0.20394890010356903, clip = 0.40292423963546753, crf = 0.0751897469162941, ce = 1.363128662109375, unr = 2.0942630767822266, ber = 5.649126052856445\n",
      "refe: [CLS] in this image, i can see a fish in the water. there is a blurred background. at the bottom right side of the image, i can see the watermark. [SEP]\n",
      "hypo: [CLS] in this image i can see a fish in the water. [SEP]\n",
      "samp: [CLS] in this image i can see a fish in the water. [SEP]\n",
      "lr con   : 1.2125944584382872e-10\n",
      "lr bert  : 1.5997481108312342e-08\n",
      "lr cri   : 5.2594458438287154e-05\n",
      "lr others: 4.2513853904282117e-07\n",
      "Train epoch = 0.34005037783375314, loss = 18.51082992553711, policy = 0.5152989029884338, entropy_loss = -0.002654054667800665, gae = 16.477737426757812, kl_div = 0.08351355791091919, reward = 5.532418727874756, ord = 7.053157806396484, repeat = -3.499534845352173, length = -0.12318476289510727, adv = 1.3318893909454346, rougeL = 1.316731572151184, cider = 0.20207545161247253, clip = 0.40270161628723145, crf = 0.07524622976779938, ce = 1.361685872077942, unr = 2.101980686187744, ber = 5.647362232208252\n",
      "refe: [CLS] in this image we can see a man standing in the ground and a ball in front of him, there are few trees in the background. [SEP]\n",
      "hypo: [CLS] in this image, we can see a person standing on the ground. in the grass and grass, grass. [SEP] grass, grass. [SEP] grass and trees. [SEP]\n",
      "samp: [CLS] in this picture, we can see a person standing on the ground. at the grass and the grass, grass. [SEP] grass, grass. [SEP] grass. [SEP]\n",
      "lr con   : 1.1429051217464315e-10\n",
      "lr bert  : 1.507808564231738e-08\n",
      "lr cri   : 4.957178841309823e-05\n",
      "lr others: 4.0070528967254406e-07\n",
      "Train epoch = 0.3778337531486146, loss = 18.293901443481445, policy = 0.499323308467865, entropy_loss = -0.002659504534676671, gae = 16.273099899291992, kl_div = 0.08379419147968292, reward = 5.508921146392822, ord = 7.0524187088012695, repeat = -3.5184426307678223, length = -0.12369871884584427, adv = 1.3180513381958008, rougeL = 1.3193855285644531, cider = 0.20001304149627686, clip = 0.40251100063323975, crf = 0.07566952705383301, ce = 1.3646742105484009, unr = 2.098644495010376, ber = 5.648591995239258\n",
      "refe: [CLS] in this picture there is a man wearing white shirt and black tie is looking into the camera. behind there is a dark background. [SEP]\n",
      "hypo: [CLS] in this picture there is a man standing and smiling. [SEP] background. [SEP]\n",
      "samp: [CLS] in this picture we can see a person wearing clothes. [SEP]. [SEP]\n",
      "lr con   : 1.073215785054576e-10\n",
      "lr bert  : 1.4158690176322418e-08\n",
      "lr cri   : 4.654911838790932e-05\n",
      "lr others: 3.76272040302267e-07\n",
      "Train epoch = 0.4156171284634761, loss = 18.277851104736328, policy = 0.5335454344749451, entropy_loss = -0.002664152067154646, gae = 16.222867965698242, kl_div = 0.08372988551855087, reward = 5.525232791900635, ord = 7.049591541290283, repeat = -3.502500295639038, length = -0.12343703955411911, adv = 1.312119960784912, rougeL = 1.3179789781570435, cider = 0.19857195019721985, clip = 0.40249103307724, crf = 0.07583051919937134, ce = 1.364542007446289, unr = 2.101579189300537, ber = 5.647480010986328\n",
      "refe: [CLS] in the image in the center, we can see airplanes. in the background there is a wall, roof and few airplanes, which are in different colors. [SEP]\n",
      "hypo: [CLS] in this image we can see a rocket rockets, in the background i can also there are lights. [SEP]\n",
      "samp: [CLS] in this image we can see a rocket rockets, at the middle. [SEP]\n",
      "lr con   : 1.0035264483627203e-10\n",
      "lr bert  : 1.3239294710327456e-08\n",
      "lr cri   : 4.35264483627204e-05\n",
      "lr others: 3.518387909319899e-07\n",
      "Train epoch = 0.4534005037783375, loss = 18.198833465576172, policy = 0.5319066643714905, entropy_loss = -0.002667289925739169, gae = 16.144792556762695, kl_div = 0.08353259414434433, reward = 5.528928756713867, ord = 7.052196502685547, repeat = -3.502103328704834, length = -0.12442781776189804, adv = 1.3039237260818481, rougeL = 1.3208818435668945, cider = 0.19906285405158997, clip = 0.40266066789627075, crf = 0.07613525539636612, ce = 1.365133285522461, unr = 2.1032626628875732, ber = 5.648338317871094\n",
      "refe: [CLS] here a woman is jumping on the road, here there are trees, here there is a building. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman standing on the road. in the road. in the footpath, there is a road. [SEP]\n",
      "samp: [CLS] in this image we can see a woman and on the road. in the road. in the image. [SEP] on the footpath. in the wall, poles. [SEP]\n",
      "lr con   : 9.338371116708649e-11\n",
      "lr bert  : 1.2319899244332495e-08\n",
      "lr cri   : 4.0503778337531486e-05\n",
      "lr others: 3.2740554156171283e-07\n",
      "Train epoch = 0.491183879093199, loss = 18.298137664794922, policy = 0.6182734966278076, entropy_loss = -0.0026626712642610073, gae = 16.157655715942383, kl_div = 0.08332893997430801, reward = 5.556007385253906, ord = 7.052689552307129, repeat = -3.4805760383605957, length = -0.12668684124946594, adv = 1.3010071516036987, rougeL = 1.3220021724700928, cider = 0.19743075966835022, clip = 0.4023612439632416, crf = 0.0763104036450386, ce = 1.3652317523956299, unr = 2.1105804443359375, ber = 5.6469831466674805\n",
      "refe: [CLS] in this picture we can see legs of two persons, we can see jeans and shoes in the front, there is a dark background. [SEP]\n",
      "hypo: [CLS] in this picture we can see a human legs of shoes. [SEP]\n",
      "samp: [CLS] in this picture we can see two legs of persons shoes. [SEP]\n",
      "lr con   : 8.641477749790091e-11\n",
      "lr bert  : 1.140050377833753e-08\n",
      "lr cri   : 3.7481108312342564e-05\n",
      "lr others: 3.029722921914357e-07\n",
      "Train epoch = 0.5289672544080605, loss = 18.49075698852539, policy = 0.6709737181663513, entropy_loss = -0.0026499745436012745, gae = 16.30082893371582, kl_div = 0.08302491158246994, reward = 5.617802143096924, ord = 7.05064582824707, repeat = -3.4316375255584717, length = -0.12819476425647736, adv = 1.3054476976394653, rougeL = 1.3218861818313599, cider = 0.19678612053394318, clip = 0.4017511308193207, crf = 0.076415054500103, ce = 1.3621619939804077, unr = 2.126988649368286, ber = 5.645754814147949\n",
      "refe: [CLS] in this picture we can see a person holding a poster with hands and in the background it is dark. [SEP]\n",
      "hypo: [CLS] in this image we can see there is a woman. [SEP]\n",
      "samp: [CLS] in this image we can see a person standing. [SEP]\n",
      "lr con   : 7.944584382871536e-11\n",
      "lr bert  : 1.048110831234257e-08\n",
      "lr cri   : 3.4458438287153655e-05\n",
      "lr others: 2.785390428211587e-07\n",
      "Train epoch = 0.5667506297229219, loss = 18.6516170501709, policy = 0.7561821341514587, entropy_loss = -0.0026376747991889715, gae = 16.38031768798828, kl_div = 0.08269677311182022, reward = 5.661648273468018, ord = 7.052709102630615, repeat = -3.4022629261016846, length = -0.12945030629634857, adv = 1.3068095445632935, rougeL = 1.324981451034546, cider = 0.19798098504543304, clip = 0.4012390673160553, crf = 0.07637526094913483, ce = 1.3586792945861816, unr = 2.1406524181365967, ber = 5.644561290740967\n",
      "refe: [CLS] in this image i can see few people standing in - front of glass door, where we can see the reflection of people and a view of trees, water and bird. [SEP]\n",
      "hypo: [CLS] in this image we can see few people standing. in the background i can see the right side. [SEP]\n",
      "samp: [CLS] in this image, we can see a group of people, wall and there is a person there is a person is wearing a person is wearing a glass. [SEP]. [SEP]\n",
      "lr con   : 7.24769101595298e-11\n",
      "lr bert  : 9.561712846347607e-09\n",
      "lr cri   : 3.143576826196473e-05\n",
      "lr others: 2.541057934508816e-07\n",
      "Train epoch = 0.6045340050377834, loss = 18.699684143066406, policy = 0.8104448318481445, entropy_loss = -0.0026330656837671995, gae = 16.37360191345215, kl_div = 0.08255911618471146, reward = 5.682095050811768, ord = 7.048798084259033, repeat = -3.3868041038513184, length = -0.13149063289165497, adv = 1.303615927696228, rougeL = 1.326087474822998, cider = 0.19902068376541138, clip = 0.40073728561401367, crf = 0.07675951719284058, ce = 1.35895574092865, unr = 2.1515917778015137, ber = 5.643862247467041\n",
      "refe: [CLS] in this image i can see number of people, vehicles and a building. i can also see a street light and a traffic cone. [SEP]\n",
      "hypo: [CLS] in this image there is a group of people standing on the road. on the road, there are few people standing. on the background there is a building. [SEP]. [SEP] on the sky. [SEP]\n",
      "samp: [CLS] in this is clicked outside there are few people standing on the road. on the background there are few people standing on the footpath there is a building. [SEP] trees. [SEP] attached to be taken may be a building. [SEP]\n",
      "lr con   : 6.550797649034425e-11\n",
      "lr bert  : 8.642317380352645e-09\n",
      "lr cri   : 2.8413098236775818e-05\n",
      "lr others: 2.2967254408060454e-07\n",
      "Train epoch = 0.6423173803526449, loss = 18.84160614013672, policy = 0.9054088592529297, entropy_loss = -0.00262446072883904, gae = 16.421844482421875, kl_div = 0.08248583972454071, reward = 5.7202677726745605, ord = 7.045560836791992, repeat = -3.356074094772339, length = -0.13287897408008575, adv = 1.3042066097259521, rougeL = 1.3266843557357788, cider = 0.1970980018377304, clip = 0.4005005657672882, crf = 0.07701526582241058, ce = 1.357478380203247, unr = 2.1636593341827393, ber = 5.644047260284424\n",
      "refe: [CLS] in this image we can see a lady wearing white color dress, and an access card, and she has a sticker with some written on it, and the background is blurred. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman is smiling. [SEP]. [SEP]\n",
      "samp: [CLS] in this image, we can see a woman. [SEP] on the image. [SEP]. [SEP]\n",
      "lr con   : 5.853904282115869e-11\n",
      "lr bert  : 7.722921914357682e-09\n",
      "lr cri   : 2.5390428211586902e-05\n",
      "lr others: 2.0523929471032745e-07\n",
      "Train epoch = 0.6801007556675063, loss = 18.934354782104492, policy = 0.9562307000160217, entropy_loss = -0.0026201766449958086, gae = 16.461545944213867, kl_div = 0.08237479627132416, reward = 5.753371238708496, ord = 7.040609359741211, repeat = -3.3277812004089355, length = -0.13526082038879395, adv = 1.3042829036712646, rougeL = 1.3264142274856567, cider = 0.1960543692111969, clip = 0.4002290666103363, crf = 0.07754100114107132, ce = 1.3592849969863892, unr = 2.175804376602173, ber = 5.642887115478516\n",
      "refe: [CLS] in this image we can see one person driving a car on the road, one fence with pole, some green grass on the side of the road, one big white wall and one object on the surface. [SEP]\n",
      "hypo: [CLS] in this image we can see a person there is a car on the background there is a fence, there is a. [SEP]. [SEP]. [SEP]\n",
      "samp: [CLS] in this image we can see a person there is a car, there is a vehicle. [SEP]. [SEP]. [SEP]. [SEP]\n",
      "lr con   : 5.157010915197313e-11\n",
      "lr bert  : 6.8035264483627206e-09\n",
      "lr cri   : 2.2367758186397984e-05\n",
      "lr others: 1.8080604534005037e-07\n",
      "Train epoch = 0.7178841309823678, loss = 18.98153305053711, policy = 1.0045592784881592, entropy_loss = -0.0026183801237493753, gae = 16.46026611328125, kl_div = 0.08229058235883713, reward = 5.776876449584961, ord = 7.039531230926514, repeat = -3.311218500137329, length = -0.13610975444316864, adv = 1.3025743961334229, rougeL = 1.327087640762329, cider = 0.19432194530963898, clip = 0.3998498022556305, crf = 0.07777652889490128, ce = 1.3592605590820312, unr = 2.18467378616333, ber = 5.643230438232422\n",
      "refe: [CLS] in the center of the image, we can see a person sitting on the chair and wearing glasses and a hat and holding a marker and a book. in the background, there are some other people, books, boards, lights, rods, posters on the wall. at the bottom, there is a table and we can see books on it and there is a bottle. [SEP]\n",
      "hypo: [CLS] in this image we can see a man is sitting on the chair and the table and there is a book, there is a book. [SEP] on the table. [SEP]. [SEP]. [SEP]\n",
      "samp: [CLS] in this picture we can see a man sitting on the chair and on the table in front of him we can see the front of this image there is sitting on the table we can see a board. [SEP] standing. [SEP]. [SEP]. [SEP]\n",
      "lr con   : 4.460117548278757e-11\n",
      "lr bert  : 5.884130982367758e-09\n",
      "lr cri   : 1.9345088161209068e-05\n",
      "lr others: 1.563727959697733e-07\n",
      "Train epoch = 0.7556675062972292, loss = 19.05211639404297, policy = 1.0853362083435059, entropy_loss = -0.002617530059069395, gae = 16.444820404052734, kl_div = 0.0822720155119896, reward = 5.792911529541016, ord = 7.036673545837402, repeat = -3.2979578971862793, length = -0.13807807862758636, adv = 1.299484372138977, rougeL = 1.32770574092865, cider = 0.19123663008213043, clip = 0.3997102975845337, crf = 0.07852405309677124, ce = 1.3637794256210327, unr = 2.192274570465088, ber = 5.642224311828613\n",
      "refe: [CLS] on the left side, there is a building which is having windows. on the right side, there are persons sitting on the wall of the building. in the background, there are trees and there are clouds in the sky. [SEP]\n",
      "hypo: [CLS] in this image we can see there is a building and there is a building. [SEP]\n",
      "samp: [CLS] this image consists of the center there is a building, there is a building. [SEP] sky. [SEP] sky. [SEP]\n",
      "lr con   : 3.7632241813602014e-11\n",
      "lr bert  : 4.964735516372796e-09\n",
      "lr cri   : 1.632241813602015e-05\n",
      "lr others: 1.3193954659949622e-07\n",
      "Train epoch = 0.7934508816120907, loss = 19.102346420288086, policy = 1.1537754535675049, entropy_loss = -0.0026128538884222507, gae = 16.426986694335938, kl_div = 0.08217780292034149, reward = 5.804795265197754, ord = 7.03900671005249, repeat = -3.2945613861083984, length = -0.13900575041770935, adv = 1.296250581741333, rougeL = 1.330888271331787, cider = 0.1925305724143982, clip = 0.3995991051197052, crf = 0.07870033383369446, ce = 1.3633198738098145, unr = 2.1993565559387207, ber = 5.642333030700684\n",
      "refe: [CLS] in this picture there is a goat who is sitting on the table, beside that we can see the stairs. in the background we can see wooden fencing and brick wall. on the right there is a wooden barrel near to the door. in front of the door we can see green grass. at the top we can see many trees. [SEP]\n",
      "hypo: [CLS] in this image we can see a dog and on the ground, we can see grass, grass, there is a. [SEP]\n",
      "samp: [CLS] in this image we can see a fence, grass on a wooden table we can see a bench. we can see the right side there is a. [SEP]. [SEP]. [SEP]\n",
      "lr con   : 3.066330814441645e-11\n",
      "lr bert  : 4.045340050377834e-09\n",
      "lr cri   : 1.3299748110831234e-05\n",
      "lr others: 1.0750629722921913e-07\n",
      "Train epoch = 0.8312342569269522, loss = 19.147401809692383, policy = 1.1994612216949463, entropy_loss = -0.0026085812132805586, gae = 16.42575454711914, kl_div = 0.08195909857749939, reward = 5.821138858795166, ord = 7.037045478820801, repeat = -3.2820088863372803, length = -0.1396317034959793, adv = 1.2941983938217163, rougeL = 1.3310822248458862, cider = 0.19200831651687622, clip = 0.39957869052886963, crf = 0.07901423424482346, ce = 1.3638230562210083, unr = 2.2057342529296875, ber = 5.64210319519043\n",
      "refe: [CLS] in this image, there is a man holding a white color plate and there is a ice cream, the man is holding a spoon and he is looking at the ice cream, in the background there are some people sitting and there is a wall. [SEP]\n",
      "hypo: [CLS] in this image we can see a man standing and holding a person is a person is a plate. [SEP]. [SEP]\n",
      "samp: [CLS] in this image i can see a person there is holding a person is a person is holding an object. [SEP]. [SEP]. [SEP]\n",
      "lr con   : 2.3694374475230897e-11\n",
      "lr bert  : 3.1259445843828713e-09\n",
      "lr cri   : 1.0277078085642317e-05\n",
      "lr others: 8.307304785894206e-08\n",
      "Train epoch = 0.8690176322418136, loss = 19.21025848388672, policy = 1.2421365976333618, entropy_loss = -0.0026026666164398193, gae = 16.44717788696289, kl_div = 0.08192119747400284, reward = 5.842268466949463, ord = 7.038944721221924, repeat = -3.268681526184082, length = -0.14051295816898346, adv = 1.2931894063949585, rougeL = 1.3332593441009521, cider = 0.19081947207450867, clip = 0.3992781639099121, crf = 0.07904330641031265, ce = 1.362584114074707, unr = 2.2125191688537598, ber = 5.642726898193359\n",
      "refe: [CLS] in this picture i can observe some people jumping. on the right side there are some people standing on the floor. in the background i can observe a wall. [SEP]\n",
      "hypo: [CLS] in this image we can see a group of people, boxing. [SEP]\n",
      "samp: [CLS] in this image we can see a person is a floor. at the person standing. [SEP]\n",
      "lr con   : 1.6725440806045338e-11\n",
      "lr bert  : 2.206549118387909e-09\n",
      "lr cri   : 7.2544080604534e-06\n",
      "lr others: 5.863979848866498e-08\n",
      "Train epoch = 0.906801007556675, loss = 19.245763778686523, policy = 1.2953044176101685, entropy_loss = -0.002600656123831868, gae = 16.429235458374023, kl_div = 0.08202727884054184, reward = 5.855730056762695, ord = 7.037600994110107, repeat = -3.2588753700256348, length = -0.14140085875988007, adv = 1.291097640991211, rougeL = 1.3331365585327148, cider = 0.19071531295776367, clip = 0.3990466594696045, crf = 0.07918126881122589, ce = 1.3626142740249634, unr = 2.2184054851531982, ber = 5.642698287963867\n",
      "refe: [CLS] in the center of the image there are people standing on the road. in the background of the image there are buildings, trees. [SEP]\n",
      "hypo: [CLS] in this image i can see a group of people standing in front of people are trees, trees, we can see the background there are standing. [SEP]. [SEP]. [SEP]\n",
      "samp: [CLS] in this picture we can see a group of persons standing. they are holding a man standing and the right side, we can see the background there are trees. [SEP]. [SEP] there are trees. [SEP]\n",
      "lr con   : 9.75650713685978e-12\n",
      "lr bert  : 1.287153652392947e-09\n",
      "lr cri   : 4.231738035264483e-06\n",
      "lr others: 3.4206549118387904e-08\n",
      "Train epoch = 0.9445843828715366, loss = 19.301647186279297, policy = 1.3378857374191284, entropy_loss = -0.0025952011346817017, gae = 16.443347930908203, kl_div = 0.08196467161178589, reward = 5.873569965362549, ord = 7.038072109222412, repeat = -3.246746063232422, length = -0.1419087052345276, adv = 1.290264368057251, rougeL = 1.3348976373672485, cider = 0.19006207585334778, clip = 0.3991754949092865, crf = 0.07929601520299911, ce = 1.3617445230484009, unr = 2.2241528034210205, ber = 5.642493724822998\n",
      "refe: [CLS] in this image, i can see a building with windows and a door. in front a building, there are plants and a car, which is parked. [SEP]\n",
      "hypo: [CLS] in this image there is a car on the road. in the background there is a building there is a building. [SEP] attached to the right side. [SEP]\n",
      "samp: [CLS] in this image there is a car on the road. at the back there is a building there is a building. [SEP] attached to the right side there is a car. [SEP] plants. [SEP]\n",
      "lr con   : 2.787573467674223e-12\n",
      "lr bert  : 3.677581863979849e-10\n",
      "lr cri   : 1.2090680100755668e-06\n",
      "lr others: 9.773299748110832e-09\n",
      "Train epoch = 0.982367758186398, loss = 19.324743270874023, policy = 1.3816457986831665, entropy_loss = -0.00259168678894639, gae = 16.424222946166992, kl_div = 0.08195896446704865, reward = 5.884186744689941, ord = 7.038384914398193, repeat = -3.2400715351104736, length = -0.14229486882686615, adv = 1.288109302520752, rougeL = 1.33608877658844, cider = 0.18895407021045685, clip = 0.3990640342235565, crf = 0.07932966202497482, ce = 1.3601759672164917, unr = 2.2281687259674072, ber = 5.642591953277588\n",
      "refe: [CLS] in this picture we can see a man running on the ground, grass, trees and in the background we can see the sky with clouds. [SEP]\n",
      "hypo: [CLS] in this image there is a person standing on the person is a person in the background there is grass, grass. [SEP]\n",
      "samp: [CLS] in the image we can see a person standing on a person standing on the background i can see the grass, grass. [SEP]\n",
      "bsz 56 is not batch_size 128. skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 06:54:06,112] Trial 4 finished with value: 1.5900936126708984 and parameters: {'config.betas': 3, 'config.len_coef': 2.5629865708781714, 'config.unr_coef': 3.280174676212547, 'config.crf_coef': 0.08943129344455958, 'config.ce_coef': 0.6582918721091665, 'config.gae_coef': 2.8799846933084483, 'config.clip_range': 0.12066350268297439, 'clip_grad_threshold': 1.7242104401200835}. Best is trial 4 with value: 1.5900936126708984.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, avg_reward = 1.5900936126708984\n",
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.23537726324159317\n",
      "clip_grad_threshold gradient norm: 1.3749604274296316\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 4.174019119616679\n",
      "unr_coef: 3.7862492663005307\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.20499838366727663\n",
      "ce_coef: 0.661358677005822\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 3.8856897510127375\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_065419.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecfa8abfa02d485caa16ec5a51f11b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 15.628486633300781, policy = 6.513496941806807e-08, entropy_loss = -0.0027723482344299555, gae = 14.057670593261719, kl_div = 0.07934118062257767, reward = 4.811633586883545, ord = 7.044802188873291, repeat = -4.322145462036133, length = -0.16728971898555756, adv = 1.0318071842193604, rougeL = 1.2054921388626099, cider = 0.25307679176330566, clip = 0.3954637050628662, crf = 0.15460023283958435, ce = 1.339647650718689, unr = 2.2562668323516846, ber = 5.679548740386963\n",
      "refe: [CLS] a person is holding an object, here people are standing. [SEP]\n",
      "hypo: [CLS] in this image there is a person wearing a person standing and we can see there is blurred. [SEP]\n",
      "samp: [CLS] in this image there is a person wearing a person standing and we can see there is a group of the ground. [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 18.384822845458984, policy = 0.21196740865707397, entropy_loss = -0.0025162026286125183, gae = 16.525741577148438, kl_div = 0.07318667322397232, reward = 5.256843090057373, ord = 7.078307628631592, repeat = -3.935743808746338, length = -0.21319657564163208, adv = 1.1164157390594482, rougeL = 1.2931957244873047, cider = 0.24233396351337433, clip = 0.40229129791259766, crf = 0.23065471649169922, ce = 1.345788598060608, unr = 2.3274762630462646, ber = 5.668532371520996\n",
      "refe: [CLS] in this image there is a dead bird on the ground. at the bottom of the image there is a dried grass and a stones on the surface. [SEP]\n",
      "hypo: [CLS] in this image we can see a bird on the center of the ground. [SEP]\n",
      "samp: [CLS] in this image we can see a bird on the center of the ground. on the ground. [SEP]\n",
      "lr con   : 1.2962216624685136e-10\n",
      "lr bert  : 1.7100755667506296e-08\n",
      "lr cri   : 5.622166246851385e-05\n",
      "lr others: 4.544584382871536e-07\n",
      "Train epoch = 0.07556675062972293, loss = 19.18587303161621, policy = 0.14407019317150116, entropy_loss = -0.002388965804129839, gae = 17.339021682739258, kl_div = 0.07516634464263916, reward = 5.459982872009277, ord = 7.090442657470703, repeat = -3.780189037322998, length = -0.22980794310569763, adv = 1.1485397815704346, rougeL = 1.3308769464492798, cider = 0.2224857360124588, clip = 0.4027242362499237, crf = 0.26704391837120056, ce = 1.3629599809646606, unr = 2.37953782081604, ber = 5.6719136238098145\n",
      "refe: [CLS] in this picture there is a person standing and smiling and he is holding the object. at the back there is a hoarding and there is a text on the hoarding. [SEP]\n",
      "hypo: [CLS] in this image there is a person is a man standing. in his hand. [SEP]\n",
      "samp: [CLS] in this image there is a man who is wearing suit. in his hand. in his hand standing and smiling. [SEP]\n",
      "lr con   : 1.6307304785894207e-10\n",
      "lr bert  : 2.1513853904282117e-08\n",
      "lr cri   : 7.073047858942065e-05\n",
      "lr others: 5.717380352644836e-07\n",
      "Train epoch = 0.11335012594458438, loss = 19.691009521484375, policy = 0.11654772609472275, entropy_loss = -0.0023708967491984367, gae = 17.859210968017578, kl_div = 0.07542525231838226, reward = 5.6055216789245605, ord = 7.104849338531494, repeat = -3.6781508922576904, length = -0.23162464797496796, adv = 1.1678402423858643, rougeL = 1.3361037969589233, cider = 0.22658519446849823, clip = 0.40196457505226135, crf = 0.2685393691062927, ce = 1.3736602067947388, unr = 2.4104480743408203, ber = 5.6675004959106445\n",
      "refe: [CLS] in this image at front there are six people sitting in front of musical instruments. at the bottom there is a mat. at the back side there is a statue and there are plants. behind the statue there is a wall and we can see lights at the top. [SEP]\n",
      "hypo: [CLS] in this image we can see a group of people, we can also there are sitting. [SEP]\n",
      "samp: [CLS] in this image i can see a group of people sitting in the center of the game. [SEP] there is a wall. [SEP]\n",
      "lr con   : 1.561041141897565e-10\n",
      "lr bert  : 2.0594458438287153e-08\n",
      "lr cri   : 6.770780856423173e-05\n",
      "lr others: 5.473047858942065e-07\n",
      "Train epoch = 0.15113350125944586, loss = 19.91452407836914, policy = 0.1020040437579155, entropy_loss = -0.0023228353820741177, gae = 18.087806701660156, kl_div = 0.07622279226779938, reward = 5.698273181915283, ord = 7.104146957397461, repeat = -3.6129496097564697, length = -0.22568276524543762, adv = 1.174919605255127, rougeL = 1.3431682586669922, cider = 0.21647414565086365, clip = 0.4031778872013092, crf = 0.2796482443809509, ce = 1.3711673021316528, unr = 2.4327595233917236, ber = 5.664860248565674\n",
      "refe: [CLS] in this image, we can see people standing and are wearing uniforms and caps. in the background, there are some machines and equipment and some other rods and objects. [SEP]\n",
      "hypo: [CLS] in this image we can see few persons are standing. in the right side we can also there are standing. [SEP]\n",
      "samp: [CLS] in this image i can see few persons are two persons are standing and in the work we can also there are working\n",
      "lr con   : 1.4913518052057094e-10\n",
      "lr bert  : 1.9675062972292192e-08\n",
      "lr cri   : 6.468513853904282e-05\n",
      "lr others: 5.228715365239295e-07\n",
      "Train epoch = 0.1889168765743073, loss = 20.29362678527832, policy = 0.09221567213535309, entropy_loss = -0.0022819791920483112, gae = 18.476472854614258, kl_div = 0.0765395313501358, reward = 5.799394607543945, ord = 7.097805976867676, repeat = -3.518460512161255, length = -0.22166326642036438, adv = 1.1836304664611816, rougeL = 1.3473156690597534, cider = 0.22128809988498688, clip = 0.40311381220817566, crf = 0.28577810525894165, ce = 1.3649026155471802, unr = 2.441713571548462, ber = 5.662359237670898\n",
      "refe: [CLS] in the picture we can see magazine with some information and images on it. [SEP]\n",
      "hypo: [CLS] in this image, we can see a poster. [SEP] images and some text. [SEP]\n",
      "samp: [CLS] in this image, we can see number of this poster. [SEP] stamps we can see people. [SEP]\n",
      "lr con   : 1.4216624685138537e-10\n",
      "lr bert  : 1.8755667506297228e-08\n",
      "lr cri   : 6.16624685138539e-05\n",
      "lr others: 4.984382871536523e-07\n",
      "Train epoch = 0.22670025188916876, loss = 20.20293617248535, policy = 0.08722495287656784, entropy_loss = -0.002265374409034848, gae = 18.379865646362305, kl_div = 0.07675771415233612, reward = 5.804073333740234, ord = 7.092416763305664, repeat = -3.5117757320404053, length = -0.22372612357139587, adv = 1.1733450889587402, rougeL = 1.3511379957199097, cider = 0.21702377498149872, clip = 0.40237197279930115, crf = 0.29200002551078796, ce = 1.3693565130233765, unr = 2.4471590518951416, ber = 5.66055154800415\n",
      "refe: [CLS] this is the picture of a waterfall. in this image there is a waterfall. at the back there is a crane and there are poles and there is a building and there are trees. at the top there are clouds. at the bottom there is water and there is grass. [SEP]\n",
      "hypo: [CLS] in this image we can see water, trees, trees, trees, we can see water. in the background we can see trees, trees. [SEP]\n",
      "samp: [CLS] in this image i can see water, trees, trees, trees, we can see background we can see background we can see sky in the sky. [SEP]\n",
      "lr con   : 1.3519731318219982e-10\n",
      "lr bert  : 1.7836272040302267e-08\n",
      "lr cri   : 5.863979848866499e-05\n",
      "lr others: 4.740050377833753e-07\n",
      "Train epoch = 0.26448362720403024, loss = 20.378828048706055, policy = 0.08197837322950363, entropy_loss = -0.002239757217466831, gae = 18.56132698059082, kl_div = 0.07717619091272354, reward = 5.862686634063721, ord = 7.10111665725708, repeat = -3.4728662967681885, length = -0.2257051318883896, adv = 1.1732525825500488, rougeL = 1.3568178415298462, cider = 0.21452857553958893, clip = 0.4020286500453949, crf = 0.2951202392578125, ce = 1.3654675483703613, unr = 2.460141897201538, ber = 5.66162109375\n",
      "refe: [CLS] this is an animated image. in this image we can see many gunny bags. also there is a girl wearing cap and she is sitting on a bag. [SEP]\n",
      "hypo: [CLS] in this image i can see a person on the image. on the image. [SEP]\n",
      "samp: [CLS] in this image i can see a woman is lying on the image. [SEP]\n",
      "lr con   : 1.2822837951301427e-10\n",
      "lr bert  : 1.6916876574307306e-08\n",
      "lr cri   : 5.561712846347607e-05\n",
      "lr others: 4.495717884130982e-07\n",
      "Train epoch = 0.3022670025188917, loss = 20.123706817626953, policy = 0.14878475666046143, entropy_loss = -0.002250025048851967, gae = 18.24372100830078, kl_div = 0.0775146409869194, reward = 5.827455043792725, ord = 7.08845329284668, repeat = -3.497734785079956, length = -0.22464199364185333, adv = 1.1555814743041992, rougeL = 1.3489397764205933, cider = 0.21004171669483185, clip = 0.40186095237731934, crf = 0.2873644530773163, ce = 1.36857008934021, unr = 2.461379051208496, ber = 5.65986442565918\n",
      "refe: [CLS] this picture is taken during night, a person stand on rock in the middle, at the top i can see darkness. [SEP]\n",
      "hypo: [CLS] in this image we can see two persons are standing on the person standing. [SEP]\n",
      "samp: [CLS] in this picture we can see two persons are two persons are standing on the background there are standing. [SEP]\n",
      "lr con   : 1.2125944584382872e-10\n",
      "lr bert  : 1.5997481108312342e-08\n",
      "lr cri   : 5.2594458438287154e-05\n",
      "lr others: 4.2513853904282117e-07\n",
      "Train epoch = 0.34005037783375314, loss = 19.745908737182617, policy = 0.14830829203128815, entropy_loss = -0.0022555345203727484, gae = 17.8763427734375, kl_div = 0.07783400267362595, reward = 5.779052734375, ord = 7.0798258781433105, repeat = -3.535433292388916, length = -0.22280952334403992, adv = 1.135857343673706, rougeL = 1.3399287462234497, cider = 0.21393123269081116, clip = 0.40235066413879395, crf = 0.2797652781009674, ce = 1.365914225578308, unr = 2.4574711322784424, ber = 5.659113883972168\n",
      "refe: [CLS] in this image i can see a food in few plates. food is in red, brown and cream color. i can see a wooden box and wooden path. the sky is in blue color. [SEP]\n",
      "hypo: [CLS] in this image we can see depiction of this image, we can also see the cages\n",
      "samp: [CLS] in this image i can see depiction of this looks like a miniature i can see a table\n",
      "lr con   : 1.1429051217464315e-10\n",
      "lr bert  : 1.507808564231738e-08\n",
      "lr cri   : 4.957178841309823e-05\n",
      "lr others: 4.0070528967254406e-07\n",
      "Train epoch = 0.3778337531486146, loss = 19.562910079956055, policy = 0.13949888944625854, entropy_loss = -0.0022418522275984287, gae = 17.700040817260742, kl_div = 0.07805100083351135, reward = 5.779776096343994, ord = 7.072690010070801, repeat = -3.538175344467163, length = -0.22326438128948212, adv = 1.1255073547363281, rougeL = 1.3361139297485352, cider = 0.2099253237247467, clip = 0.40242937207221985, crf = 0.279662549495697, ce = 1.367897868156433, unr = 2.46852707862854, ber = 5.659234046936035\n",
      "refe: [CLS] in this image i can see the group of people with black and grey color dresses. and i can see some frames to the wall. and there is a blurred background. [SEP]\n",
      "hypo: [CLS] in this image we can see few people sitting in the background there is sitting on the background we can see chairs. [SEP]\n",
      "samp: [CLS] in this image we can see few people on the background i can see background we can see chairs. [SEP] other objects. [SEP]\n",
      "lr con   : 1.073215785054576e-10\n",
      "lr bert  : 1.4158690176322418e-08\n",
      "lr cri   : 4.654911838790932e-05\n",
      "lr others: 3.76272040302267e-07\n",
      "Train epoch = 0.4156171284634761, loss = 19.433618545532227, policy = 0.13212019205093384, entropy_loss = -0.002232795814052224, gae = 17.578651428222656, kl_div = 0.0781661868095398, reward = 5.780496597290039, ord = 7.071262359619141, repeat = -3.543532609939575, length = -0.22169919312000275, adv = 1.1155133247375488, rougeL = 1.335149884223938, cider = 0.21056699752807617, clip = 0.40256503224372864, crf = 0.27922871708869934, ce = 1.3676844835281372, unr = 2.474466323852539, ber = 5.659572601318359\n",
      "refe: [CLS] there is a woodpecker on a tree. [SEP]\n",
      "hypo: [CLS] in this image we can see a bird on the branch of the tree on the background there is a tree. [SEP]\n",
      "samp: [CLS] in this image we can see a bird on the branch of a tree on the background there is a bird. [SEP]\n",
      "lr con   : 1.0035264483627203e-10\n",
      "lr bert  : 1.3239294710327456e-08\n",
      "lr cri   : 4.35264483627204e-05\n",
      "lr others: 3.518387909319899e-07\n",
      "Train epoch = 0.4534005037783375, loss = 19.427946090698242, policy = 0.1326741874217987, entropy_loss = -0.0022225556895136833, gae = 17.572317123413086, kl_div = 0.07839874923229218, reward = 5.801651954650879, ord = 7.0750346183776855, repeat = -3.5273568630218506, length = -0.22214731574058533, adv = 1.1098958253860474, rougeL = 1.337789535522461, cider = 0.21029381453990936, clip = 0.4027153253555298, crf = 0.278888076543808, ce = 1.367889404296875, unr = 2.4761219024658203, ber = 5.658552646636963\n",
      "refe: [CLS] in this image there is floor. there is grass. there is a egg tray. there is a mouse. at the top there is a red color basket. [SEP]\n",
      "hypo: [CLS] in this image we can see an animal there is a bowl, there is placed on it. in the table, we can see some food items. [SEP] objects. [SEP]\n",
      "samp: [CLS] in this image i can see a rat with some food item and there is placed on it. in we can see a table we can also we can see some object. [SEP] object. [SEP]\n",
      "lr con   : 9.338371116708649e-11\n",
      "lr bert  : 1.2319899244332495e-08\n",
      "lr cri   : 4.0503778337531486e-05\n",
      "lr others: 3.2740554156171283e-07\n",
      "Train epoch = 0.491183879093199, loss = 19.688669204711914, policy = 0.1265963762998581, entropy_loss = -0.002200283110141754, gae = 17.840068817138672, kl_div = 0.07838313281536102, reward = 5.875598430633545, ord = 7.089297294616699, repeat = -3.4774539470672607, length = -0.22185549139976501, adv = 1.114698052406311, rougeL = 1.3442093133926392, cider = 0.21577802300453186, clip = 0.40264302492141724, crf = 0.2816900908946991, ce = 1.364132046699524, unr = 2.4856109619140625, ber = 5.659116744995117\n",
      "refe: [CLS] in this image we can see the players in the stadium. and we can see some people sitting. and we can see the net. and we can see the boundary wall and we can see the cloth banners. [SEP]\n",
      "hypo: [CLS] in this image there are a stadium. in the ground. in the ground. in the ground. [SEP]\n",
      "samp: [CLS] in this image there is a stadium. we can see the ground there is a football. [SEP]\n",
      "lr con   : 8.641477749790091e-11\n",
      "lr bert  : 1.140050377833753e-08\n",
      "lr cri   : 3.7481108312342564e-05\n",
      "lr others: 3.029722921914357e-07\n",
      "Train epoch = 0.5289672544080605, loss = 19.719440460205078, policy = 0.12211195379495621, entropy_loss = -0.002182070631533861, gae = 17.876447677612305, kl_div = 0.07839520275592804, reward = 5.907656669616699, ord = 7.089082717895508, repeat = -3.4508185386657715, length = -0.2212778627872467, adv = 1.1117799282073975, rougeL = 1.3462992906570435, cider = 0.21223895251750946, clip = 0.40285465121269226, crf = 0.28387153148651123, ce = 1.3607977628707886, unr = 2.4906702041625977, ber = 5.658077716827393\n",
      "refe: [CLS] this image is taken indoors. at the bottom of the image there is a floor. on the right side of the image there is a table and an empty chair. on the left side of the image there is a plant and there are two chairs and a table. in the middle of the image there is a cupboard with a few things. in the background there is a wall with a window and a picture frame. [SEP]\n",
      "hypo: [CLS] in this image i can see tables there are chairs. at the table, we can see chairs, we can see chairs. [SEP]\n",
      "samp: [CLS] in this image i can see tables there are chairs. at the table and i can see a chair and the background i can see a chair, doors. [SEP]\n",
      "lr con   : 7.944584382871536e-11\n",
      "lr bert  : 1.048110831234257e-08\n",
      "lr cri   : 3.4458438287153655e-05\n",
      "lr others: 2.785390428211587e-07\n",
      "Train epoch = 0.5667506297229219, loss = 19.81757164001465, policy = 0.12484357506036758, entropy_loss = -0.002166192280128598, gae = 17.969829559326172, kl_div = 0.07845475524663925, reward = 5.9507951736450195, ord = 7.092159748077393, repeat = -3.41664457321167, length = -0.22190243005752563, adv = 1.1113585233688354, rougeL = 1.3486801385879517, cider = 0.21458163857460022, clip = 0.40321946144104004, crf = 0.2863615155220032, ce = 1.3602502346038818, unr = 2.4971821308135986, ber = 5.658125400543213\n",
      "refe: [CLS] in this image we can see stones, concrete bricks, memento and grass. [SEP]\n",
      "hypo: [CLS] in this image we can see a grass, we can see grass, there is grass. [SEP]\n",
      "samp: [CLS] in this image there is a wooden grass, grass with some text. i can see a grassy land. [SEP]\n",
      "lr con   : 7.24769101595298e-11\n",
      "lr bert  : 9.561712846347607e-09\n",
      "lr cri   : 3.143576826196473e-05\n",
      "lr others: 2.541057934508816e-07\n",
      "Train epoch = 0.6045340050377834, loss = 19.885528564453125, policy = 0.13639824092388153, entropy_loss = -0.002159130061045289, gae = 18.032329559326172, kl_div = 0.07848453521728516, reward = 5.986266613006592, ord = 7.094767093658447, repeat = -3.390836238861084, length = -0.22092054784297943, adv = 1.109847903251648, rougeL = 1.3467515707015991, cider = 0.21552690863609314, clip = 0.40323373675346375, crf = 0.28467029333114624, ce = 1.3558073043823242, unr = 2.5032553672790527, ber = 5.658950328826904\n",
      "refe: [CLS] in this picture we can see the branches, green leaves. we can see the zebras and grass. [SEP]\n",
      "hypo: [CLS] in this image we can see two animals are standing. we can see there are trees. [SEP]\n",
      "samp: [CLS] in this image i can see two animals sitting on the bottom of the middle of trees. [SEP] grass. [SEP]\n",
      "lr con   : 6.550797649034425e-11\n",
      "lr bert  : 8.642317380352645e-09\n",
      "lr cri   : 2.8413098236775818e-05\n",
      "lr others: 2.2967254408060454e-07\n",
      "Train epoch = 0.6423173803526449, loss = 19.850629806518555, policy = 0.14903545379638672, entropy_loss = -0.0021533153485506773, gae = 17.986963272094727, kl_div = 0.07849745452404022, reward = 5.999076843261719, ord = 7.096506595611572, repeat = -3.3837122917175293, length = -0.22034433484077454, adv = 1.1043016910552979, rougeL = 1.3452636003494263, cider = 0.21883392333984375, clip = 0.40348130464553833, crf = 0.283687561750412, ce = 1.3545998334884644, unr = 2.5066261291503906, ber = 5.6599016189575195\n",
      "refe: [CLS] in this image, we can see bed, pillows, cushions. and there is a tables on the right side and left side, few items are placed on it. background, there is a wall. in the middle of the image, we can see some toy. [SEP]\n",
      "hypo: [CLS] in this image we can see there is a bed, a bed, there is a lamp, there is a bed. [SEP]\n",
      "samp: [CLS] in this picture we can see a bed. on a bed. i can see a lamp, we can pillows. [SEP]\n",
      "lr con   : 5.853904282115869e-11\n",
      "lr bert  : 7.722921914357682e-09\n",
      "lr cri   : 2.5390428211586902e-05\n",
      "lr others: 2.0523929471032745e-07\n",
      "Train epoch = 0.6801007556675063, loss = 19.808609008789062, policy = 0.16586537659168243, entropy_loss = -0.002147622173652053, gae = 17.929208755493164, kl_div = 0.07853974401950836, reward = 6.010380268096924, ord = 7.096076488494873, repeat = -3.376142978668213, length = -0.22088322043418884, adv = 1.0988662242889404, rougeL = 1.346411943435669, cider = 0.21666567027568817, clip = 0.4034271538257599, crf = 0.28291580080986023, ce = 1.35422682762146, unr = 2.511328935623169, ber = 5.6609673500061035\n",
      "refe: [CLS] this is the picture of a lady in white jacket sitting on the chair in front of a table and on the table there is a system. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman sitting on the chair on the table there is a table and a table. [SEP]\n",
      "samp: [CLS] in this image we can see a woman sitting in front of chair and she is laptop. on a table. on the table. [SEP]\n",
      "lr con   : 5.157010915197313e-11\n",
      "lr bert  : 6.8035264483627206e-09\n",
      "lr cri   : 2.2367758186397984e-05\n",
      "lr others: 1.8080604534005037e-07\n",
      "Train epoch = 0.7178841309823678, loss = 19.615806579589844, policy = 0.16083796322345734, entropy_loss = -0.002151739550754428, gae = 17.744483947753906, kl_div = 0.0786883607506752, reward = 5.988217353820801, ord = 7.0962066650390625, repeat = -3.3967227935791016, length = -0.22052016854286194, adv = 1.0874630212783813, rougeL = 1.3445578813552856, cider = 0.21636027097702026, clip = 0.4033401310443878, crf = 0.2797302305698395, ce = 1.354217290878296, unr = 2.5092544555664062, ber = 5.661648273468018\n",
      "refe: [CLS] front this man is sitting and holding an object. far this person is riding a surfboard on water. [SEP]\n",
      "hypo: [CLS] in this image i can see a person sitting on the image there is a person is holding an object. [SEP] ocean. [SEP]\n",
      "samp: [CLS] in this image i can see a person sitting on the image there is a person is holding an object. [SEP]\n",
      "lr con   : 4.460117548278757e-11\n",
      "lr bert  : 5.884130982367758e-09\n",
      "lr cri   : 1.9345088161209068e-05\n",
      "lr others: 1.563727959697733e-07\n",
      "Train epoch = 0.7556675062972292, loss = 19.68597984313965, policy = 0.16650767624378204, entropy_loss = -0.002149144420400262, gae = 17.8065242767334, kl_div = 0.07876881957054138, reward = 6.0171685218811035, ord = 7.092614650726318, repeat = -3.368797540664673, length = -0.22252383828163147, adv = 1.0864183902740479, rougeL = 1.3475896120071411, cider = 0.2124362587928772, clip = 0.40321242809295654, crf = 0.2801869213581085, ce = 1.3561391830444336, unr = 2.5158751010894775, ber = 5.660190105438232\n",
      "refe: [CLS] in this image we can see there is a shed and in front of the shed there is an object looks like a machine. and there is grass and trees. [SEP]\n",
      "hypo: [CLS] in this image we can see there is made up of the image. [SEP]\n",
      "samp: [CLS] in this image i can see there is a building. at the ground. [SEP]\n",
      "lr con   : 3.7632241813602014e-11\n",
      "lr bert  : 4.964735516372796e-09\n",
      "lr cri   : 1.632241813602015e-05\n",
      "lr others: 1.3193954659949622e-07\n",
      "Train epoch = 0.7934508816120907, loss = 19.738218307495117, policy = 0.16208401322364807, entropy_loss = -0.0021381196565926075, gae = 17.8614501953125, kl_div = 0.07884793728590012, reward = 6.047924995422363, ord = 7.095419406890869, repeat = -3.3449854850769043, length = -0.2229146808385849, adv = 1.0856987237930298, rougeL = 1.3502118587493896, cider = 0.21282970905303955, clip = 0.4032326340675354, crf = 0.28210002183914185, ce = 1.355873465538025, unr = 2.5204057693481445, ber = 5.660506725311279\n",
      "refe: [CLS] in this image we can see a vehicle which is in green color. [SEP]\n",
      "hypo: [CLS] in this image we can see a vehicle with some text on it. [SEP]\n",
      "samp: [CLS] in this picture, we can see a vehicle with some text on the car. [SEP]\n",
      "lr con   : 3.066330814441645e-11\n",
      "lr bert  : 4.045340050377834e-09\n",
      "lr cri   : 1.3299748110831234e-05\n",
      "lr others: 1.0750629722921913e-07\n",
      "Train epoch = 0.8312342569269522, loss = 19.77376937866211, policy = 0.15676313638687134, entropy_loss = -0.00212864694185555, gae = 17.901018142700195, kl_div = 0.07880619168281555, reward = 6.0728020668029785, ord = 7.097004413604736, repeat = -3.325380802154541, length = -0.22364600002765656, adv = 1.084197759628296, rougeL = 1.3519567251205444, cider = 0.21159756183624268, clip = 0.4031408429145813, crf = 0.28386732935905457, ce = 1.3554438352584839, unr = 2.524824380874634, ber = 5.661084175109863\n",
      "refe: [CLS] many people are sitting on the chairs. and there are tables. on the tables there are books, not containing a plant, bottles, glasses, plate, food items. a lady wearing a white dress is having a mobile phone. she is wearing a cap. behind there is a building. there are umbrellas. [SEP]\n",
      "hypo: [CLS] in this image we can see a group of people. on the table there is a table. on the table. [SEP]\n",
      "samp: [CLS] in this image i can see a group of people on chairs and a table. on the table, there is a table. on the table. [SEP]rs. [SEP]\n",
      "lr con   : 2.3694374475230897e-11\n",
      "lr bert  : 3.1259445843828713e-09\n",
      "lr cri   : 1.0277078085642317e-05\n",
      "lr others: 8.307304785894206e-08\n",
      "Train epoch = 0.8690176322418136, loss = 19.860549926757812, policy = 0.18800577521324158, entropy_loss = -0.002129180124029517, gae = 17.958791732788086, kl_div = 0.07887014746665955, reward = 6.100502014160156, ord = 7.096401691436768, repeat = -3.303743600845337, length = -0.22507743537425995, adv = 1.0838685035705566, rougeL = 1.355473518371582, cider = 0.20984601974487305, clip = 0.403009295463562, crf = 0.281369686126709, ce = 1.3556406497955322, unr = 2.5329220294952393, ber = 5.660463809967041\n",
      "refe: [CLS] in this image, we can see a wall, few plants, statue, few decorative pieces. on the right side, we can see a person is sitting on the wall and keeping a blue color carry bag on her lap. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman is a woman is a tree. on the right side of a building. we can see a person. [SEP]\n",
      "samp: [CLS] in this image we can see a woman is one person sitting, plants, plants, plants, there is a building. we can see a fence. [SEP]\n",
      "lr con   : 1.6725440806045338e-11\n",
      "lr bert  : 2.206549118387909e-09\n",
      "lr cri   : 7.2544080604534e-06\n",
      "lr others: 5.863979848866498e-08\n",
      "Train epoch = 0.906801007556675, loss = 19.882488250732422, policy = 0.19088390469551086, entropy_loss = -0.0021269458811730146, gae = 17.97727394104004, kl_div = 0.07887498289346695, reward = 6.118721008300781, ord = 7.0950469970703125, repeat = -3.2888333797454834, length = -0.22612065076828003, adv = 1.0820523500442505, rougeL = 1.3571044206619263, cider = 0.2077706903219223, clip = 0.40293005108833313, crf = 0.28134867548942566, ce = 1.3562325239181519, unr = 2.538627862930298, ber = 5.659300327301025\n",
      "refe: [CLS] in this image there is a little girl with a smile on her face. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman smiling. [SEP]\n",
      "samp: [CLS] in this picture we can see a girl. [SEP]\n",
      "lr con   : 9.75650713685978e-12\n",
      "lr bert  : 1.287153652392947e-09\n",
      "lr cri   : 4.231738035264483e-06\n",
      "lr others: 3.4206549118387904e-08\n",
      "Train epoch = 0.9445843828715366, loss = 19.88007164001465, policy = 0.19614581763744354, entropy_loss = -0.0021237290930002928, gae = 17.96807289123535, kl_div = 0.0789412185549736, reward = 6.1285400390625, ord = 7.093785285949707, repeat = -3.2803022861480713, length = -0.22751650214195251, adv = 1.078773856163025, rougeL = 1.3572496175765991, cider = 0.2059563845396042, clip = 0.4029063582420349, crf = 0.28141239285469055, ce = 1.3576246500015259, unr = 2.5425729751586914, ber = 5.6589035987854\n",
      "refe: [CLS] in this image i can see some snow on the ground, few black colored poles and lights on them, a chandelier, few trees, a bench on the right side of the image, the water, few lights and few buildings. in the background i can see the sky. [SEP]\n",
      "hypo: [CLS] in this image there is a water, trees. this image, trees. we can also see trees. [SEP] trees. [SEP]\n",
      "samp: [CLS] in the image i can see few buildings, we can see some trees. we can see a tree. [SEP] trees. [SEP]\n",
      "lr con   : 2.787573467674223e-12\n",
      "lr bert  : 3.677581863979849e-10\n",
      "lr cri   : 1.2090680100755668e-06\n",
      "lr others: 9.773299748110832e-09\n",
      "Train epoch = 0.982367758186398, loss = 19.901016235351562, policy = 0.19029146432876587, entropy_loss = -0.002116082003340125, gae = 17.994226455688477, kl_div = 0.07897963374853134, reward = 6.144314765930176, ord = 7.095387935638428, repeat = -3.2691502571105957, length = -0.22773166000843048, adv = 1.0768944025039673, rougeL = 1.358855962753296, cider = 0.20638321340084076, clip = 0.40286287665367126, crf = 0.2828735113143921, ce = 1.356760859489441, unr = 2.5458085536956787, ber = 5.658997535705566\n",
      "refe: [CLS] here we can see a bag on the floor and on the right there is an object and a japanese samurai armour and a cloth on a stand at the wall. on the left there is a folding fan, cloth and a book on a platform and we can see these reflections on a mirror at the top on the left side. [SEP]\n",
      "hypo: [CLS] in this image there is a purse on which is placed on it. [SEP]\n",
      "samp: [CLS] in this image there is a purse on which are placed on it. [SEP] [SEP]\n",
      "bsz 56 is not batch_size 128. skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 07:51:24,870] Trial 5 finished with value: 1.605001449584961 and parameters: {'config.betas': 1, 'config.len_coef': 4.174019119616679, 'config.unr_coef': 3.7862492663005307, 'config.crf_coef': 0.20499838366727663, 'config.ce_coef': 0.661358677005822, 'config.gae_coef': 3.8856897510127375, 'config.clip_range': 0.23537726324159317, 'clip_grad_threshold': 1.3749604274296316}. Best is trial 5 with value: 1.605001449584961.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, avg_reward = 1.605001449584961\n",
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.2472216274021157\n",
      "clip_grad_threshold gradient norm: 0.1411969121007469\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.4070762041957576\n",
      "unr_coef: 3.20914583721162\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.7104722385579834\n",
      "ce_coef: 0.9895125289564403\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.714229633112709\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_075137.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3349cced4b1e48e2bc68df3fa7cb97bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 18.23726463317871, policy = -1.1060655502603822e-08, entropy_loss = -0.002733747474849224, gae = 15.719670295715332, kl_div = 0.08224988728761673, reward = 4.035857677459717, ord = 7.001897811889648, repeat = -4.7440595626831055, length = -0.07459355145692825, adv = 1.062950849533081, rougeL = 1.2097631692886353, cider = 0.2521743178367615, clip = 0.4014803469181061, crf = 0.48455730080604553, ce = 1.9535226821899414, unr = 1.8526126146316528, ber = 5.691145896911621\n",
      "refe: [CLS] in this image we can see some people are walking on the road and we can also see a building with windows, stores, trees, vehicles, plants and sky. [SEP]\n",
      "hypo: [CLS] in this picture we can see vehicles on the road, we can see people walking on the background we can see the road. [SEP] we can see few buildings, we can see the footpath and we can see the sky. [SEP]\n",
      "samp: [CLS] this picture is clicked outside. there is a road and there are walking. there are some people walking on the road, we can see few buildings. on the road, we can see the sky. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 07:51:56,632] Trial 6 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.2008020450707778\n",
      "clip_grad_threshold gradient norm: 2.3092700527458763\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 4.332693354886365\n",
      "unr_coef: 2.621139572678797\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.5060323859599191\n",
      "ce_coef: 0.9687496397802492\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 1.9426709959601225\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_075209.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09dccb0fca84848972dfc329872cced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 5.436443328857422, policy = 1.2289617323801849e-08, entropy_loss = -0.00287908548489213, gae = 2.8553998470306396, kl_div = 0.08277998119592667, reward = 3.5996341705322266, ord = 7.018229961395264, repeat = -4.739355564117432, length = -0.18404605984687805, adv = 0.26700079441070557, rougeL = 1.2431238889694214, cider = 0.17484036087989807, clip = 0.40839967131614685, crf = 0.42110568284988403, ce = 2.0800371170043945, unr = 1.5048059225082397, ber = 5.705810070037842\n",
      "refe: [CLS] as we can see in the image there is a man holding guitar. [SEP]\n",
      "hypo: [CLS] in this image there is a person. he is a guitar and he is a guitar. [SEP]\n",
      "samp: [CLS] this is a man is a guitar, he is a guitar and there is a microphone, lights. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 07:52:27,282] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.12418996108452325\n",
      "clip_grad_threshold gradient norm: 0.7186569895143932\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.7912256887215885\n",
      "unr_coef: 0.21644613881649732\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.24031810727219216\n",
      "ce_coef: 0.9590846976399273\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 1.2121962491497418\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_075239.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0412617c6e8047b0b87e7d95ba65f1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 3.601271629333496, policy = 4.915846840702898e-09, entropy_loss = -0.0027410832699388266, gae = 1.3415111303329468, kl_div = 0.08074856549501419, reward = 2.758192539215088, ord = 7.027244567871094, repeat = -4.2537078857421875, length = -0.1458187997341156, adv = 0.1305013746023178, rougeL = 1.2518751621246338, cider = 0.22353379428386688, clip = 0.3931328356266022, crf = 0.18695788085460663, ce = 1.9947952032089233, unr = 0.13047464191913605, ber = 5.652407646179199\n",
      "refe: [CLS] in the image there is a painting of an angel and there is a table in front of the angel. [SEP]\n",
      "hypo: [CLS] this is a black and white picture we can see a person. i can see the right side of the right side of the bottom there is a. [SEP]\n",
      "samp: [CLS] in this picture we can see this image there is a person standing. at the right side of the left side of the right side of the middle. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 07:54:23,702] Trial 8 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.20634907602065308\n",
      "clip_grad_threshold gradient norm: 0.9484928921756787\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 1.8063050255223767\n",
      "unr_coef: 2.1998266246888294\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.7957583465609002\n",
      "ce_coef: 0.07199096888035139\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 0.7834823965791005\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_075436.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1210ee2ee84b93afd9920229644ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 3.829538583755493, policy = -2.4579234647603698e-08, entropy_loss = -0.0027156774885952473, gae = 3.074533700942993, kl_div = 0.08209804445505142, reward = 3.991128444671631, ord = 7.004029750823975, repeat = -4.263350486755371, length = -0.05904020369052887, adv = 1.097123622894287, rougeL = 1.2035813331604004, cider = 0.2790733873844147, clip = 0.40934088826179504, crf = 0.5355928540229797, ce = 0.14002980291843414, unr = 1.3094892501831055, ber = 5.658995628356934\n",
      "refe: [CLS] in this image i can see the wall painting. in the painting i can see the person's face with the specs. to the side i can see the pipe. [SEP]\n",
      "hypo: [CLS] in this picture we can see a photo frame on the wall. on the right side of the right side of the wall. [SEP]\n",
      "samp: [CLS] in this picture we can see a wall with some text on the wall and we can see the left side of the wall. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 07:56:19,973] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.2997419462628915\n",
      "clip_grad_threshold gradient norm: 2.9498572912847987\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.050663081235003\n",
      "unr_coef: 4.799310534098601\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.30795132453555396\n",
      "ce_coef: 0.5143113945691371\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 3.4633992744576325\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_075632.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a562813efda54475a99a61501967fc7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 9.26482105255127, policy = 7.373770039009742e-09, entropy_loss = -0.0028981398791074753, gae = 7.788424491882324, kl_div = 0.08562091737985611, reward = 4.794101238250732, ord = 6.84789514541626, repeat = -4.697963714599609, length = -0.1371687799692154, adv = 0.493930459022522, rougeL = 1.2131866216659546, cider = 0.24524785578250885, clip = 0.39968010783195496, crf = 0.2683696150779724, ce = 1.125303864479065, unr = 2.781338691711426, ber = 5.625269412994385\n",
      "refe: [CLS] this image is clicked in a room. there are six persons in this image. in the front, there is a table on which mobiles, mics, papers along with a projector are kept. to the left, the woman is wearing pink shirt. in the background, there is a wall, window along with window blind and a tv. [SEP]\n",
      "hypo: [CLS] in this image we can see some people sitting on chairs. in front of them there is a table on the table, we can see the table. [SEP]\n",
      "samp: [CLS] there are many people sitting on a group of a table there are front of them there is a microphones and a table on the table on the table. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 07:56:51,009] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.23870146415503746\n",
      "clip_grad_threshold gradient norm: 1.8253549094366863\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 1.7519431106369463\n",
      "unr_coef: 3.7444393945832855\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.009133428377235284\n",
      "ce_coef: 0.6640291277610624\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 3.041267678744865\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_075704.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e850418b9fb14e219f5fc7adb4b11605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 14.861002922058105, policy = 1.0814863315999901e-07, entropy_loss = -0.002852119505405426, gae = 13.3525390625, kl_div = 0.08015906810760498, reward = 4.496502876281738, ord = 6.989833831787109, repeat = -4.610241413116455, length = -0.06890513002872467, adv = 1.3389816284179688, rougeL = 1.2291879653930664, cider = 0.20449531078338623, clip = 0.402425616979599, crf = 0.007616047281771898, ce = 1.4235411882400513, unr = 2.1858158111572266, ber = 5.669242858886719\n",
      "refe: [CLS] in the foreground of this image, there is some food item on a platter which is on the surface. [SEP]\n",
      "hypo: [CLS] in this image we can see some food on a plate. [SEP]\n",
      "samp: [CLS] in this picture we can see some food is a plate. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 07:57:21,899] Trial 11 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.1614891398090334\n",
      "clip_grad_threshold gradient norm: 2.144495022485862\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.1103610959685857\n",
      "unr_coef: 3.888805352215654\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.006462354445047946\n",
      "ce_coef: 0.679886247940529\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 2.3920724198771595\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_075734.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d6338a548d45de9a1f42bc4df3b6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 5.930233955383301, policy = 8.525922190472102e-09, entropy_loss = -0.0028495495207607746, gae = 4.44534969329834, kl_div = 0.08864153176546097, reward = 4.41222620010376, ord = 6.984417915344238, repeat = -4.707841396331787, length = -0.12409140914678574, adv = 0.4096015691757202, rougeL = 1.1824557781219482, cider = 0.22955375909805298, clip = 0.4079248011112213, crf = 0.004920356906950474, ce = 1.3941718339920044, unr = 2.2597415447235107, ber = 5.664842128753662\n",
      "refe: [CLS] in this picture i can see two persons standing, and in the background there are group of people standing and there is a canopy tent. [SEP]\n",
      "hypo: [CLS] in this image we can see few persons are standing and smiling and smiling and smiling. in the background we can see a building. [SEP]\n",
      "samp: [CLS] in the foreground we can see group of the left side of the background there is wearing spectacles and in the background we can see group of them we can see the background we can see the building. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 07:57:52,385] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.1706913715969294\n",
      "clip_grad_threshold gradient norm: 1.458147504574575\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 1.4232198741655133\n",
      "unr_coef: 3.894167719142234\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.20027119757561612\n",
      "ce_coef: 0.664773527112378\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.043132934975976\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_075804.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c258ee00010a471a9dcb15a74a6f79e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 11.858771324157715, policy = -5.991188434251171e-09, entropy_loss = -0.002858127001672983, gae = 10.145106315612793, kl_div = 0.07673028856515884, reward = 4.470869064331055, ord = 6.9104108810424805, repeat = -4.673269748687744, length = -0.06706675887107849, adv = 0.7617301940917969, rougeL = 1.1939352750778198, cider = 0.20200015604496002, clip = 0.4072646498680115, crf = 0.17734986543655396, ce = 1.4624420404434204, unr = 2.3007946014404297, ber = 5.656172275543213\n",
      "refe: [CLS] in the picture i can see a man on the right side and he is sitting on the luggage bag. there is a woman on the left side and there is a smile on her face. i can see the luggage bags on the floor and there is a gift box on the bag. in the background, i can see the trees. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman is a woman sitting on the right side of the right side there is a bag. [SEP]\n",
      "samp: [CLS] in this image we can see a woman is a woman is a bag on the right side of the background there is a bag. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 07:58:23,484] Trial 13 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.10337114309739122\n",
      "clip_grad_threshold gradient norm: 2.202735417247089\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.727480419093336\n",
      "unr_coef: 3.1054913193533373\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.3593367875067338\n",
      "ce_coef: 0.4408147363981525\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 2.911148017857877\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_075835.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9755925dfe3c46a6952a5328343a5e27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 13.060184478759766, policy = 7.865354945124636e-08, entropy_loss = -0.0028011465910822153, gae = 11.841001510620117, kl_div = 0.08309371769428253, reward = 4.686283588409424, ord = 7.086605548858643, repeat = -4.093315124511719, length = -0.12492917478084564, adv = 1.0201836824417114, rougeL = 1.2277088165283203, cider = 0.29061082005500793, clip = 0.4108205735683441, crf = 0.25698891282081604, ce = 0.8819012641906738, unr = 1.8179222345352173, ber = 5.689397811889648\n",
      "refe: [CLS] in this image there is a table, on that table there is a table lamp, keyboard, mouse and a broken monitor and there is smoke. [SEP]\n",
      "hypo: [CLS] in this image we can see there is a table, we can see a keyboard in the background we can see a speaker and there is a wall, we can see a wall. [SEP]\n",
      "samp: [CLS] in this image there is a computer there is a table, we can see the background we can see the background there is a wall. at the background there is a wooden background there is a window blind. [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 14.40422248840332, policy = 0.22231626510620117, entropy_loss = -0.0026980668772011995, gae = 12.96136474609375, kl_div = 0.08424676954746246, reward = 4.981650352478027, ord = 7.032627105712891, repeat = -3.839261293411255, length = -0.11167341470718384, adv = 1.086064338684082, rougeL = 1.2563300132751465, cider = 0.23930081725120544, clip = 0.4050561189651489, crf = 0.2595558166503906, ce = 0.8794360160827637, unr = 1.8999583721160889, ber = 5.6556925773620605\n",
      "refe: [CLS] in this picture we can see a person standing in front of a podium. there is some text and art is visible on a podium. we can see a few microphones and a glass object on this podium. there are glass objects and stands on the right and left side of the image. we can see a few colorful lights in the background. [SEP]\n",
      "hypo: [CLS] in this image we can see a man standing in the podium. in front of the podium. [SEP]\n",
      "samp: [CLS] in this image there is a man standing and in front of the podium. in front of the left side there is a microphone. in the left side. behind him. in the image there is. [SEP]\n",
      "lr con   : 1.2962216624685136e-10\n",
      "lr bert  : 1.7100755667506296e-08\n",
      "lr cri   : 5.622166246851385e-05\n",
      "lr others: 4.544584382871536e-07\n",
      "Train epoch = 0.07556675062972293, loss = 15.093562126159668, policy = 0.39450377225875854, entropy_loss = -0.0026580432895570993, gae = 13.44977855682373, kl_div = 0.08436410874128342, reward = 5.128796577453613, ord = 7.013610363006592, repeat = -3.702075719833374, length = -0.12717477977275848, adv = 1.115691900253296, rougeL = 1.2814234495162964, cider = 0.22164802253246307, clip = 0.4018317759037018, crf = 0.2721182703971863, ce = 0.8954554200172424, unr = 1.9444363117218018, ber = 5.6360344886779785\n",
      "refe: [CLS] there is a spectacles through which we can see a camera and a laptop. [SEP]\n",
      "hypo: [CLS] in this image there is a camera. [SEP]\n",
      "samp: [CLS] in this image i can see a person an object. [SEP]\n",
      "lr con   : 1.6307304785894207e-10\n",
      "lr bert  : 2.1513853904282117e-08\n",
      "lr cri   : 7.073047858942065e-05\n",
      "lr others: 5.717380352644836e-07\n",
      "Train epoch = 0.11335012594458438, loss = 15.568224906921387, policy = 0.4125615060329437, entropy_loss = -0.0026369818951934576, gae = 13.892102241516113, kl_div = 0.08353035151958466, reward = 5.26311731338501, ord = 7.011418342590332, repeat = -3.596519947052002, length = -0.12806262075901031, adv = 1.1371688842773438, rougeL = 1.2927014827728271, cider = 0.2056036740541458, clip = 0.4012821316719055, crf = 0.2817789614200592, ce = 0.9008887410163879, unr = 1.976281762123108, ber = 5.630093574523926\n",
      "refe: [CLS] we can see trees, flowers and grass. in the background we can see houses, trees and sky. [SEP]\n",
      "hypo: [CLS] in this image we can see buildings, trees, trees, trees. on the background there are trees. on the sky. [SEP]\n",
      "samp: [CLS] in this image we can see some plants, houses, trees. i can see the background we can see the middle there are trees. [SEP]\n",
      "lr con   : 1.561041141897565e-10\n",
      "lr bert  : 2.0594458438287153e-08\n",
      "lr cri   : 6.770780856423173e-05\n",
      "lr others: 5.473047858942065e-07\n",
      "Train epoch = 0.15113350125944586, loss = 15.993406295776367, policy = 0.5434871315956116, entropy_loss = -0.0026283881161361933, gae = 14.178289413452148, kl_div = 0.08295244723558426, reward = 5.360835075378418, ord = 7.032341003417969, repeat = -3.5417988300323486, length = -0.12864536046981812, adv = 1.1496202945709229, rougeL = 1.312721848487854, cider = 0.210488960146904, clip = 0.40160512924194336, crf = 0.28691810369491577, ce = 0.904385507106781, unr = 1.9989383220672607, ber = 5.636565685272217\n",
      "refe: [CLS] in this image there are people standing in front of the buildings. in the background of the image there is sky. [SEP]\n",
      "hypo: [CLS] in this image we can see people walking on the bottom of them there are few people are some text written on the top of persons standing and there are walking on it. [SEP]\n",
      "samp: [CLS] in this picture we can see people walking on the bottom of them there are few people are some text written on the text on the sky. [SEP]. [SEP]\n",
      "lr con   : 1.4913518052057094e-10\n",
      "lr bert  : 1.9675062972292192e-08\n",
      "lr cri   : 6.468513853904282e-05\n",
      "lr others: 5.228715365239295e-07\n",
      "Train epoch = 0.1889168765743073, loss = 16.41243553161621, policy = 0.4605247974395752, entropy_loss = -0.0025965378154069185, gae = 14.655706405639648, kl_div = 0.08334852010011673, reward = 5.514638900756836, ord = 7.041900157928467, repeat = -3.420639991760254, length = -0.13176697492599487, adv = 1.1727495193481445, rougeL = 1.3255586624145508, cider = 0.20553728938102722, clip = 0.40095338225364685, crf = 0.30770406126976013, ce = 0.9077482223510742, unr = 2.0251457691192627, ber = 5.638923168182373\n",
      "refe: [CLS] in this picture there are different colors of fishes in the boxes. at the bottom it looks like a floor. [SEP]\n",
      "hypo: [CLS] in this image, we can see a kind placed on the trays and on the\n",
      "samp: [CLS] in this picture, we can see some other objects on the middle of the ground. at the ground. at the floor. [SEP]\n",
      "lr con   : 1.4216624685138537e-10\n",
      "lr bert  : 1.8755667506297228e-08\n",
      "lr cri   : 6.16624685138539e-05\n",
      "lr others: 4.984382871536523e-07\n",
      "Train epoch = 0.22670025188916876, loss = 16.731399536132812, policy = 0.4741920530796051, entropy_loss = -0.0025852788239717484, gae = 14.942737579345703, kl_div = 0.08286520838737488, reward = 5.611081600189209, ord = 7.045252799987793, repeat = -3.3358852863311768, length = -0.13420653343200684, adv = 1.183363437652588, rougeL = 1.3353577852249146, cider = 0.20605647563934326, clip = 0.40062469244003296, crf = 0.32318517565727234, ce = 0.9110056161880493, unr = 2.0359208583831787, ber = 5.638408660888672\n",
      "refe: [CLS] in the picture we can see some food item and spoon which are in white color plate and we can see two forks, glass which are on the surface of a table. [SEP]\n",
      "hypo: [CLS] in this image we can see food items on the plate, we can see a plate there are placed on a wooden table. [SEP]\n",
      "samp: [CLS] in this image i can see food items on the plate and i can see a plate there are placed on a wooden table. [SEP]\n",
      "lr con   : 1.3519731318219982e-10\n",
      "lr bert  : 1.7836272040302267e-08\n",
      "lr cri   : 5.863979848866499e-05\n",
      "lr others: 4.740050377833753e-07\n",
      "Train epoch = 0.26448362720403024, loss = 16.730010986328125, policy = 0.4593895673751831, entropy_loss = -0.002562216017395258, gae = 14.931180000305176, kl_div = 0.08295155316591263, reward = 5.639582633972168, ord = 7.039916515350342, repeat = -3.3093087673187256, length = -0.13527549803256989, adv = 1.1811314821243286, rougeL = 1.3403817415237427, cider = 0.1967114955186844, clip = 0.4007691442966461, crf = 0.3456425964832306, ce = 0.9134094715118408, unr = 2.044250726699829, ber = 5.636137962341309\n",
      "refe: [CLS] in this image i can see a woman wearing spectacles and jacket is standing. at the right side of the image i can see a man holding a laptop and sitting on the chair. at the left side of the image i can see another man holding a bag and standing. this is a bench were some objects are placed on it. this is a switch board which is white in color. i can see another bag at the right bottom corner of the image. [SEP]\n",
      "hypo: [CLS] in this image there is a man sitting on the woman sitting on the chair. on the woman sitting on the right side of them there is standing on the chair and the chair, we can see a bag. [SEP]\n",
      "samp: [CLS] in this image there is a man sitting on the chair and there is sitting on the man sitting on the right side of them there is a chair and a bag. beside it. [SEP]\n",
      "lr con   : 1.2822837951301427e-10\n",
      "lr bert  : 1.6916876574307306e-08\n",
      "lr cri   : 5.561712846347607e-05\n",
      "lr others: 4.495717884130982e-07\n",
      "Train epoch = 0.3022670025188917, loss = 16.67212677001953, policy = 0.4470931589603424, entropy_loss = -0.0025655231438577175, gae = 14.879183769226074, kl_div = 0.08327071368694305, reward = 5.654444694519043, ord = 7.03702449798584, repeat = -3.294736623764038, length = -0.13899153470993042, adv = 1.1755989789962769, rougeL = 1.3420403003692627, cider = 0.19592584669589996, clip = 0.40082743763923645, crf = 0.345694899559021, ce = 0.9194502830505371, unr = 2.0511474609375, ber = 5.632120132446289\n",
      "refe: [CLS] this is the picture of a black and white image and we can see some trees and dry leaves on the ground and there is a poster which looks like a book attached to the tree and there is some text on the book and we can see the sky. [SEP]\n",
      "hypo: [CLS] in this image we can see trees. on the image. [SEP]\n",
      "samp: [CLS] in this image there is a tree. at the middle. [SEP]\n",
      "lr con   : 1.2125944584382872e-10\n",
      "lr bert  : 1.5997481108312342e-08\n",
      "lr cri   : 5.2594458438287154e-05\n",
      "lr others: 4.2513853904282117e-07\n",
      "Train epoch = 0.34005037783375314, loss = 16.723005294799805, policy = 0.4095582664012909, entropy_loss = -0.002540347632020712, gae = 14.957109451293945, kl_div = 0.08369256556034088, reward = 5.692952632904053, ord = 7.039170742034912, repeat = -3.2658660411834717, length = -0.13689054548740387, adv = 1.1754668951034546, rougeL = 1.3474584817886353, cider = 0.19288799166679382, clip = 0.4004848003387451, crf = 0.3589429557323456, ce = 0.9162412285804749, unr = 2.056539297103882, ber = 5.629924297332764\n",
      "refe: [CLS] there are many glass bottles. on the front bottle tabasco pepper sauce is written. [SEP]\n",
      "hypo: [CLS] in this image there are bottles. [SEP]. [SEP]. [SEP]\n",
      "samp: [CLS] in this image there are many bottles. [SEP] bottles. [SEP]\n",
      "lr con   : 1.1429051217464315e-10\n",
      "lr bert  : 1.507808564231738e-08\n",
      "lr cri   : 4.957178841309823e-05\n",
      "lr others: 4.0070528967254406e-07\n",
      "Train epoch = 0.3778337531486146, loss = 16.748342514038086, policy = 0.40064844489097595, entropy_loss = -0.0025185630656778812, gae = 14.982050895690918, kl_div = 0.08382650464773178, reward = 5.731016159057617, ord = 7.036863327026367, repeat = -3.2287614345550537, length = -0.1366555094718933, adv = 1.174879789352417, rougeL = 1.3517346382141113, cider = 0.18926922976970673, clip = 0.4003419280052185, crf = 0.3703184425830841, ce = 0.9140148162841797, unr = 2.059569835662842, ber = 5.6268439292907715\n",
      "refe: [CLS] in the foreground of this picture, there is a man and behind him, there is a photo frame to the wall and there is also a green balloon. [SEP]\n",
      "hypo: [CLS] in this image i can see a man standing and there is an object. [SEP]\n",
      "samp: [CLS] in this picture, we can see a person wearing black color t shirt. [SEP] on the wall with some other objects. [SEP]\n",
      "lr con   : 1.073215785054576e-10\n",
      "lr bert  : 1.4158690176322418e-08\n",
      "lr cri   : 4.654911838790932e-05\n",
      "lr others: 3.76272040302267e-07\n",
      "Train epoch = 0.4156171284634761, loss = 16.853010177612305, policy = 0.37963584065437317, entropy_loss = -0.0024988988880068064, gae = 15.106400489807129, kl_div = 0.08356760442256927, reward = 5.791559219360352, ord = 7.044117450714111, repeat = -3.182626962661743, length = -0.13488660752773285, adv = 1.1788471937179565, rougeL = 1.3584504127502441, cider = 0.18902577459812164, clip = 0.4002619683742523, crf = 0.37696316838264465, ce = 0.9089407920837402, unr = 2.064955711364746, ber = 5.62872838973999\n",
      "refe: [CLS] in this picture there are two persons sitting on the toilet seat. at the back there are toilet seats in the trolley. at the top there is light and fan. [SEP]\n",
      "hypo: [CLS] in this image we can see two persons and the floor. on the sitting on the right side. in the floor. [SEP]\n",
      "samp: [CLS] in this image we can see two persons and the floor. at the smile on the right side. in the background there are chairs. at the left side. [SEP]\n",
      "lr con   : 1.0035264483627203e-10\n",
      "lr bert  : 1.3239294710327456e-08\n",
      "lr cri   : 4.35264483627204e-05\n",
      "lr others: 3.518387909319899e-07\n",
      "Train epoch = 0.4534005037783375, loss = 16.884796142578125, policy = 0.36365413665771484, entropy_loss = -0.0024872038047760725, gae = 15.142873764038086, kl_div = 0.08365100622177124, reward = 5.824858665466309, ord = 7.043819904327393, repeat = -3.154684543609619, length = -0.13686811923980713, adv = 1.1775683164596558, rougeL = 1.3653076887130737, cider = 0.18674397468566895, clip = 0.4001980721950531, crf = 0.38632798194885254, ce = 0.910775899887085, unr = 2.072591543197632, ber = 5.62805700302124\n",
      "refe: [CLS] in this image we see a food item in a bowl and in the top left we can see a metal. [SEP]\n",
      "hypo: [CLS] in this image we can see food items. [SEP]\n",
      "samp: [CLS] in this image we can see food items. in the middle. [SEP]\n",
      "lr con   : 9.338371116708649e-11\n",
      "lr bert  : 1.2319899244332495e-08\n",
      "lr cri   : 4.0503778337531486e-05\n",
      "lr others: 3.2740554156171283e-07\n",
      "Train epoch = 0.491183879093199, loss = 16.769245147705078, policy = 0.36050087213516235, entropy_loss = -0.0024906143080443144, gae = 15.037979125976562, kl_div = 0.08375246077775955, reward = 5.8206610679626465, ord = 7.0440521240234375, repeat = -3.160853862762451, length = -0.13643436133861542, adv = 1.1690336465835571, rougeL = 1.364729881286621, cider = 0.18435192108154297, clip = 0.39984795451164246, crf = 0.3800486624240875, ce = 0.9094539880752563, unr = 2.0738980770111084, ber = 5.626314163208008\n",
      "refe: [CLS] in this picture there are swans on the water. at the back there are trees and there are plants. at the top there is sky. at the bottom there are reflections of swans, plants and trees on the water. [SEP]\n",
      "hypo: [CLS] in this image we can see a water. on the water. in the water. in the trees. at the background there are trees. [SEP]\n",
      "samp: [CLS] in this image we can see a water. at the city. in the background, grass. in the background there are trees, trees. [SEP]\n",
      "lr con   : 8.641477749790091e-11\n",
      "lr bert  : 1.140050377833753e-08\n",
      "lr cri   : 3.7481108312342564e-05\n",
      "lr others: 3.029722921914357e-07\n",
      "Train epoch = 0.5289672544080605, loss = 16.861597061157227, policy = 0.36140426993370056, entropy_loss = -0.002473599975928664, gae = 15.128751754760742, kl_div = 0.08384773135185242, reward = 5.865451335906982, ord = 7.046351432800293, repeat = -3.125755548477173, length = -0.13864202797412872, adv = 1.1707755327224731, rougeL = 1.367419719696045, cider = 0.18416866660118103, clip = 0.3995194435119629, crf = 0.3814356029033661, ce = 0.9086305499076843, unr = 2.083498239517212, ber = 5.625951290130615\n",
      "refe: [CLS] in this image in the foreground there are plants and flowers. in the middle there is a wall. in the background there is mountain. [SEP]\n",
      "hypo: [CLS] in this image we can see a house, plants, grass. [SEP]. [SEP]\n",
      "samp: [CLS] in this image i can see a house, plants, grass. [SEP] on the image. [SEP]\n",
      "lr con   : 7.944584382871536e-11\n",
      "lr bert  : 1.048110831234257e-08\n",
      "lr cri   : 3.4458438287153655e-05\n",
      "lr others: 2.785390428211587e-07\n",
      "Train epoch = 0.5667506297229219, loss = 17.024503707885742, policy = 0.36335986852645874, entropy_loss = -0.002450779778882861, gae = 15.2835693359375, kl_div = 0.08402436226606369, reward = 5.930172920227051, ord = 7.04736328125, repeat = -3.0714406967163086, length = -0.14082078635692596, adv = 1.1768914461135864, rougeL = 1.3712519407272339, cider = 0.18372732400894165, clip = 0.39928194880485535, crf = 0.38846099376678467, ce = 0.9075391888618469, unr = 2.0950708389282227, ber = 5.624874114990234\n",
      "refe: [CLS] in this image, there are group of people standing and wearing clothes. there is some cars in the middle of the image. in the background, there are buildings. [SEP]\n",
      "hypo: [CLS] in this image we can see group of people standing and the road. in front of the right side. in the right side. at the right side. [SEP]\n",
      "samp: [CLS] in this picture we can see group of people standing on the road. at the road. at the right side. in his hands. at the left side. [SEP]\n",
      "lr con   : 7.24769101595298e-11\n",
      "lr bert  : 9.561712846347607e-09\n",
      "lr cri   : 3.143576826196473e-05\n",
      "lr others: 2.541057934508816e-07\n",
      "Train epoch = 0.6045340050377834, loss = 17.08062171936035, policy = 0.38570114970207214, entropy_loss = -0.00242818845435977, gae = 15.309165954589844, kl_div = 0.08430643379688263, reward = 5.954576015472412, ord = 7.039307117462158, repeat = -3.042764186859131, length = -0.14268290996551514, adv = 1.1757066249847412, rougeL = 1.3709508180618286, cider = 0.18233861029148102, clip = 0.3988208472728729, crf = 0.39556440711021423, ce = 0.9083131551742554, unr = 2.1007158756256104, ber = 5.620716094970703\n",
      "refe: [CLS] in this image i can see the person riding the bicycle. in the background i can see the grass and few trees in green color and i can also see few buildings and the sky is in white and blue color. [SEP]\n",
      "hypo: [CLS] in this image we can see a person riding a bicycle. in the road. in the road. [SEP] grass. [SEP]\n",
      "samp: [CLS] in this picture we can see the person riding bicycle. at the road. there is the road. [SEP] on the road. [SEP]\n",
      "lr con   : 6.550797649034425e-11\n",
      "lr bert  : 8.642317380352645e-09\n",
      "lr cri   : 2.8413098236775818e-05\n",
      "lr others: 2.2967254408060454e-07\n",
      "Train epoch = 0.6423173803526449, loss = 17.151691436767578, policy = 0.3713577687740326, entropy_loss = -0.0024034876842051744, gae = 15.384164810180664, kl_div = 0.08443029969930649, reward = 5.992918968200684, ord = 7.040740489959717, repeat = -3.011629819869995, length = -0.14431102573871613, adv = 1.1773747205734253, rougeL = 1.372575044631958, cider = 0.18395113945007324, clip = 0.3984205424785614, crf = 0.40622270107269287, ce = 0.9079207181930542, unr = 2.108119487762451, ber = 5.619969844818115\n",
      "refe: [CLS] in this picture we can see a food item on grills and some objects on a platform. [SEP]\n",
      "hypo: [CLS] in this image we can see a bowl in the on the table. [SEP]\n",
      "samp: [CLS] in this image i can see a bowl view. on the table. [SEP]. [SEP]\n",
      "lr con   : 5.853904282115869e-11\n",
      "lr bert  : 7.722921914357682e-09\n",
      "lr cri   : 2.5390428211586902e-05\n",
      "lr others: 2.0523929471032745e-07\n",
      "Train epoch = 0.6801007556675063, loss = 17.243406295776367, policy = 0.37734153866767883, entropy_loss = -0.0023835976608097553, gae = 15.466131210327148, kl_div = 0.0843781977891922, reward = 6.035372734069824, ord = 7.03596305847168, repeat = -2.973116397857666, length = -0.14644008874893188, adv = 1.1799782514572144, rougeL = 1.3722448348999023, cider = 0.1832103580236435, clip = 0.39818745851516724, crf = 0.4107118844985962, ce = 0.9072292447090149, unr = 2.118967056274414, ber = 5.617586612701416\n",
      "refe: [CLS] in this image in the middle there is a woman she is holding mic, her hair is short. on the right there is a woman she is staring at man. the three are holding mic. in the background there is building and plant. [SEP]\n",
      "hypo: [CLS] in this image, we can see a woman standing in their hands and the left side. [SEP] blazer. [SEP]. [SEP]\n",
      "samp: [CLS] in this image i can see two women are standing. at the man standing in the left side holding a microphones. [SEP] blazer. [SEP] spectacles. [SEP] spectacles. [SEP] blazer. [SEP]\n",
      "lr con   : 5.157010915197313e-11\n",
      "lr bert  : 6.8035264483627206e-09\n",
      "lr cri   : 2.2367758186397984e-05\n",
      "lr others: 1.8080604534005037e-07\n",
      "Train epoch = 0.7178841309823678, loss = 17.268083572387695, policy = 0.39871594309806824, entropy_loss = -0.0023675146512687206, gae = 15.465807914733887, kl_div = 0.08443541824817657, reward = 6.057148456573486, ord = 7.031204700469971, repeat = -2.953484535217285, length = -0.1481073647737503, adv = 1.178737998008728, rougeL = 1.370967149734497, cider = 0.18318875133991241, clip = 0.39806655049324036, crf = 0.41522055864334106, ce = 0.9062709808349609, unr = 2.127535581588745, ber = 5.616028308868408\n",
      "refe: [CLS] in the image in the center we can see two persons were standing and one person is holding frame. in the background there is a wall, door, tablecloth, paper, laptop and one person is sitting. [SEP]\n",
      "hypo: [CLS] in this image we can see two men are two persons sitting on the right side. [SEP] on the table. on the table. [SEP]\n",
      "samp: [CLS] in this image we can see few people are two persons sitting on the man standing on the table. at the left side of them there is a table. [SEP]\n",
      "lr con   : 4.460117548278757e-11\n",
      "lr bert  : 5.884130982367758e-09\n",
      "lr cri   : 1.9345088161209068e-05\n",
      "lr others: 1.563727959697733e-07\n",
      "Train epoch = 0.7556675062972292, loss = 17.288375854492188, policy = 0.392850399017334, entropy_loss = -0.0023586610332131386, gae = 15.493256568908691, kl_div = 0.08459334075450897, reward = 6.086989879608154, ord = 7.025222301483154, repeat = -2.924583911895752, length = -0.14925704896450043, adv = 1.1791844367980957, rougeL = 1.369861125946045, cider = 0.1807638555765152, clip = 0.3978869318962097, crf = 0.41462960839271545, ce = 0.9054040908813477, unr = 2.1356091499328613, ber = 5.614175796508789\n",
      "refe: [CLS] in this image we can see the computer keyboard, speakers and cables on the wooden surface. [SEP]\n",
      "hypo: [CLS] in this image we can see a laptop, on the table. [SEP] cables. [SEP]\n",
      "samp: [CLS] in this picture we can see a laptop, on the table. [SEP]cula placed. [SEP]\n",
      "lr con   : 3.7632241813602014e-11\n",
      "lr bert  : 4.964735516372796e-09\n",
      "lr cri   : 1.632241813602015e-05\n",
      "lr others: 1.3193954659949622e-07\n",
      "Train epoch = 0.7934508816120907, loss = 17.356185913085938, policy = 0.4248265326023102, entropy_loss = -0.0023525720462203026, gae = 15.530172348022461, kl_div = 0.08472304791212082, reward = 6.11809778213501, ord = 7.020603179931641, repeat = -2.8957066535949707, length = -0.1499033123254776, adv = 1.1800132989883423, rougeL = 1.370226502418518, cider = 0.1790432631969452, clip = 0.39793872833251953, crf = 0.41391849517822266, ce = 0.90489661693573, unr = 2.14310359954834, ber = 5.61401891708374\n",
      "refe: [CLS] in this picture we can see a woman smiling and at the back of her we can see a glass with some text on it, table, road, grass, trees, pole, building, wall and in the background we can see the sky. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman is a black color t - front of the background, we can see a pole, trees. [SEP]\n",
      "samp: [CLS] in this picture we can see a woman is a black color t - shirt. at the background we can see trees. [SEP]. [SEP]. [SEP] trees. [SEP]\n",
      "lr con   : 3.066330814441645e-11\n",
      "lr bert  : 4.045340050377834e-09\n",
      "lr cri   : 1.3299748110831234e-05\n",
      "lr others: 1.0750629722921913e-07\n",
      "Train epoch = 0.8312342569269522, loss = 17.423994064331055, policy = 0.4481852948665619, entropy_loss = -0.0023475068155676126, gae = 15.573862075805664, kl_div = 0.08463483303785324, reward = 6.148501873016357, ord = 7.017575263977051, repeat = -2.868635892868042, length = -0.15057477355003357, adv = 1.1809951066970825, rougeL = 1.370843529701233, cider = 0.17897462844848633, clip = 0.3979024291038513, crf = 0.4143452048301697, ce = 0.9053141474723816, unr = 2.1501364707946777, ber = 5.613765239715576\n",
      "refe: [CLS] this picture is clicked outside. on the left we can see an object on which we can see the poster and the text on the poster. on the right we can see the sky and the branches and stems of the trees and some other objects. [SEP]\n",
      "hypo: [CLS] in this image, we can see a pole. on the left side. [SEP]\n",
      "samp: [CLS] in this picture, we can see a pole. at the left side. [SEP] sky. [SEP] trees. [SEP]\n",
      "lr con   : 2.3694374475230897e-11\n",
      "lr bert  : 3.1259445843828713e-09\n",
      "lr cri   : 1.0277078085642317e-05\n",
      "lr others: 8.307304785894206e-08\n",
      "Train epoch = 0.8690176322418136, loss = 17.49003791809082, policy = 0.4446927607059479, entropy_loss = -0.0023381796199828386, gae = 15.6402587890625, kl_div = 0.08457798510789871, reward = 6.182829856872559, ord = 7.019729137420654, repeat = -2.8417084217071533, length = -0.15083013474941254, adv = 1.1828970909118652, rougeL = 1.3731287717819214, cider = 0.1795346885919571, clip = 0.3979611396789551, crf = 0.4178847670555115, ce = 0.9049597978591919, unr = 2.155639410018921, ber = 5.6144280433654785\n",
      "refe: [CLS] in this image i can see a person wearing blue and violet dress is standing and i can see she is wearing few gold ornaments. in the background i can see another person wearing a costume, the metal fence, few persons on the other side of the metal fence. [SEP]\n",
      "hypo: [CLS] in this image in the center there are two persons standing. at the background, we can see the background. [SEP]. [SEP]\n",
      "samp: [CLS] in this image, we can see two persons standing on the bottom of the background i can see the background there are trees, plants. [SEP] trees. [SEP]\n",
      "lr con   : 1.6725440806045338e-11\n",
      "lr bert  : 2.206549118387909e-09\n",
      "lr cri   : 7.2544080604534e-06\n",
      "lr others: 5.863979848866498e-08\n",
      "Train epoch = 0.906801007556675, loss = 17.56362533569336, policy = 0.49505332112312317, entropy_loss = -0.0023330622352659702, gae = 15.664816856384277, kl_div = 0.08457914739847183, reward = 6.205646514892578, ord = 7.019157409667969, repeat = -2.822096824645996, length = -0.15163172781467438, adv = 1.182800531387329, rougeL = 1.3738521337509155, cider = 0.17981141805648804, clip = 0.3979935646057129, crf = 0.41720691323280334, ce = 0.9043010473251343, unr = 2.1602180004119873, ber = 5.614709377288818\n",
      "refe: [CLS] in this image there is a person holding a bottle. in the back there are few people. also there is a cover. on the ground there is grass. and there is a pole. in the background there is water, hill and sky with clouds. [SEP]\n",
      "hypo: [CLS] in this image i can see a man wearing black color t - shirt. in his hand. at the right side, grass. [SEP]. [SEP]\n",
      "samp: [CLS] in this image we can see a person is an object in his hands. at the ground. at the right side, trees, at the right side there are trees, grass. [SEP] sky. [SEP] sky. [SEP]. [SEP]\n",
      "lr con   : 9.75650713685978e-12\n",
      "lr bert  : 1.287153652392947e-09\n",
      "lr cri   : 4.231738035264483e-06\n",
      "lr others: 3.4206549118387904e-08\n",
      "Train epoch = 0.9445843828715366, loss = 17.65879249572754, policy = 0.5052321553230286, entropy_loss = -0.0023178004194051027, gae = 15.745965003967285, kl_div = 0.08453742414712906, reward = 6.243473052978516, ord = 7.019708633422852, repeat = -2.7902233600616455, length = -0.15220937132835388, adv = 1.1860382556915283, rougeL = 1.3764476776123047, cider = 0.17940464615821838, clip = 0.3979746401309967, crf = 0.42248278856277466, ce = 0.9028928875923157, unr = 2.1661975383758545, ber = 5.614745616912842\n",
      "refe: [CLS] in this image we can see a woman and few objects in the background and a red color carpet on the floor. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman standing and white color dress. [SEP]\n",
      "samp: [CLS] in this image we can see a person wearing black color t - shirt. [SEP]. [SEP]\n",
      "lr con   : 2.787573467674223e-12\n",
      "lr bert  : 3.677581863979849e-10\n",
      "lr cri   : 1.2090680100755668e-06\n",
      "lr others: 9.773299748110832e-09\n",
      "Train epoch = 0.982367758186398, loss = 17.715682983398438, policy = 0.48960697650909424, entropy_loss = -0.002306103240698576, gae = 15.810599327087402, kl_div = 0.08446162939071655, reward = 6.273673057556152, ord = 7.021749973297119, repeat = -2.7655365467071533, length = -0.1533316671848297, adv = 1.1880241632461548, rougeL = 1.3783191442489624, cider = 0.1783798187971115, clip = 0.39784789085388184, crf = 0.42923393845558167, ce = 0.9040853977203369, unr = 2.1707921028137207, ber = 5.614717483520508\n",
      "refe: [CLS] in this image, we can see a person holding an object. we can see the ground covered with grass. we can also see a ball and the shadow on the ground. [SEP]\n",
      "hypo: [CLS] in this image we can see a person standing on the ground, grass. [SEP]\n",
      "samp: [CLS] in this picture, we can see a bat in the ground. [SEP] golfet. [SEP]\n",
      "bsz 56 is not batch_size 128. skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 08:55:59,192] Trial 14 finished with value: 1.6862283945083618 and parameters: {'config.betas': 1, 'config.len_coef': 2.727480419093336, 'config.unr_coef': 3.1054913193533373, 'config.crf_coef': 0.3593367875067338, 'config.ce_coef': 0.4408147363981525, 'config.gae_coef': 2.911148017857877, 'config.clip_range': 0.10337114309739122, 'clip_grad_threshold': 2.202735417247089}. Best is trial 14 with value: 1.6862283945083618.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, avg_reward = 1.6862283945083618\n",
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.2235796150373513\n",
      "clip_grad_threshold gradient norm: 2.6923018330968373\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.6815121049128408\n",
      "unr_coef: 4.320363282028907\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.3652815543910764\n",
      "ce_coef: 0.4217161982553098\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 1.8660519537583322\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_085612.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436334030d4640aea8ce775ede2fe02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 7.830657958984375, policy = 5.530327751301911e-09, entropy_loss = -0.002790480852127075, gae = 6.55192232131958, kl_div = 0.08233509212732315, reward = 5.202600002288818, ord = 6.992245197296143, repeat = -4.181037425994873, length = -0.16624322533607483, adv = 0.9718259572982788, rougeL = 1.2479512691497803, cider = 0.29264625906944275, clip = 0.40536922216415405, crf = 0.30507364869117737, ce = 0.894117534160614, unr = 2.55763578414917, ber = 5.6540398597717285\n",
      "refe: [CLS] this picture is in a big hall. in the middle a person who is wearing a green jacket and a pant is holding a paper and reading something. there is a colorful carpet on the floor. few persons are sitting beside on chairs. there are table in front of them. on the table there is paper, bottle. it is looking like the they are listening to the middle person. in the background there are curtain in white and red color. there are lights in the ceiling\n",
      "hypo: [CLS] in this image we can see a man is a man standing. on the right side of them we can see a table in front of them we can also there is a table. [SEP]\n",
      "samp: [CLS] in this picture we can see a man standing and speaking. he is a table in front of them we can see the table in front of them we can also there is wearing spectacles, there are sitting on the image there is a chairs. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 08:56:32,541] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.27273409222286465\n",
      "clip_grad_threshold gradient norm: 2.2716464485045114\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 4.905536472311776\n",
      "unr_coef: 3.0305278823765485\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.983139529722787\n",
      "ce_coef: 0.2799106118097532\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.168050600321752\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_085645.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243327227ba74a8bb52047ccdddb3c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 12.006479263305664, policy = 1.1675136413202836e-08, entropy_loss = -0.002894036239013076, gae = 10.571355819702148, kl_div = 0.08247321844100952, reward = 3.839061975479126, ord = 6.939021110534668, repeat = -4.612828254699707, length = -0.21366244554519653, adv = 0.6758115291595459, rougeL = 1.2296162843704224, cider = 0.2554533779621124, clip = 0.3975759744644165, crf = 0.7667226195335388, ce = 0.5888217687606812, unr = 1.726531982421875, ber = 5.678328990936279\n",
      "refe: [CLS] in this image we can see some food item which is in bowl and there is a plate on the surface. [SEP]\n",
      "hypo: [CLS] in this image we can see there is a plate and some food items. in the top of the right corner. [SEP]\n",
      "samp: [CLS] in this image we can see there is a bucket over here we can see the left side of the image. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 08:57:03,660] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.100706344768098\n",
      "clip_grad_threshold gradient norm: 2.026480800125035\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 4.347474770527697\n",
      "unr_coef: 2.028272745218299\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.40506256139817787\n",
      "ce_coef: 0.5420128048602144\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 3.203185514214314\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_085716.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee6dd6dc42046649c440dac825db170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 11.742777824401855, policy = 8.356939673603847e-08, entropy_loss = -0.0027181277982890606, gae = 10.227877616882324, kl_div = 0.08049668371677399, reward = 3.74499773979187, ord = 7.0226826667785645, repeat = -4.316030979156494, length = -0.16489943861961365, adv = 1.0642441511154175, rougeL = 1.2416446208953857, cider = 0.23625269532203674, clip = 0.40877383947372437, crf = 0.3184348940849304, ce = 1.118686318397522, unr = 1.203245759010315, ber = 5.664800643920898\n",
      "refe: [CLS] this picture contains the face of a girl and behind her, we see trees. it is a sunny day. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman and a woman is a woman is blurred. [SEP]\n",
      "samp: [CLS] in this image we can see a woman smiling. there is a woman is blurred. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 08:57:35,451] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.21791259989758385\n",
      "clip_grad_threshold gradient norm: 2.514988603836487\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.9992234712023134\n",
      "unr_coef: 1.6857769478184834\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.20808381310675256\n",
      "ce_coef: 0.31155008478677904\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 2.441196147439567\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_085748.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb13558231d441ab3031f4a81630962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 6.298391819000244, policy = 3.3028346280161713e-08, entropy_loss = -0.0029086617287248373, gae = 5.3593058586120605, kl_div = 0.08286330848932266, reward = 3.2377121448516846, ord = 7.024053573608398, repeat = -4.616591453552246, length = -0.14163701236248016, adv = 0.6661554574966431, rougeL = 1.2916048765182495, cider = 0.26557955145835876, clip = 0.3966885209083557, crf = 0.17935268580913544, ce = 0.6797782182693481, unr = 0.9718871712684631, ber = 5.70543098449707\n",
      "refe: [CLS] in this image we can see group of persons standing, some persons are holding cameras in their hands. at the bottom of the image we can see barricades and a plant. in the center of the image we can see some vehicles parked on the ground. in the background, we can see a group of trees and the sly. [SEP]\n",
      "hypo: [CLS] in this image there is a group of people standing and there is a camera, we can see a video can see the right side, trees, trees. there is a few trees. there are trees. there are trees. there are trees. [SEP]\n",
      "samp: [CLS] this picture shows the image there is a person standing on the ground and besides, we can see a video hands. there is a few persons are trees. on the right side of him there are trees. in the left side of the background there are trees. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 08:58:06,645] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.25835758031242356\n",
      "clip_grad_threshold gradient norm: 1.5213015330999287\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 4.292557785735329\n",
      "unr_coef: 3.5407426180573127\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.4449875495209227\n",
      "ce_coef: 0.801325357332606\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 3.6241003944942216\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_085819.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1454ca248b4c19922293893d561150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 14.156376838684082, policy = 5.5917759311796544e-08, entropy_loss = -0.0028842072933912277, gae = 12.06020450592041, kl_div = 0.08522491902112961, reward = 4.510658264160156, ord = 6.967439651489258, repeat = -4.3872904777526855, length = -0.173027902841568, adv = 0.9809160828590393, rougeL = 1.2115168571472168, cider = 0.20447786152362823, clip = 0.4008898138999939, crf = 0.3490452468395233, ce = 1.6647859811782837, unr = 2.103537082672119, ber = 5.656588077545166\n",
      "refe: [CLS] in the image there is a woman, she is wearing spectacles. only the face of the woman is visible and the background of the woman is blur. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman wearing spectacles. in the background there is blurred. [SEP]\n",
      "samp: [CLS] in this image there is a woman there is a woman wearing spectacles. behind her head. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 08:58:37,380] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.18121893471742695\n",
      "clip_grad_threshold gradient norm: 1.3232017031664491\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.3936949935002425\n",
      "unr_coef: 4.346782207555315\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.12921371334343312\n",
      "ce_coef: 0.36676281737454264\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.391875954976487\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_085850.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e12b9067d3944aa6961c5fcff2e998d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 23.34239387512207, policy = 8.848524402083058e-08, entropy_loss = -0.0027029591146856546, gae = 22.44341468811035, kl_div = 0.08601895719766617, reward = 5.507548809051514, ord = 7.086819648742676, repeat = -4.1702189445495605, length = -0.09832745045423508, adv = 1.3311597108840942, rougeL = 1.2490649223327637, cider = 0.2910308837890625, clip = 0.405755877494812, crf = 0.09263185411691666, ce = 0.7230321764945984, unr = 2.6892759799957275, ber = 5.686166763305664\n",
      "refe: [CLS] there are three men playing football and a ground. [SEP]\n",
      "hypo: [CLS] in the center of the image we can see a ball in the right side of the ball. [SEP]\n",
      "samp: [CLS] in the center of the picture we can see a ball in the ground there is a football. [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 24.918075561523438, policy = 0.04550794139504433, entropy_loss = -0.0025105748791247606, gae = 23.896507263183594, kl_div = 0.07949002832174301, reward = 5.767276763916016, ord = 7.049290657043457, repeat = -3.8580167293548584, length = -0.11936703324317932, adv = 1.3781309127807617, rougeL = 1.2907161712646484, cider = 0.238101527094841, clip = 0.4042816758155823, crf = 0.14869864284992218, ce = 0.7503848075866699, unr = 2.6953697204589844, ber = 5.666181564331055\n",
      "refe: [CLS] here there are few persons walking on the road and among them few are carrying bags on their hands. in the background we can see vehicles, buildings, windows, poles, trees, hoardings, bags tied to a pole and some other objects and clouds in the sky. on the right at the bottom corner we can see a kid sitting on a stroller. [SEP]\n",
      "hypo: [CLS] in this image we can see few people walking on the road, on the road. on the right side of the right side, there are buildings. [SEP] on the background there are buildings and in the sky. [SEP]\n",
      "samp: [CLS] in this image we can see few people are walking on the road and few people sitting on the image there is a pole, there are buildings, there is standing. [SEP] in the image there is taken may be in the sky. [SEP]\n",
      "lr con   : 1.2962216624685136e-10\n",
      "lr bert  : 1.7100755667506296e-08\n",
      "lr cri   : 5.622166246851385e-05\n",
      "lr others: 4.544584382871536e-07\n",
      "Train epoch = 0.07556675062972293, loss = 27.768632888793945, policy = 0.051185715943574905, entropy_loss = -0.0024223593063652515, gae = 26.709054946899414, kl_div = 0.0793369859457016, reward = 6.2299275398254395, ord = 7.070880889892578, repeat = -3.47294282913208, length = -0.1323367804288864, adv = 1.4623539447784424, rougeL = 1.3287700414657593, cider = 0.204779714345932, clip = 0.40409499406814575, crf = 0.17059874534606934, ce = 0.7608785629272461, unr = 2.764326333999634, ber = 5.65981912612915\n",
      "refe: [CLS] as we can see in the image there are two people. the man over here is wearing a black color dress and holding a tin. the woman is wearing red color dress and holding glass. in the background there are few people and the background is blurred. [SEP]\n",
      "hypo: [CLS] in this image we can see a man and smiling and smiling and smiling. in their hands. in his hand. [SEP]\n",
      "samp: [CLS] in this image i can see a man and smiling and holding a glass and in their hands. in his hands. [SEP]\n",
      "lr con   : 1.6307304785894207e-10\n",
      "lr bert  : 2.1513853904282117e-08\n",
      "lr cri   : 7.073047858942065e-05\n",
      "lr others: 5.717380352644836e-07\n",
      "Train epoch = 0.11335012594458438, loss = 29.13564109802246, policy = 0.05677712708711624, entropy_loss = -0.002381920348852873, gae = 28.05974769592285, kl_div = 0.07950858771800995, reward = 6.460056304931641, ord = 7.078738212585449, repeat = -3.301321506500244, length = -0.13080084323883057, adv = 1.4979212284088135, rougeL = 1.3492629528045654, cider = 0.194510817527771, clip = 0.40333813428878784, crf = 0.17908141016960144, ce = 0.7629090547561646, unr = 2.8134403228759766, ber = 5.657217502593994\n",
      "refe: [CLS] in this image, in the middle, we can see three people. on the right side, we can see some trees, plants, buildings. on the left side, we can also see buildings, pillars, trees, plants. in the background, we can see some buildings, towers, statue. at the top, we can see a sky which is cloudy, at the bottom, we can see some plants, flowers and a grass. [SEP]\n",
      "hypo: [CLS] in this image we can see few buildings, plants, plants, plants, plants, plants, we can see number of people walking on the sky. [SEP] buildings and sky. there is a day. there are buildings and sky. [SEP]\n",
      "samp: [CLS] in this image i can see some people, we can see some people walking on the background i can see few people walking on the road. there is a few people are buildings, there are walking and a day. there is taken may be cloudy sky. [SEP]\n",
      "lr con   : 1.561041141897565e-10\n",
      "lr bert  : 2.0594458438287153e-08\n",
      "lr cri   : 6.770780856423173e-05\n",
      "lr others: 5.473047858942065e-07\n",
      "Train epoch = 0.15113350125944586, loss = 30.795103073120117, policy = 0.057934124022722244, entropy_loss = -0.002311269287019968, gae = 29.727060317993164, kl_div = 0.07819532603025436, reward = 6.745405197143555, ord = 7.103885173797607, repeat = -3.1059188842773438, length = -0.1267480105161667, adv = 1.5434423685073853, rougeL = 1.3723028898239136, cider = 0.19583584368228912, clip = 0.40257537364959717, crf = 0.18123796582221985, ce = 0.7529876232147217, unr = 2.8741872310638428, ber = 5.659907817840576\n",
      "refe: [CLS] here we can see vehicles on the floor under a tent and we can see trees and poles. [SEP]\n",
      "hypo: [CLS] in this image i can see cars, there is a black color. [SEP]\n",
      "samp: [CLS] in this image i can see few vehicles parked on the floor. in the background there is blurred. [SEP] grass. [SEP]\n",
      "lr con   : 1.4913518052057094e-10\n",
      "lr bert  : 1.9675062972292192e-08\n",
      "lr cri   : 6.468513853904282e-05\n",
      "lr others: 5.228715365239295e-07\n",
      "Train epoch = 0.1889168765743073, loss = 31.417457580566406, policy = 0.058827340602874756, entropy_loss = -0.0022739716805517673, gae = 30.345813751220703, kl_div = 0.07724523544311523, reward = 6.870709419250488, ord = 7.111058235168457, repeat = -3.0153656005859375, length = -0.12763792276382446, adv = 1.5568053722381592, rougeL = 1.3815125226974487, cider = 0.19836628437042236, clip = 0.40291380882263184, crf = 0.1845247596502304, ce = 0.7533228397369385, unr = 2.9026551246643066, ber = 5.659340858459473\n",
      "refe: [CLS] in this image we can see three different color coins. [SEP]\n",
      "hypo: [CLS] in this image there are different color coins. [SEP]\n",
      "samp: [CLS] in this image we can see wooden coins. [SEP]\n",
      "lr con   : 1.4216624685138537e-10\n",
      "lr bert  : 1.8755667506297228e-08\n",
      "lr cri   : 6.16624685138539e-05\n",
      "lr others: 4.984382871536523e-07\n",
      "Train epoch = 0.22670025188916876, loss = 31.423019409179688, policy = 0.058780815452337265, entropy_loss = -0.002241768641397357, gae = 30.343894958496094, kl_div = 0.07720291614532471, reward = 6.901998519897461, ord = 7.111110687255859, repeat = -2.9914698600769043, length = -0.1324339061975479, adv = 1.5519495010375977, rougeL = 1.3914192914962769, cider = 0.19396854937076569, clip = 0.40340718626976013, crf = 0.18772339820861816, ce = 0.7576619982719421, unr = 2.914793014526367, ber = 5.657958030700684\n",
      "refe: [CLS] in this image there is a dog sitting on the bed and watching from the window. beside the dog there is another doll. on the right side there is a sofa on which there are blankets. on the left side there is a curtain. through the glass window we can see that there is a parked on the road. beside the car there is a tree. [SEP]\n",
      "hypo: [CLS] in this image there is a dog, a dog, there is a dog and there is a dog. [SEP]\n",
      "samp: [CLS] in this image, we can see a dog is a car. there is a dog is a dog. [SEP]\n",
      "lr con   : 1.3519731318219982e-10\n",
      "lr bert  : 1.7836272040302267e-08\n",
      "lr cri   : 5.863979848866499e-05\n",
      "lr others: 4.740050377833753e-07\n",
      "Train epoch = 0.26448362720403024, loss = 31.619047164916992, policy = 0.05832253769040108, entropy_loss = -0.0022139379289001226, gae = 30.545764923095703, kl_div = 0.07698415964841843, reward = 6.969784736633301, ord = 7.110603332519531, repeat = -2.9422457218170166, length = -0.1316358745098114, adv = 1.5539287328720093, rougeL = 1.3922778367996216, cider = 0.1929919570684433, clip = 0.4037174880504608, crf = 0.18769893050193787, ce = 0.7524944543838501, unr = 2.933063268661499, ber = 5.659144401550293\n",
      "refe: [CLS] in this image i can see an insect which is in brown color on some object and the object is in green color. [SEP]\n",
      "hypo: [CLS] in this image i can see an insect on the surface. [SEP]\n",
      "samp: [CLS] in this image i can see an insect. on the surface. [SEP]\n",
      "lr con   : 1.2822837951301427e-10\n",
      "lr bert  : 1.6916876574307306e-08\n",
      "lr cri   : 5.561712846347607e-05\n",
      "lr others: 4.495717884130982e-07\n",
      "Train epoch = 0.3022670025188917, loss = 31.98980140686035, policy = 0.05771675705909729, entropy_loss = -0.0021923340391367674, gae = 30.92169952392578, kl_div = 0.07700294256210327, reward = 7.068075180053711, ord = 7.121677875518799, repeat = -2.872286796569824, length = -0.1315772831439972, adv = 1.5618231296539307, rougeL = 1.3977664709091187, cider = 0.19602203369140625, clip = 0.40427467226982117, crf = 0.18781255185604095, ce = 0.7477631568908691, unr = 2.950260877609253, ber = 5.6616530418396\n",
      "refe: [CLS] in this picture we can see people running on the ground in the middle and we have people walking on either side of the path surrounded by trees and grass. [SEP]\n",
      "hypo: [CLS] in the foreground of this image we can see few running on the road, there are trees, we can see trees. [SEP]\n",
      "samp: [CLS] in the foreground of this group of people are people walking on the background i can see a group of people are trees in the background there is a building. [SEP]\n",
      "lr con   : 1.2125944584382872e-10\n",
      "lr bert  : 1.5997481108312342e-08\n",
      "lr cri   : 5.2594458438287154e-05\n",
      "lr others: 4.2513853904282117e-07\n",
      "Train epoch = 0.34005037783375314, loss = 31.949954986572266, policy = 0.06600309163331985, entropy_loss = -0.002184030134230852, gae = 30.871383666992188, kl_div = 0.0773533433675766, reward = 7.091509819030762, ord = 7.1206889152526855, repeat = -2.8529317378997803, length = -0.1321607381105423, adv = 1.555884599685669, rougeL = 1.4011688232421875, cider = 0.19530166685581207, clip = 0.404279500246048, crf = 0.1891026645898819, ce = 0.7482985854148865, unr = 2.955913543701172, ber = 5.660485744476318\n",
      "refe: [CLS] there is a lady wearing chest number is smiling. there is a road. in the back there are many people. and it is blurred in the background. there is a watermark on the right corner. [SEP]\n",
      "hypo: [CLS] in this image, we can see a woman wearing a road and smiling. in the background we can see some people. at the footpath. [SEP]\n",
      "samp: [CLS] in this picture, we can see a woman standing and smiling. in the background i can see some people standing and sky. [SEP]\n",
      "lr con   : 1.1429051217464315e-10\n",
      "lr bert  : 1.507808564231738e-08\n",
      "lr cri   : 4.957178841309823e-05\n",
      "lr others: 4.0070528967254406e-07\n",
      "Train epoch = 0.3778337531486146, loss = 31.859512329101562, policy = 0.06534026563167572, entropy_loss = -0.002170130843296647, gae = 30.7817325592041, kl_div = 0.07732745260000229, reward = 7.106222629547119, ord = 7.1218085289001465, repeat = -2.8427090644836426, length = -0.13218382000923157, adv = 1.5485420227050781, rougeL = 1.4016273021697998, cider = 0.19331610202789307, clip = 0.40423133969306946, crf = 0.18964257836341858, ce = 0.7476416826248169, unr = 2.9593071937561035, ber = 5.659961700439453\n",
      "refe: [CLS] this is an animated image with the numbers and images of the persons and objects in it. [SEP]\n",
      "hypo: [CLS] in this image we can see in this image. [SEP] we can see a person. [SEP]\n",
      "samp: [CLS] in this image i can see some images on the surface. [SEP] characters. [SEP]\n",
      "lr con   : 1.073215785054576e-10\n",
      "lr bert  : 1.4158690176322418e-08\n",
      "lr cri   : 4.654911838790932e-05\n",
      "lr others: 3.76272040302267e-07\n",
      "Train epoch = 0.4156171284634761, loss = 31.86029052734375, policy = 0.07183638960123062, entropy_loss = -0.0021540415473282337, gae = 30.773197174072266, kl_div = 0.07720934599637985, reward = 7.135499000549316, ord = 7.119546413421631, repeat = -2.815932273864746, length = -0.13327248394489288, adv = 1.5442852973937988, rougeL = 1.4015897512435913, cider = 0.19335611164569855, clip = 0.4040531814098358, crf = 0.19124579429626465, ce = 0.7489578127861023, unr = 2.9651577472686768, ber = 5.659417152404785\n",
      "refe: [CLS] this picture shows a man and a dog and in the background their books arranged in the shell [SEP]\n",
      "hypo: [CLS] in this image there is a man is a man who is a person wearing spectacles wearing spectacles. [SEP]\n",
      "samp: [CLS] in this image i can see a man is a dog and he is a person wearing spectacles. [SEP]\n",
      "lr con   : 1.0035264483627203e-10\n",
      "lr bert  : 1.3239294710327456e-08\n",
      "lr cri   : 4.35264483627204e-05\n",
      "lr others: 3.518387909319899e-07\n",
      "Train epoch = 0.4534005037783375, loss = 31.7446231842041, policy = 0.0754915252327919, entropy_loss = -0.0021366416476666927, gae = 30.653884887695312, kl_div = 0.07741747796535492, reward = 7.146430969238281, ord = 7.119246006011963, repeat = -2.8089120388031006, length = -0.13315701484680176, adv = 1.5367366075515747, rougeL = 1.4018365144729614, cider = 0.19422250986099243, clip = 0.4041332006454468, crf = 0.19182032346725464, ce = 0.7481479048728943, unr = 2.9692542552948, ber = 5.659344673156738\n",
      "refe: [CLS] in the image there is a woman with wearing a black suit with a mic in her hand sat, in front of her there is water bottle and glass beside her, on the right side there is a hand visible. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman wearing spectacles on her hand holding a microphone and a microphone and a microphone. [SEP]\n",
      "samp: [CLS] in this image we can see a woman who is a microphone and there is holding a bottle, she is a bottle, in color. [SEP]\n",
      "lr con   : 9.338371116708649e-11\n",
      "lr bert  : 1.2319899244332495e-08\n",
      "lr cri   : 4.0503778337531486e-05\n",
      "lr others: 3.2740554156171283e-07\n",
      "Train epoch = 0.491183879093199, loss = 31.4692440032959, policy = 0.07410679757595062, entropy_loss = -0.002129535423591733, gae = 30.376312255859375, kl_div = 0.0776297077536583, reward = 7.129216194152832, ord = 7.116657257080078, repeat = -2.8204007148742676, length = -0.1343856155872345, adv = 1.5242007970809937, rougeL = 1.400336503982544, cider = 0.19210974872112274, clip = 0.40416884422302246, crf = 0.19296757876873016, ce = 0.7503644227981567, unr = 2.967346668243408, ber = 5.657473087310791\n",
      "refe: [CLS] in the picture there is a road, on the road there are two women walking, beside them there are many vehicles present on the road, there are buildings, there are texts present on the one of the buildings, there are lights, there is a tree, there are small moles present. [SEP]\n",
      "hypo: [CLS] in this image there are two women, a woman is a road. and smiling. in the background there are buildingsbag in the background. [SEP]\n",
      "samp: [CLS] in this image there are two persons standing and there is a road. and smiling. in the back there is a woman is a vehicle. [SEP] cars. [SEP]\n",
      "lr con   : 8.641477749790091e-11\n",
      "lr bert  : 1.140050377833753e-08\n",
      "lr cri   : 3.7481108312342564e-05\n",
      "lr others: 3.029722921914357e-07\n",
      "Train epoch = 0.5289672544080605, loss = 31.15022087097168, policy = 0.07294895499944687, entropy_loss = -0.0021187139209359884, gae = 30.058490753173828, kl_div = 0.0779106467962265, reward = 7.106531143188477, ord = 7.111342430114746, repeat = -2.832840919494629, length = -0.13475757837295532, adv = 1.510827898979187, rougeL = 1.3997124433517456, cider = 0.19045765697956085, clip = 0.4038918912410736, crf = 0.19330407679080963, ce = 0.7496861219406128, unr = 2.962787628173828, ber = 5.653972625732422\n",
      "refe: [CLS] in this image there is a wall on which we can see there are some posters and some graffiti. [SEP]\n",
      "hypo: [CLS] in this image, we can see a door. in the wall. [SEP]\n",
      "samp: [CLS] in this picture, we can see a door. in the wall. [SEP]\n",
      "lr con   : 7.944584382871536e-11\n",
      "lr bert  : 1.048110831234257e-08\n",
      "lr cri   : 3.4458438287153655e-05\n",
      "lr others: 2.785390428211587e-07\n",
      "Train epoch = 0.5667506297229219, loss = 31.031068801879883, policy = 0.07172174751758575, entropy_loss = -0.0021088402718305588, gae = 29.93854331970215, kl_div = 0.0780746191740036, reward = 7.1133131980896, ord = 7.108707427978516, repeat = -2.825324296951294, length = -0.13547754287719727, adv = 1.5034191608428955, rougeL = 1.3994805812835693, cider = 0.18850670754909515, clip = 0.403646856546402, crf = 0.19425033032894135, ce = 0.7505910396575928, unr = 2.965407609939575, ber = 5.6507062911987305\n",
      "refe: [CLS] in this image there are trees, buildings and building. [SEP]\n",
      "hypo: [CLS] in this image we can see the middle of the image, there is a pole, we can see a light. [SEP]\n",
      "samp: [CLS] in this picture we can see buildings, there is a tree. in the background there is blurred. [SEP] we see a glass. [SEP]\n",
      "lr con   : 7.24769101595298e-11\n",
      "lr bert  : 9.561712846347607e-09\n",
      "lr cri   : 3.143576826196473e-05\n",
      "lr others: 2.541057934508816e-07\n",
      "Train epoch = 0.6045340050377834, loss = 31.091806411743164, policy = 0.07087510824203491, entropy_loss = -0.002100894693285227, gae = 29.998502731323242, kl_div = 0.07814599573612213, reward = 7.1507134437561035, ord = 7.1019287109375, repeat = -2.7866525650024414, length = -0.1356574296951294, adv = 1.5021494626998901, rougeL = 1.3990529775619507, cider = 0.18562480807304382, clip = 0.40369299054145813, crf = 0.1949564665555954, ce = 0.7514289021492004, unr = 2.9710938930511475, ber = 5.648390293121338\n",
      "refe: [CLS] in the image there are three men in the front sitting in front of table with food french fries, noodles, toasts, pickles, soft drinks on it and behind there are many ladies and men sitting, this seems to be clicked in a restaurant. [SEP]\n",
      "hypo: [CLS] here we can see a group of the center there is a chair and some plates, in front of the table on the table, there are some food items. [SEP]\n",
      "samp: [CLS] here we can see a group of the center of the middle of the t - shirt with some food items. there are some food items. there is some food items. [SEP]. [SEP]\n",
      "lr con   : 6.550797649034425e-11\n",
      "lr bert  : 8.642317380352645e-09\n",
      "lr cri   : 2.8413098236775818e-05\n",
      "lr others: 2.2967254408060454e-07\n",
      "Train epoch = 0.6423173803526449, loss = 31.167339324951172, policy = 0.06982966512441635, entropy_loss = -0.0020933537743985653, gae = 30.074039459228516, kl_div = 0.07837751507759094, reward = 7.191549301147461, ord = 7.097933292388916, repeat = -2.749959707260132, length = -0.13623031973838806, adv = 1.5019729137420654, rougeL = 1.3988012075424194, cider = 0.1846378594636917, clip = 0.40382927656173706, crf = 0.1954655647277832, ce = 0.7517227530479431, unr = 2.979806423187256, ber = 5.646815776824951\n",
      "refe: [CLS] this person standing playing guitar and singing. there is a microphone with stand. on the background we can see wall, frames, posters. we can see chairs, speakers on the floor. [SEP]\n",
      "hypo: [CLS] in this image i can see a man holding a guitar and a guitar. [SEP]\n",
      "samp: [CLS] in this image i can see a man holding a guitar and a guitar. [SEP]\n",
      "lr con   : 5.853904282115869e-11\n",
      "lr bert  : 7.722921914357682e-09\n",
      "lr cri   : 2.5390428211586902e-05\n",
      "lr others: 2.0523929471032745e-07\n",
      "Train epoch = 0.6801007556675063, loss = 31.1849422454834, policy = 0.06909499317407608, entropy_loss = -0.0020850165747106075, gae = 30.09183692932129, kl_div = 0.07840529084205627, reward = 7.220653057098389, ord = 7.096524238586426, repeat = -2.7255825996398926, length = -0.13722576200962067, adv = 1.4998177289962769, rougeL = 1.3998098373413086, cider = 0.1825040578842163, clip = 0.40397533774375916, crf = 0.19585835933685303, ce = 0.7518343925476074, unr = 2.9869368076324463, ber = 5.6464152336120605\n",
      "refe: [CLS] in the image there is a painting of a bird, honey bees and leaves. below the painting there is something written on it. [SEP]\n",
      "hypo: [CLS] in this image we can see a painting of a paper, we can see a bird. [SEP]\n",
      "samp: [CLS] in this picture we can see a paper on a poster. [SEP] bird. [SEP]\n",
      "lr con   : 5.157010915197313e-11\n",
      "lr bert  : 6.8035264483627206e-09\n",
      "lr cri   : 2.2367758186397984e-05\n",
      "lr others: 1.8080604534005037e-07\n",
      "Train epoch = 0.7178841309823678, loss = 31.245012283325195, policy = 0.06828158348798752, entropy_loss = -0.002077196491882205, gae = 30.15130615234375, kl_div = 0.07851947098970413, reward = 7.253118991851807, ord = 7.097127914428711, repeat = -2.700974225997925, length = -0.13698820769786835, adv = 1.4986776113510132, rougeL = 1.3991730213165283, cider = 0.181804820895195, clip = 0.40418627858161926, crf = 0.19633713364601135, ce = 0.7526488304138184, unr = 2.993952751159668, ber = 5.645686626434326\n",
      "refe: [CLS] in this image, we can see a person sitting on the boat and he is wearing a safety jacket, gloves, a cap and holding a fish. in the background, there is water. [SEP]\n",
      "hypo: [CLS] in this image i can see a person in the person holding a fish in his hand. in his hand and there is a boat on the water. [SEP]\n",
      "samp: [CLS] in this image i can see a man holding a boat and holding a fish in his hand. i can see an object. [SEP]\n",
      "lr con   : 4.460117548278757e-11\n",
      "lr bert  : 5.884130982367758e-09\n",
      "lr cri   : 1.9345088161209068e-05\n",
      "lr others: 1.563727959697733e-07\n",
      "Train epoch = 0.7556675062972292, loss = 31.15390396118164, policy = 0.0676981583237648, entropy_loss = -0.0020711112301796675, gae = 30.05982780456543, kl_div = 0.07856916636228561, reward = 7.261050224304199, ord = 7.0943403244018555, repeat = -2.6911537647247314, length = -0.13745632767677307, adv = 1.4931319952011108, rougeL = 1.3995251655578613, cider = 0.18121860921382904, clip = 0.404308021068573, crf = 0.19668713212013245, ce = 0.7531939744949341, unr = 2.9953203201293945, ber = 5.645569324493408\n",
      "refe: [CLS] in this image i can see a sewing machine which is black and cream in color on the white colored board. i can see a black colored cloth on the board. [SEP]\n",
      "hypo: [CLS] in this image we can see a table on which is a table. [SEP]\n",
      "samp: [CLS] in this picture we can see a briefcase placed on which is a paper. [SEP]\n",
      "lr con   : 3.7632241813602014e-11\n",
      "lr bert  : 4.964735516372796e-09\n",
      "lr cri   : 1.632241813602015e-05\n",
      "lr others: 1.3193954659949622e-07\n",
      "Train epoch = 0.7934508816120907, loss = 31.078880310058594, policy = 0.0671912431716919, entropy_loss = -0.002064882777631283, gae = 29.984514236450195, kl_div = 0.07867591083049774, reward = 7.270158767700195, ord = 7.093804359436035, repeat = -2.6848230361938477, length = -0.13810016214847565, adv = 1.4880993366241455, rougeL = 1.3997925519943237, cider = 0.18181262910366058, clip = 0.40442460775375366, crf = 0.19721058011054993, ce = 0.753357470035553, unr = 2.9992780685424805, ber = 5.645914554595947\n",
      "refe: [CLS] this is ipod in the hand. [SEP]\n",
      "hypo: [CLS] in this image we can see a person holding a person's hand. [SEP]\n",
      "samp: [CLS] in the center we can see a person is holding a mobile phone in the top left side. [SEP]\n",
      "lr con   : 3.066330814441645e-11\n",
      "lr bert  : 4.045340050377834e-09\n",
      "lr cri   : 1.3299748110831234e-05\n",
      "lr others: 1.0750629722921913e-07\n",
      "Train epoch = 0.8312342569269522, loss = 31.13072395324707, policy = 0.0668504536151886, entropy_loss = -0.002054854528978467, gae = 30.03729248046875, kl_div = 0.07876006513834, reward = 7.29831075668335, ord = 7.092226982116699, repeat = -2.6606028079986572, length = -0.13800522685050964, adv = 1.4871716499328613, rougeL = 1.4000850915908813, cider = 0.18137432634830475, clip = 0.4045162498950958, crf = 0.19742049276828766, ce = 0.7524555325508118, unr = 3.004692316055298, ber = 5.645983695983887\n",
      "refe: [CLS] this picture seems to be clicked outside. on the right there is a metal object attached to the wall of a house and we can see the windows and through the window we can see there are some objects placed in the cabinets. [SEP]\n",
      "hypo: [CLS] in this image we can see a black color wall, and there is a wall. [SEP]\n",
      "samp: [CLS] in this image i can see a wall. on the background i can see a wall. [SEP]\n",
      "lr con   : 2.3694374475230897e-11\n",
      "lr bert  : 3.1259445843828713e-09\n",
      "lr cri   : 1.0277078085642317e-05\n",
      "lr others: 8.307304785894206e-08\n",
      "Train epoch = 0.8690176322418136, loss = 31.0745849609375, policy = 0.06630494445562363, entropy_loss = -0.0020470668096095324, gae = 29.983196258544922, kl_div = 0.07887504994869232, reward = 7.304610729217529, ord = 7.091652870178223, repeat = -2.6569840908050537, length = -0.13763251900672913, adv = 1.4823360443115234, rougeL = 1.4003652334213257, cider = 0.18342511355876923, clip = 0.40453508496284485, crf = 0.19729864597320557, ce = 0.7509613633155823, unr = 3.0075745582580566, ber = 5.6463799476623535\n",
      "refe: [CLS] in this image i can see insects are on the leaf. [SEP]\n",
      "hypo: [CLS] in this image we can see an worms orange color. [SEP]\n",
      "samp: [CLS] in this image there are some insects on a tree. [SEP]\n",
      "lr con   : 1.6725440806045338e-11\n",
      "lr bert  : 2.206549118387909e-09\n",
      "lr cri   : 7.2544080604534e-06\n",
      "lr others: 5.863979848866498e-08\n",
      "Train epoch = 0.906801007556675, loss = 31.058412551879883, policy = 0.0665111318230629, entropy_loss = -0.002040798543021083, gae = 29.96675682067871, kl_div = 0.07880273461341858, reward = 7.316870212554932, ord = 7.0942792892456055, repeat = -2.6492714881896973, length = -0.13809707760810852, adv = 1.4790369272232056, rougeL = 1.4017759561538696, cider = 0.18386432528495789, clip = 0.4045272767543793, crf = 0.19749827682971954, ce = 0.7508847713470459, unr = 3.0099599361419678, ber = 5.64647102355957\n",
      "refe: [CLS] in this picture i can observe a pond on the bottom of the picture. there are buildings in this picture. on the left side i can observe a pole. in the background i can observe some clouds in the sky. [SEP]\n",
      "hypo: [CLS] in this image we can see buildings, trees, trees, trees, there are buildings and few people, there are people, we can see a few people on the background there is sky. [SEP]\n",
      "samp: [CLS] in this image i can see buildings, trees, trees, we can see there is a few people, there is water, we can see a few people are walking. [SEP] there is water. [SEP]\n",
      "lr con   : 9.75650713685978e-12\n",
      "lr bert  : 1.287153652392947e-09\n",
      "lr cri   : 4.231738035264483e-06\n",
      "lr others: 3.4206549118387904e-08\n",
      "Train epoch = 0.9445843828715366, loss = 30.986873626708984, policy = 0.06690860539674759, entropy_loss = -0.0020373451989144087, gae = 29.893766403198242, kl_div = 0.07879788428544998, reward = 7.321353435516357, ord = 7.0918402671813965, repeat = -2.6435017585754395, length = -0.13835249841213226, adv = 1.474573016166687, rougeL = 1.4006701707839966, cider = 0.18227830529212952, clip = 0.4044460356235504, crf = 0.19784417748451233, ce = 0.7515963315963745, unr = 3.0113677978515625, ber = 5.645807266235352\n",
      "refe: [CLS] in this picture we can see food items in bowls and these bowls are on a wooden platform and in the background we can see some objects. [SEP]\n",
      "hypo: [CLS] in this image we can see there is a plate is a plate and there is a wooden plate. [SEP]\n",
      "samp: [CLS] in this image i can see there is a plate is a plate, there is a plate. [SEP]\n",
      "lr con   : 2.787573467674223e-12\n",
      "lr bert  : 3.677581863979849e-10\n",
      "lr cri   : 1.2090680100755668e-06\n",
      "lr others: 9.773299748110832e-09\n",
      "Train epoch = 0.982367758186398, loss = 30.91344451904297, policy = 0.06642436236143112, entropy_loss = -0.0020330443512648344, gae = 29.82044792175293, kl_div = 0.0787942111492157, reward = 7.325076103210449, ord = 7.093161106109619, repeat = -2.643361806869507, length = -0.13897447288036346, adv = 1.4703346490859985, rougeL = 1.4005564451217651, cider = 0.1836194097995758, clip = 0.4043959081172943, crf = 0.1980082243680954, ce = 0.751800537109375, unr = 3.014252185821533, ber = 5.646088123321533\n",
      "refe: [CLS] in the image i can see the chairs on the floor. i can see the metallic structure poles in the middle of the picture. i can see the glass windows on the left side and the right side as well. there is a lighting arrangement on the roof. [SEP]\n",
      "hypo: [CLS] in this image there are a room. in this image. [SEP]\n",
      "samp: [CLS] in this picture we can see a group of this image there are some text written cabins lights, lights. [SEP]\n",
      "bsz 56 is not batch_size 128. skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 09:55:51,863] Trial 20 finished with value: 1.7153098583221436 and parameters: {'config.betas': 0, 'config.len_coef': 2.3936949935002425, 'config.unr_coef': 4.346782207555315, 'config.crf_coef': 0.12921371334343312, 'config.ce_coef': 0.36676281737454264, 'config.gae_coef': 4.391875954976487, 'config.clip_range': 0.18121893471742695, 'clip_grad_threshold': 1.3232017031664491}. Best is trial 20 with value: 1.7153098583221436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, avg_reward = 1.7153098583221436\n",
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.18107127052969124\n",
      "clip_grad_threshold gradient norm: 1.41108475447355\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.378662511545963\n",
      "unr_coef: 4.269121635380444\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.09993603449242267\n",
      "ce_coef: 0.3541959789502583\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.319399610060926\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_095604.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb66f9c7c7a4b5ca9af5b36d70604eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 19.276954650878906, policy = 5.161639293760345e-08, entropy_loss = -0.002915809163823724, gae = 18.352771759033203, kl_div = 0.08250536024570465, reward = 4.8577141761779785, ord = 7.012958526611328, repeat = -4.52933931350708, length = -0.10862016677856445, adv = 1.1455341577529907, rougeL = 1.2587077617645264, cider = 0.2307385504245758, clip = 0.40672001242637634, crf = 0.08150803297758102, ce = 0.7630844116210938, unr = 2.482715129852295, ber = 5.700037479400635\n",
      "refe: [CLS] there is one woman standing and wearing a black color dress in the middle of this image. we can see a group of people at the bottom of this image. we can a wall and a curtain in the background. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman is a woman is a woman is a woman is holding a group of people are sitting on the background there are people. [SEP]\n",
      "samp: [CLS] in this image we can see a woman is a woman is a woman sitting in the bottom there is a group of people sitting on the left side of the background there is blurred. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 09:56:22,378] Trial 21 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.18508173242005205\n",
      "clip_grad_threshold gradient norm: 0.821923703201962\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 1.1971654013741235\n",
      "unr_coef: 4.984686765698742\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.30151928335295564\n",
      "ce_coef: 0.1463106993178765\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.411249133064809\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_095634.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "607d8a3c5dde4b85a8338de7e6cd5668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 27.010955810546875, policy = 2.7651639200598765e-08, entropy_loss = -0.0026470075827091932, gae = 26.357954025268555, kl_div = 0.081148162484169, reward = 5.580665588378906, ord = 6.955325126647949, repeat = -4.354129791259766, length = -0.060365621000528336, adv = 1.4761452674865723, rougeL = 1.287436604499817, cider = 0.23378770053386688, clip = 0.40996015071868896, crf = 0.26316797733306885, ce = 0.31133323907852173, unr = 3.0398366451263428, ber = 5.680962085723877\n",
      "refe: [CLS] in this picture i can see there is a doll placed on a white cloth. the backdrop is blurred. [SEP]\n",
      "hypo: [CLS] in this image we can see a toy doll of the background we can see the background. [SEP]\n",
      "samp: [CLS] in this picture we can see a toy. [SEP] eyes. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 09:56:53,305] Trial 22 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.1397858535102262\n",
      "clip_grad_threshold gradient norm: 1.2969598306421775\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.4529240922564224\n",
      "unr_coef: 4.27962560714817\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.1451464355386004\n",
      "ce_coef: 0.5473716981375955\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.939326199114433\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_095706.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e41bbd370646ef9b42cda87d04fb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 15.35379695892334, policy = 2.7037158289999752e-08, entropy_loss = -0.002676148433238268, gae = 14.083765029907227, kl_div = 0.08208630234003067, reward = 5.126026153564453, ord = 7.063921928405762, repeat = -4.369651794433594, length = -0.12814801931381226, adv = 0.8441032767295837, rougeL = 1.2314481735229492, cider = 0.22620360553264618, clip = 0.4060339331626892, crf = 0.1036514863371849, ce = 1.0869706869125366, unr = 2.5599045753479004, ber = 5.669386863708496\n",
      "refe: [CLS] in this image we can see houses, cars, trees. at the bottom of the image there is water. there are ships. at the top of the image there is sky. [SEP]\n",
      "hypo: [CLS] in this image, we can see buildings, trees and some trees. there is a bridge, trees. there are buildings, we can see buildings, buildings, there are trees. [SEP]\n",
      "samp: [CLS] in this image, we can see boats on the foreground there is a bridge, we can see buildings, we can see the background there are buildings, we can see the sky. [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 20.07793426513672, policy = 0.07286415249109268, entropy_loss = -0.002569034928455949, gae = 18.625030517578125, kl_div = 0.08035176247358322, reward = 5.744610786437988, ord = 7.076964378356934, repeat = -3.7712349891662598, length = -0.17002829909324646, adv = 0.9570788145065308, rougeL = 1.311302900314331, cider = 0.2124595195055008, clip = 0.4009699821472168, crf = 0.1688041090965271, ce = 1.1334526538848877, unr = 2.608910083770752, ber = 5.661126136779785\n",
      "refe: [CLS] in the picture we can see a woman standing near the jar holding a yellow spoon and serving in the glass which she is holding in the other hand and beside the jar we can see some other jars and behind her we can see some people are standing in the dark. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman holding a glass and a glass. in the foreground of the foreground\n",
      "samp: [CLS] in this image we can see a woman and a bottle and a glass. in the foreground of the foreground of the left side. [SEP]\n",
      "lr con   : 1.2962216624685136e-10\n",
      "lr bert  : 1.7100755667506296e-08\n",
      "lr cri   : 5.622166246851385e-05\n",
      "lr others: 4.544584382871536e-07\n",
      "Train epoch = 0.07556675062972293, loss = 20.772136688232422, policy = 0.07838605344295502, entropy_loss = -0.002467662561684847, gae = 19.30617332458496, kl_div = 0.08258660137653351, reward = 5.892387866973877, ord = 7.052958965301514, repeat = -3.652620315551758, length = -0.17293281853199005, adv = 0.9722521901130676, rougeL = 1.313880205154419, cider = 0.21490107476711273, clip = 0.40144962072372437, crf = 0.1759074479341507, ce = 1.1315462589263916, unr = 2.664982318878174, ber = 5.644260883331299\n",
      "refe: [CLS] in the image in the center, we can see one person and he is in black color t shirt. in the background there is a slope and water. [SEP]\n",
      "hypo: [CLS] in this image there is a man standing. in the water. in the background there is blurred. [SEP]\n",
      "samp: [CLS] in this image there is a man standing. in the middle of the background. [SEP] there is blurred. [SEP]\n",
      "lr con   : 1.6307304785894207e-10\n",
      "lr bert  : 2.1513853904282117e-08\n",
      "lr cri   : 7.073047858942065e-05\n",
      "lr others: 5.717380352644836e-07\n",
      "Train epoch = 0.11335012594458438, loss = 21.1093692779541, policy = 0.2674438953399658, entropy_loss = -0.002437952673062682, gae = 19.466768264770508, kl_div = 0.08446171879768372, reward = 5.984125137329102, ord = 7.028569221496582, repeat = -3.5739426612854004, length = -0.17314276099205017, adv = 0.9745638966560364, rougeL = 1.3070980310440063, cider = 0.20748396217823029, clip = 0.4033485949039459, crf = 0.16706989705562592, ce = 1.1260634660720825, unr = 2.702641725540161, ber = 5.638326168060303\n",
      "refe: [CLS] there are two white sofas on the either side and there is a table and a red chair in between them and there is also a stair case and book shelf in background. [SEP]\n",
      "hypo: [CLS] in this image we can see a room. in this image sofas, we can see a dining table. [SEP]\n",
      "samp: [CLS] this picture describes about can see a room. in this room. in the foreground there are chairs on the table. [SEP] furniture. [SEP]\n",
      "lr con   : 1.561041141897565e-10\n",
      "lr bert  : 2.0594458438287153e-08\n",
      "lr cri   : 6.770780856423173e-05\n",
      "lr others: 5.473047858942065e-07\n",
      "Train epoch = 0.15113350125944586, loss = 22.79630470275879, policy = 0.2185070812702179, entropy_loss = -0.002356354845687747, gae = 21.197294235229492, kl_div = 0.0840403288602829, reward = 6.323643207550049, ord = 7.031540870666504, repeat = -3.3116114139556885, length = -0.17463000118732452, adv = 1.022368311882019, rougeL = 1.3246872425079346, cider = 0.20415370166301727, clip = 0.4035370945930481, crf = 0.17894580960273743, ce = 1.1198722124099731, unr = 2.778343677520752, ber = 5.639294624328613\n",
      "refe: [CLS] in this image i can see a woman wearing black and white colored dress and black colored hat is standing and smiling and i can see few flowers which are red and green in color beside her. in the background i can see the grass, few trees, a building and the sky. [SEP]\n",
      "hypo: [CLS] in this picture there is a woman we can see a flower bouquet. in front of the background of the background there are plants, trees. [SEP]\n",
      "samp: [CLS] in this picture there is a woman standing. in the front of the bottom of the left side of the background there are plants, trees. [SEP] grass. [SEP]\n",
      "lr con   : 1.4913518052057094e-10\n",
      "lr bert  : 1.9675062972292192e-08\n",
      "lr cri   : 6.468513853904282e-05\n",
      "lr others: 5.228715365239295e-07\n",
      "Train epoch = 0.1889168765743073, loss = 23.694108963012695, policy = 0.18704178929328918, entropy_loss = -0.0023140818811953068, gae = 22.108844757080078, kl_div = 0.08360189199447632, reward = 6.512682914733887, ord = 7.040447235107422, repeat = -3.1693644523620605, length = -0.18092267215251923, adv = 1.042587399482727, rougeL = 1.339956283569336, cider = 0.194563090801239, clip = 0.4031287431716919, crf = 0.1880401372909546, ce = 1.128894567489624, unr = 2.8225224018096924, ber = 5.639941215515137\n",
      "refe: [CLS] in the picture we can see a woman standing near the wall and behind the wall we can see the water surface and far away from it we can see the hill slope and the sky. [SEP]\n",
      "hypo: [CLS] in the foreground of a woman there is a woman standing on the background. behind her hand. there is water. [SEP] we can see water. [SEP]\n",
      "samp: [CLS] in this picture there is a woman who is a woman standing. i can see some smiling. at the water, water, we can see a tree. [SEP]\n",
      "lr con   : 1.4216624685138537e-10\n",
      "lr bert  : 1.8755667506297228e-08\n",
      "lr cri   : 6.16624685138539e-05\n",
      "lr others: 4.984382871536523e-07\n",
      "Train epoch = 0.22670025188916876, loss = 24.200519561767578, policy = 0.16567671298980713, entropy_loss = -0.002284127054736018, gae = 22.620508193969727, kl_div = 0.08332452923059464, reward = 6.631601333618164, ord = 7.039205551147461, repeat = -3.0745627880096436, length = -0.18674229085445404, adv = 1.05045747756958, rougeL = 1.3502476215362549, cider = 0.1874474436044693, clip = 0.40383219718933105, crf = 0.1955561637878418, ce = 1.1377378702163696, unr = 2.853701114654541, ber = 5.637152194976807\n",
      "refe: [CLS] in this image i can see there are sculptures and at the back it looks like a cloth. [SEP]\n",
      "hypo: [CLS] in this image we can see a statue. [SEP]\n",
      "samp: [CLS] in this image we can see a statue. [SEP]. [SEP]\n",
      "lr con   : 1.3519731318219982e-10\n",
      "lr bert  : 1.7836272040302267e-08\n",
      "lr cri   : 5.863979848866499e-05\n",
      "lr others: 4.740050377833753e-07\n",
      "Train epoch = 0.26448362720403024, loss = 24.344036102294922, policy = 0.15441885590553284, entropy_loss = -0.0022615278139710426, gae = 22.77381134033203, kl_div = 0.082901231944561, reward = 6.683267116546631, ord = 7.04200553894043, repeat = -3.032790184020996, length = -0.18744529783725739, adv = 1.0459554195404053, rougeL = 1.3549010753631592, cider = 0.18518374860286713, clip = 0.40407660603523254, crf = 0.19970783591270447, ce = 1.1354583501815796, unr = 2.861497640609741, ber = 5.636744976043701\n",
      "refe: [CLS] in the picture we can see a man sitting on the floor and holding something in his hand with the bottle of drink, and near to him there is a bird, a man is wearing a sweater and black pant. [SEP]\n",
      "hypo: [CLS] in this image we can see a man sitting on the image is holding an object in his hand. [SEP]\n",
      "samp: [CLS] in this image we can see a man in front of the picture, in his hand in his hand. in his hand. [SEP]. [SEP] grass. [SEP]\n",
      "lr con   : 1.2822837951301427e-10\n",
      "lr bert  : 1.6916876574307306e-08\n",
      "lr cri   : 5.561712846347607e-05\n",
      "lr others: 4.495717884130982e-07\n",
      "Train epoch = 0.3022670025188917, loss = 24.450237274169922, policy = 0.14210116863250732, entropy_loss = -0.0022444897331297398, gae = 22.887258529663086, kl_div = 0.0826815813779831, reward = 6.72990608215332, ord = 7.042614936828613, repeat = -2.9932916164398193, length = -0.19096335768699646, adv = 1.041311264038086, rougeL = 1.359890103340149, cider = 0.1855352222919464, clip = 0.4044836461544037, crf = 0.2030915468931198, ce = 1.1373498439788818, unr = 2.8715457916259766, ber = 5.635931968688965\n",
      "refe: [CLS] in this image in the foreground there is one glass window, on that window there is one bee. in the background there are some trees and a walkway. [SEP]\n",
      "hypo: [CLS] in this image we can see a part of the background we can see the background there is sky. [SEP]\n",
      "samp: [CLS] in this image i can see a vehicle. at the background we can see the background i can see a car. [SEP]\n",
      "lr con   : 1.2125944584382872e-10\n",
      "lr bert  : 1.5997481108312342e-08\n",
      "lr cri   : 5.2594458438287154e-05\n",
      "lr others: 4.2513853904282117e-07\n",
      "Train epoch = 0.34005037783375314, loss = 24.46889877319336, policy = 0.13245889544487, entropy_loss = -0.002229685429483652, gae = 22.910795211791992, kl_div = 0.08278767764568329, reward = 6.7676568031311035, ord = 7.043071269989014, repeat = -2.9643986225128174, length = -0.19246533513069153, adv = 1.035347580909729, rougeL = 1.3622242212295532, cider = 0.1807020902633667, clip = 0.4048103988170624, crf = 0.20634542405605316, ce = 1.1387392282485962, unr = 2.8814494609832764, ber = 5.635829925537109\n",
      "refe: [CLS] there are two men standing side by side. the man with white checks shirt is standing to the left. on his head there is a dog. to the right side there is a man with violet color t - shirt holding a glass in his hand. [SEP]\n",
      "hypo: [CLS] in this image we can see a person's are smiling. [SEP]\n",
      "samp: [CLS] in this image we can see a person's are smiling. [SEP] arms center of the glass. [SEP]. [SEP]\n",
      "lr con   : 1.1429051217464315e-10\n",
      "lr bert  : 1.507808564231738e-08\n",
      "lr cri   : 4.957178841309823e-05\n",
      "lr others: 4.0070528967254406e-07\n",
      "Train epoch = 0.3778337531486146, loss = 24.504350662231445, policy = 0.1259366124868393, entropy_loss = -0.00221554609015584, gae = 22.950393676757812, kl_div = 0.0829140692949295, reward = 6.810784816741943, ord = 7.038656711578369, repeat = -2.925682306289673, length = -0.19262845814228058, adv = 1.030605673789978, rougeL = 1.3608332872390747, cider = 0.181020587682724, clip = 0.4046926200389862, crf = 0.20837654173374176, ce = 1.1389440298080444, unr = 2.890437364578247, ber = 5.634387969970703\n",
      "refe: [CLS] this image is taken outdoors. at the bottom of the image there is a ground with grass and many dry leaves on it. at the top of the image there is the sky with clouds. in the background there are many trees and plants with stems, branches and leaves. on the left side of the image there are a few rocks and there is an algae on the rocks. [SEP]\n",
      "hypo: [CLS] in this image we can see the plants. at the ground. [SEP]\n",
      "samp: [CLS] in this picture we can see the ground. at the ground. [SEP]. [SEP]\n",
      "lr con   : 1.073215785054576e-10\n",
      "lr bert  : 1.4158690176322418e-08\n",
      "lr cri   : 4.654911838790932e-05\n",
      "lr others: 3.76272040302267e-07\n",
      "Train epoch = 0.4156171284634761, loss = 24.524761199951172, policy = 0.11962612718343735, entropy_loss = -0.0021984803024679422, gae = 22.97655487060547, kl_div = 0.08304847776889801, reward = 6.846199035644531, ord = 7.034428119659424, repeat = -2.891660451889038, length = -0.19279319047927856, adv = 1.0245476961135864, rougeL = 1.3633313179016113, cider = 0.18016619980335236, clip = 0.4043341875076294, crf = 0.20995648205280304, ce = 1.1377737522125244, unr = 2.8962247371673584, ber = 5.632309913635254\n",
      "refe: [CLS] in this image i can see two aircraft in white and red color and something is written on it. background is in white color. [SEP]\n",
      "hypo: [CLS] in this image we can see a poster. i can see some text written. [SEP]\n",
      "samp: [CLS] in this picture we can see a board with some information looks like a poster. [SEP]\n",
      "lr con   : 1.0035264483627203e-10\n",
      "lr bert  : 1.3239294710327456e-08\n",
      "lr cri   : 4.35264483627204e-05\n",
      "lr others: 3.518387909319899e-07\n",
      "Train epoch = 0.4534005037783375, loss = 24.531808853149414, policy = 0.11403283476829529, entropy_loss = -0.0021842860151082277, gae = 22.990209579467773, kl_div = 0.08315550535917282, reward = 6.8702850341796875, ord = 7.033204078674316, repeat = -2.8693723678588867, length = -0.19182062149047852, adv = 1.0170834064483643, rougeL = 1.365019679069519, cider = 0.17975713312625885, clip = 0.4041634798049927, crf = 0.21123751997947693, ce = 1.1353577375411987, unr = 2.8982744216918945, ber = 5.630436420440674\n",
      "refe: [CLS] these picture is taken on the sea shore. on the shore, there are people scattered around. some of the people are playing volleyball. on the water, there is a person standing on the board. in the background, there are trees. [SEP]\n",
      "hypo: [CLS] in this picture we can see water, in the water, the water, we can see the background of the right side, we can see trees. [SEP]\n",
      "samp: [CLS] in this picture we can see water, in the foreground of the background i can see the background of the right side there are trees and sky. [SEP]\n",
      "lr con   : 9.338371116708649e-11\n",
      "lr bert  : 1.2319899244332495e-08\n",
      "lr cri   : 4.0503778337531486e-05\n",
      "lr others: 3.2740554156171283e-07\n",
      "Train epoch = 0.491183879093199, loss = 24.477102279663086, policy = 0.11294325441122055, entropy_loss = -0.002169304294511676, gae = 22.937393188476562, kl_div = 0.08317697048187256, reward = 6.8868560791015625, ord = 7.034945011138916, repeat = -2.8552427291870117, length = -0.1925610601902008, adv = 1.008455514907837, rougeL = 1.3680264949798584, cider = 0.18214312195777893, clip = 0.40410733222961426, crf = 0.2120046615600586, ce = 1.1337543725967407, unr = 2.8997159004211426, ber = 5.6292009353637695\n",
      "refe: [CLS] a man is standing wearing t shirt and trouser, this is belt, this is cream color. [SEP]\n",
      "hypo: [CLS] in this image we can see a man standing and standing. in the background. [SEP]\n",
      "samp: [CLS] in this image we can see a man and he is wearing a white color. [SEP]. [SEP]\n",
      "lr con   : 8.641477749790091e-11\n",
      "lr bert  : 1.140050377833753e-08\n",
      "lr cri   : 3.7481108312342564e-05\n",
      "lr others: 3.029722921914357e-07\n",
      "Train epoch = 0.5289672544080605, loss = 24.501096725463867, policy = 0.11302144825458527, entropy_loss = -0.0021591277327388525, gae = 22.956457138061523, kl_div = 0.08300688117742538, reward = 6.9158735275268555, ord = 7.031830310821533, repeat = -2.8266167640686035, length = -0.1942792683839798, adv = 1.0029363632202148, rougeL = 1.36799156665802, cider = 0.18238145112991333, clip = 0.40366247296333313, crf = 0.21374760568141937, ce = 1.1370235681533813, unr = 2.904939651489258, ber = 5.626798152923584\n",
      "refe: [CLS] in this picture we can observe two cars on the road. they are in blue and white color. we can observe different colors of buildings. there are some trees. in the background there is a sky. [SEP]\n",
      "hypo: [CLS] in this picture, we can see few buildings, windows, doors. in the road. on the building. [SEP]\n",
      "samp: [CLS] in the foreground of this image, windows, grass, plants, windows. we can see the building. [SEP]\n",
      "lr con   : 7.944584382871536e-11\n",
      "lr bert  : 1.048110831234257e-08\n",
      "lr cri   : 3.4458438287153655e-05\n",
      "lr others: 2.785390428211587e-07\n",
      "Train epoch = 0.5667506297229219, loss = 24.510618209838867, policy = 0.11107081919908524, entropy_loss = -0.002149091800674796, gae = 22.966588973999023, kl_div = 0.08325847238302231, reward = 6.9432878494262695, ord = 7.029355049133301, repeat = -2.8030381202697754, length = -0.19637557864189148, adv = 0.9975371956825256, rougeL = 1.36661696434021, cider = 0.18348614871501923, clip = 0.4037405848503113, crf = 0.214737206697464, ce = 1.137110710144043, unr = 2.9133477210998535, ber = 5.625859260559082\n",
      "refe: [CLS] this is animated picture, we can see three people, this man holding guns and this woman holding a tool. we can see floor and right side of the image we can see a gun hold with hand. top we can see light. [SEP]\n",
      "hypo: [CLS] in the foreground of a collage of this image. we can see a floor. [SEP]\n",
      "samp: [CLS] in this picture we can see group of this image, in the image there is holding an object. [SEP]. [SEP]\n",
      "lr con   : 7.24769101595298e-11\n",
      "lr bert  : 9.561712846347607e-09\n",
      "lr cri   : 3.143576826196473e-05\n",
      "lr others: 2.541057934508816e-07\n",
      "Train epoch = 0.6045340050377834, loss = 24.567853927612305, policy = 0.1081693023443222, entropy_loss = -0.0021376730874180794, gae = 23.0286808013916, kl_div = 0.0831465944647789, reward = 6.978226661682129, ord = 7.033926010131836, repeat = -2.778546094894409, length = -0.19657529890537262, adv = 0.9940930604934692, rougeL = 1.3673990964889526, cider = 0.18542423844337463, clip = 0.4034765064716339, crf = 0.2150387018918991, ce = 1.134955883026123, unr = 2.9194211959838867, ber = 5.626853942871094\n",
      "refe: [CLS] in this image, we can see a lake. there are some dry trees in the middle of the image. there are clouds in the sky. [SEP]\n",
      "hypo: [CLS] in this image we can see water, we can see some plants. [SEP]\n",
      "samp: [CLS] in this picture, we can see some trees in the water. at the sky. [SEP]\n",
      "lr con   : 6.550797649034425e-11\n",
      "lr bert  : 8.642317380352645e-09\n",
      "lr cri   : 2.8413098236775818e-05\n",
      "lr others: 2.2967254408060454e-07\n",
      "Train epoch = 0.6423173803526449, loss = 24.53676986694336, policy = 0.10512492060661316, entropy_loss = -0.002130751498043537, gae = 23.001359939575195, kl_div = 0.08306223899126053, reward = 6.99348258972168, ord = 7.0364861488342285, repeat = -2.767888069152832, length = -0.19660751521587372, adv = 0.9875725507736206, rougeL = 1.3674260377883911, cider = 0.18768733739852905, clip = 0.40333154797554016, crf = 0.2157052904367447, ce = 1.1336491107940674, unr = 2.921492099761963, ber = 5.626160621643066\n",
      "refe: [CLS] here i can see a building. in the middle of the image there is a railing. on the top i can see the sky. [SEP]\n",
      "hypo: [CLS] in this image i can see a building. this looks like a building. [SEP] pillars. [SEP]. [SEP]\n",
      "samp: [CLS] in this image i can see the monuments, there is made up of the road. [SEP]. [SEP]\n",
      "lr con   : 5.853904282115869e-11\n",
      "lr bert  : 7.722921914357682e-09\n",
      "lr cri   : 2.5390428211586902e-05\n",
      "lr others: 2.0523929471032745e-07\n",
      "Train epoch = 0.6801007556675063, loss = 24.373491287231445, policy = 0.10640209168195724, entropy_loss = -0.002127823419868946, gae = 22.843481063842773, kl_div = 0.08308876305818558, reward = 6.983952045440674, ord = 7.036279678344727, repeat = -2.779404878616333, length = -0.1946597397327423, adv = 0.9767570495605469, rougeL = 1.3645111322402954, cider = 0.18919619917869568, clip = 0.4033498466014862, crf = 0.21368786692619324, ce = 1.1289561986923218, unr = 2.9217371940612793, ber = 5.625317573547363\n",
      "refe: [CLS] in this picture there is a man playing a guitar. there is a mic. [SEP]\n",
      "hypo: [CLS] in this picture we can see a man playing guitar. [SEP]\n",
      "samp: [CLS] in this image i can see a person playing guitar. [SEP] singing. [SEP]\n",
      "lr con   : 5.157010915197313e-11\n",
      "lr bert  : 6.8035264483627206e-09\n",
      "lr cri   : 2.2367758186397984e-05\n",
      "lr others: 1.8080604534005037e-07\n",
      "Train epoch = 0.7178841309823678, loss = 24.40096664428711, policy = 0.13628272712230682, entropy_loss = -0.002122806617990136, gae = 22.84456443786621, kl_div = 0.0828925147652626, reward = 7.0025835037231445, ord = 7.0366106033325195, repeat = -2.76393723487854, length = -0.19468581676483154, adv = 0.9714338183403015, rougeL = 1.363782525062561, cider = 0.18955303728580475, clip = 0.4032552242279053, crf = 0.212195485830307, ce = 1.127158284187317, unr = 2.9245965480804443, ber = 5.626368999481201\n",
      "refe: [CLS] there are 5 wine bottles, food on the table. [SEP]\n",
      "hypo: [CLS] in this picture, we can see a table. [SEP] table. in the right side. [SEP]\n",
      "samp: [CLS] in this picture, we can see a table. [SEP] are bottles, in the top left side. [SEP]\n",
      "lr con   : 4.460117548278757e-11\n",
      "lr bert  : 5.884130982367758e-09\n",
      "lr cri   : 1.9345088161209068e-05\n",
      "lr others: 1.563727959697733e-07\n",
      "Train epoch = 0.7556675062972292, loss = 24.119712829589844, policy = 0.1516944020986557, entropy_loss = -0.00213624513708055, gae = 22.551815032958984, kl_div = 0.08293449878692627, reward = 6.966848850250244, ord = 7.034188270568848, repeat = -2.7943403720855713, length = -0.19388288259506226, adv = 0.9568491578102112, rougeL = 1.3586201667785645, cider = 0.19102218747138977, clip = 0.40344342589378357, crf = 0.20760135352611542, ce = 1.1278070211410522, unr = 2.9208850860595703, ber = 5.626761436462402\n",
      "refe: [CLS] people are running on the road. in the background we can see trees, plants and sky. [SEP]\n",
      "hypo: [CLS] in this image we can see a group of people on the group of the road. i can see some trees. [SEP]\n",
      "samp: [CLS] in this image we can see the group of people on the road. at the road. [SEP] jogging grass. [SEP] sky. [SEP]\n",
      "lr con   : 3.7632241813602014e-11\n",
      "lr bert  : 4.964735516372796e-09\n",
      "lr cri   : 1.632241813602015e-05\n",
      "lr others: 1.3193954659949622e-07\n",
      "Train epoch = 0.7934508816120907, loss = 24.26941680908203, policy = 0.24245595932006836, entropy_loss = -0.0021423932630568743, gae = 22.616912841796875, kl_div = 0.0828949585556984, reward = 6.996266841888428, ord = 7.0348358154296875, repeat = -2.7736737728118896, length = -0.19507111608982086, adv = 0.9549514055252075, rougeL = 1.361063003540039, cider = 0.18879467248916626, clip = 0.4031846225261688, crf = 0.2031318098306656, ce = 1.1261651515960693, unr = 2.930176258087158, ber = 5.627250671386719\n",
      "refe: [CLS] in this image i can see few trees, houses, stones, few clothes and dry trees. [SEP]\n",
      "hypo: [CLS] in this picture we can see trees, there are trees and the sky. [SEP]. [SEP]\n",
      "samp: [CLS] in this picture we can see the group of the top of this image. [SEP]. [SEP]. [SEP]\n",
      "lr con   : 3.066330814441645e-11\n",
      "lr bert  : 4.045340050377834e-09\n",
      "lr cri   : 1.3299748110831234e-05\n",
      "lr others: 1.0750629722921913e-07\n",
      "Train epoch = 0.8312342569269522, loss = 24.127552032470703, policy = 0.26086464524269104, entropy_loss = -0.002150031505152583, gae = 22.458200454711914, kl_div = 0.08287981897592545, reward = 6.983453750610352, ord = 7.03216552734375, repeat = -2.7849888801574707, length = -0.19593924283981323, adv = 0.9454423189163208, rougeL = 1.3597973585128784, cider = 0.18953749537467957, clip = 0.4031744599342346, crf = 0.1997416913509369, ce = 1.1280145645141602, unr = 2.9322164058685303, ber = 5.6280975341796875\n",
      "refe: [CLS] in the image there is a cup with some drink and behind that cup there is a clear view of the city, it has many buildings and there is a river and there is a bridge across that river, some vehicles are moving on the bridge. [SEP]\n",
      "hypo: [CLS] in this image, we can see a glass glass, there is a glass. in the water, we can see buildings. [SEP] buildings. [SEP]\n",
      "samp: [CLS] in this picture, we can see a glass, in the glass in the middle of drink in the foreground of the foreground of the table. [SEP] seen. [SEP] sky. [SEP]\n",
      "lr con   : 2.3694374475230897e-11\n",
      "lr bert  : 3.1259445843828713e-09\n",
      "lr cri   : 1.0277078085642317e-05\n",
      "lr others: 8.307304785894206e-08\n",
      "Train epoch = 0.8690176322418136, loss = 24.221210479736328, policy = 0.29753631353378296, entropy_loss = -0.0021556455176323652, gae = 22.51892852783203, kl_div = 0.08272017538547516, reward = 7.0144782066345215, ord = 7.0325751304626465, repeat = -2.760530948638916, length = -0.19741494953632355, adv = 0.9447442293167114, rougeL = 1.362415075302124, cider = 0.18732398748397827, clip = 0.4030933082103729, crf = 0.19633452594280243, ce = 1.1278477907180786, unr = 2.939849376678467, ber = 5.627894878387451\n",
      "refe: [CLS] in this image i can see group of people. in the background i can see few objects in gray color, few poles, lights and the sky is in white color. [SEP]\n",
      "hypo: [CLS] in this image there are group of the foreground there are standing. [SEP]. [SEP]\n",
      "samp: [CLS] in this image i can see group of people standing in the background i can see some objects. [SEP]\n",
      "lr con   : 1.6725440806045338e-11\n",
      "lr bert  : 2.206549118387909e-09\n",
      "lr cri   : 7.2544080604534e-06\n",
      "lr others: 5.863979848866498e-08\n",
      "Train epoch = 0.906801007556675, loss = 24.383243560791016, policy = 0.3471533954143524, entropy_loss = -0.0021570022217929363, gae = 22.636505126953125, kl_div = 0.08256574720144272, reward = 7.0513763427734375, ord = 7.033902168273926, repeat = -2.7354540824890137, length = -0.19707325100898743, adv = 0.9452948570251465, rougeL = 1.3641035556793213, cider = 0.1869768500328064, clip = 0.40305593609809875, crf = 0.19301144778728485, ce = 1.1261630058288574, unr = 2.950002908706665, ber = 5.6282172203063965\n",
      "refe: [CLS] in the image there is a man and only the head of the man is visible, the background of him is blur. [SEP]\n",
      "hypo: [CLS] in this picture we can see a person wearing clothes. [SEP]\n",
      "samp: [CLS] in this picture we can see a person. [SEP]\n",
      "lr con   : 9.75650713685978e-12\n",
      "lr bert  : 1.287153652392947e-09\n",
      "lr cri   : 4.231738035264483e-06\n",
      "lr others: 3.4206549118387904e-08\n",
      "Train epoch = 0.9445843828715366, loss = 24.38419532775879, policy = 0.3983374238014221, entropy_loss = -0.0021628406830132008, gae = 22.588716506958008, kl_div = 0.08244578540325165, reward = 7.05648946762085, ord = 7.0292253494262695, repeat = -2.7292003631591797, length = -0.1988937109708786, adv = 0.9403039813041687, rougeL = 1.3653684854507446, cider = 0.18485800921916962, clip = 0.40291252732276917, crf = 0.19035093486309052, ce = 1.1265058517456055, unr = 2.9553592205047607, ber = 5.627860069274902\n",
      "refe: [CLS] in this image on the right side we can see a open shed, chair, railing, roof and grass at the bottom. in the background we can see trees. [SEP]\n",
      "hypo: [CLS] in this image we can see a wooden grass on the wooden grass, grass. [SEP]\n",
      "samp: [CLS] in this picture, we can see some grass, grass, grass. there is a building. [SEP]\n",
      "lr con   : 2.787573467674223e-12\n",
      "lr bert  : 3.677581863979849e-10\n",
      "lr cri   : 1.2090680100755668e-06\n",
      "lr others: 9.773299748110832e-09\n",
      "Train epoch = 0.982367758186398, loss = 24.402862548828125, policy = 0.3980238139629364, entropy_loss = -0.002167052123695612, gae = 22.610998153686523, kl_div = 0.08231180161237717, reward = 7.073304653167725, ord = 7.028966903686523, repeat = -2.7174320220947266, length = -0.1989564150571823, adv = 0.9379196166992188, rougeL = 1.3663266897201538, cider = 0.1840963065624237, clip = 0.40274500846862793, crf = 0.1875912994146347, ce = 1.126104712486267, unr = 2.9607274532318115, ber = 5.6276326179504395\n",
      "refe: [CLS] in this picture there are people sitting in vehicles and we can see poles, boards, banner, lights, shed and objects. in the background of the image we can see leaves. [SEP]\n",
      "hypo: [CLS] in this picture we can see three people sitting on the vehicle. [SEP]\n",
      "samp: [CLS] in this picture we can see three people sitting on the picture there are two persons sitting on the car. [SEP] standing. [SEP]. [SEP]\n",
      "bsz 56 is not batch_size 128. skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 10:54:23,870] Trial 23 finished with value: 1.684715986251831 and parameters: {'config.betas': 0, 'config.len_coef': 3.4529240922564224, 'config.unr_coef': 4.27962560714817, 'config.crf_coef': 0.1451464355386004, 'config.ce_coef': 0.5473716981375955, 'config.gae_coef': 4.939326199114433, 'config.clip_range': 0.1397858535102262, 'clip_grad_threshold': 1.2969598306421775}. Best is trial 20 with value: 1.7153098583221436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, avg_reward = 1.684715986251831\n",
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.14537436628840317\n",
      "clip_grad_threshold gradient norm: 1.8527255244690948\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.299668360988019\n",
      "unr_coef: 4.3334945535694835\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.08937364518098076\n",
      "ce_coef: 0.5731307505144451\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.923883637132983\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_105436.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f19aab2462014b84a09aebbb903fe930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 23.64472198486328, policy = 0.0, entropy_loss = -0.002651211339980364, gae = 22.35760498046875, kl_div = 0.08434556424617767, reward = 5.07752799987793, ord = 6.999523162841797, repeat = -4.391523361206055, length = -0.10962710529565811, adv = 1.3258641958236694, rougeL = 1.22190260887146, cider = 0.24873954057693481, clip = 0.4026413559913635, crf = 0.06223075091838837, ce = 1.1431916952133179, unr = 2.579155445098877, ber = 5.675737380981445\n",
      "refe: [CLS] in this image we can see a woman holding the mike and also wearing the watch. in the background we can see the black color curtain and we can also see some wires at the bottom. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman standing and a microphone and she is a microphone. [SEP]\n",
      "samp: [CLS] in this picture we can see a woman in front of the right side of the background there is holding a black color. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 10:54:54,576] Trial 24 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.1031319005122096\n",
      "clip_grad_threshold gradient norm: 0.5620370647666674\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.676964139284956\n",
      "unr_coef: 2.9868439332668233\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.13643684285559998\n",
      "ce_coef: 0.43473448056457437\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.641382152561937\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_105507.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed6557fa9b7499795600193b46c3553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 17.758058547973633, policy = 5.991188345433329e-08, entropy_loss = -0.00285329669713974, gae = 16.704761505126953, kl_div = 0.07748527079820633, reward = 4.222093105316162, ord = 6.951268672943115, repeat = -4.414571285247803, length = -0.0798720121383667, adv = 1.1515828371047974, rougeL = 1.1503489017486572, cider = 0.20608966052532196, clip = 0.39850282669067383, crf = 0.10535064339637756, ce = 0.873313307762146, unr = 1.7652682065963745, ber = 5.62835693359375\n",
      "refe: [CLS] in this image i can see a bottle and a glass with full of drink in it. [SEP]\n",
      "hypo: [CLS] in this image, we can see glass, we can see a glass in the background there is a glass and we can see a blurry. [SEP]\n",
      "samp: [CLS] in this picture, we can see there is a glass in the glass in the background we can see the top there is blurred. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 10:55:24,990] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.1446945431114914\n",
      "clip_grad_threshold gradient norm: 1.2553235187910814\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.202971635055366\n",
      "unr_coef: 4.354395993567951\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.29528974495360716\n",
      "ce_coef: 0.3685827345407754\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.9910701317253725\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_105537.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb0451dee17467cab792df04c5f34d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 28.24030113220215, policy = 7.373770039009742e-09, entropy_loss = -0.002669914159923792, gae = 27.235265731811523, kl_div = 0.08137677609920502, reward = 5.491109371185303, ord = 7.08121919631958, repeat = -4.148817539215088, length = -0.06920869648456573, adv = 1.384942650794983, rougeL = 1.226864218711853, cider = 0.21730801463127136, clip = 0.4011949598789215, crf = 0.2069217711687088, ce = 0.7194041609764099, unr = 2.6279163360595703, ber = 5.655869007110596\n",
      "refe: [CLS] in this picture we can see women standing. there is a table. on the table we can see laptop, speaker, cable, glass, papers, mobile. we can see chair. in this background we can see screen and wall and there is a door. there is a board. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman is a woman standing and a table and a table on a table, laptop, laptop, laptop, there is a woman. [SEP]\n",
      "samp: [CLS] in this image we can see a woman is one woman she is a woman is a table on a table, laptop, laptop, laptop, wires. on the background i can see a projector. [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 30.798784255981445, policy = 0.09389320015907288, entropy_loss = -0.0025861787144094706, gae = 29.538860321044922, kl_div = 0.07706332206726074, reward = 5.73021125793457, ord = 7.12687873840332, repeat = -3.910285711288452, length = -0.10981045663356781, adv = 1.4282644987106323, rougeL = 1.305644154548645, cider = 0.21462826430797577, clip = 0.3989522159099579, crf = 0.3403383493423462, ce = 0.7512103915214539, unr = 2.6234288215637207, ber = 5.6542816162109375\n",
      "refe: [CLS] in the picture we can see group of people standing, some are holding glasses in their hands and in the background of the picture there is a wall to which photo frame is attached and we can see multi color cloth and there are some doors. [SEP]\n",
      "hypo: [CLS] in this image there is a group of people standing and smiling. in the floor. in the background we can see there is a door and we can see [SEP]\n",
      "samp: [CLS] in this image there is a group of people. in the wall and smiling. in the right side we can see there is a door and we can see a door and we can see a door and\n",
      "lr con   : 1.2962216624685136e-10\n",
      "lr bert  : 1.7100755667506296e-08\n",
      "lr cri   : 5.622166246851385e-05\n",
      "lr others: 4.544584382871536e-07\n",
      "Train epoch = 0.07556675062972293, loss = 30.46312141418457, policy = 0.16850243508815765, entropy_loss = -0.00256468472070992, gae = 29.07002830505371, kl_div = 0.07446791976690292, reward = 5.6347808837890625, ord = 7.0906853675842285, repeat = -3.893613338470459, length = -0.12796129286289215, adv = 1.4028122425079346, rougeL = 1.3128185272216797, cider = 0.2144806832075119, clip = 0.40090471506118774, crf = 0.39290812611579895, ce = 0.7597795128822327, unr = 2.5656700134277344, ber = 5.6468610763549805\n",
      "refe: [CLS] in this image we can see cars on the road. in the background there are trees and we can see a tunnel. [SEP]\n",
      "hypo: [CLS] in this image we can see vehicles on the road. in the road. on the right side there is a road. on the right side there are trees. [SEP]\n",
      "samp: [CLS] in this image we can see vehicles on the road. in the road. vehicles on the right side there is a road. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 11:00:56,607] Trial 26 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.1357152602854982\n",
      "clip_grad_threshold gradient norm: 1.0594475408890578\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.4386093123793353\n",
      "unr_coef: 2.739815349556677\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.5055980613454999\n",
      "ce_coef: 0.19614209393572485\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 3.4769014468942947\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_110109.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5a708e203c435989e9188ff44f2e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 12.514527320861816, policy = 2.826612011119778e-08, entropy_loss = -0.0029226476326584816, gae = 11.633426666259766, kl_div = 0.08538975566625595, reward = 4.205513954162598, ord = 6.977604866027832, repeat = -4.260998249053955, length = -0.12851613759994507, adv = 1.0244969129562378, rougeL = 1.245599389076233, cider = 0.18985708057880402, clip = 0.4071747362613678, crf = 0.39588090777397156, ce = 0.40275201201438904, unr = 1.6174238920211792, ber = 5.673745632171631\n",
      "refe: [CLS] in this image i can see a group of people sitting on chair there are few books, glasses, mobile, pen on a table at the back ground i can see door, flag, frame on a wall. [SEP]\n",
      "hypo: [CLS] in this picture we can see group of people sitting on a chair. there is a table there are chairs. on the table on the table, there is a table. [SEP]\n",
      "samp: [CLS] in this picture we can see group of people who is a chair. all of them there are sitting on the table, there is a table, there are placed on the left side of the books. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 11:01:27,702] Trial 27 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.1554453349734946\n",
      "clip_grad_threshold gradient norm: 1.9823927451532692\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.027776681198299\n",
      "unr_coef: 3.4443943186301844\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.14993794592498969\n",
      "ce_coef: 0.5661581800497767\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 2.7280296995306204\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_110140.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5655570816f84695b16dd39bfc15cbaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 9.676584243774414, policy = 4.915846840702898e-09, entropy_loss = -0.0026712759863585234, gae = 8.465039253234863, kl_div = 0.08301959186792374, reward = 4.558073997497559, ord = 7.102591514587402, repeat = -4.504880905151367, length = -0.05335668474435806, adv = 0.7742464542388916, rougeL = 1.2247016429901123, cider = 0.33812880516052246, clip = 0.4062303900718689, crf = 0.09439268708229065, ce = 1.03680419921875, unr = 2.0137197971343994, ber = 5.686710357666016\n",
      "refe: [CLS] this looks like a building with a window and a door. i think this is a spire. these are the trees with branches and leaves. here is a grass. this looks like a bench, which is under the tree. i think this is a pathway. [SEP]\n",
      "hypo: [CLS] in this picture we can see a building with windows, trees, we can see the background we can see the grass. at the sky. at the sky. at the sky. [SEP]\n",
      "samp: [CLS] in this picture we can see the ground with windows, we can surrounded here we can see the sky. at the background there are trees. at the sky. at the top of the top there is a [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 9.595046043395996, policy = 0.08595853298902512, entropy_loss = -0.002696518786251545, gae = 8.20516586303711, kl_div = 0.08503960818052292, reward = 4.539287090301514, ord = 7.006449222564697, repeat = -4.418099403381348, length = -0.07203026860952377, adv = 0.7681979537010193, rougeL = 1.2251050472259521, cider = 0.26087647676467896, clip = 0.4074637293815613, crf = 0.10759687423706055, ce = 1.1139814853668213, unr = 2.0229673385620117, ber = 5.659049034118652\n",
      "refe: [CLS] in this image i can see a stage with four people. i can see grills, metal constructions, speakers, papers all over, lights, and a keyboard on the stage. i can see a crew of people at the top of the image. in the bottom left corner i can see a person holding a camera. the background is dark. [SEP]\n",
      "hypo: [CLS] in this image there is a person standing. in the stage. on the stage. i can see a musical instruments we can see a musical instruments. [SEP]\n",
      "samp: [CLS] as we can see the image there is a musical instruments. in the stage and a musical instruments, lights. there is a musical instruments. [SEP]. [SEP] dais. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 11:04:08,761] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.11353607771254716\n",
      "clip_grad_threshold gradient norm: 1.068950902206263\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 0.6112620040701535\n",
      "unr_coef: 0.576216429709939\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.6037425045949907\n",
      "ce_coef: 0.46832413196439326\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.450275189867991\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_110421.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1f638e47b14d0b8c0d35aa909274df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 8.756270408630371, policy = 2.0277868273410604e-08, entropy_loss = -0.0026594679802656174, gae = 7.428221225738525, kl_div = 0.08402448147535324, reward = 3.045229434967041, ord = 7.081857204437256, repeat = -4.373414993286133, length = -0.019139494746923447, adv = 0.5930507779121399, rougeL = 1.2583959102630615, cider = 0.28409573435783386, clip = 0.40795400738716125, crf = 0.36403101682662964, ce = 0.8826526999473572, unr = 0.3559267818927765, ber = 5.69130802154541\n",
      "refe: [CLS] this image consists of a boat in which there are many people. at the bottom, there are two men walking. and there is a grass. to the right, there is water. at the top, there are clouds in the sky. [SEP]\n",
      "hypo: [CLS] this is a black and white image. here we can see there is a boat there is a boat. in the ground. [SEP]\n",
      "samp: [CLS] this is a black and white image. here we can see there is a boat. at the ground. in the background i can see the background there is sky. [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 10.600353240966797, policy = 0.26435765624046326, entropy_loss = -0.002579939318820834, gae = 8.818079948425293, kl_div = 0.0833883211016655, reward = 3.431763172149658, ord = 7.067942142486572, repeat = -3.965200662612915, length = -0.02377159707248211, adv = 0.6644269227981567, rougeL = 1.2640308141708374, cider = 0.26067692041397095, clip = 0.4084061086177826, crf = 0.5214360952377319, ce = 0.9156706929206848, unr = 0.35279327630996704, ber = 5.660431385040283\n",
      "refe: [CLS] this is a black and white image where we can see a person holding a sheep and in the background there are metal rods, walls and a few other objects. [SEP]\n",
      "hypo: [CLS] in this image i can see a person on the image there is sitting on the floor and there is holding trouser. [SEP] laying on it. [SEP]. [SEP]\n",
      "samp: [CLS] in this picture we can see a person on the image. on the middle beside him there is holding an object and trouser. [SEP] trouser. on it. [SEP]\n",
      "lr con   : 1.2962216624685136e-10\n",
      "lr bert  : 1.7100755667506296e-08\n",
      "lr cri   : 5.622166246851385e-05\n",
      "lr others: 4.544584382871536e-07\n",
      "Train epoch = 0.07556675062972293, loss = 11.556927680969238, policy = 0.4214022755622864, entropy_loss = -0.0025166268460452557, gae = 9.467446327209473, kl_div = 0.08530236035585403, reward = 3.6266117095947266, ord = 7.025115489959717, repeat = -3.7311370372772217, length = -0.02781059965491295, adv = 0.6932035088539124, rougeL = 1.2741347551345825, cider = 0.22531358897686005, clip = 0.4062880873680115, crf = 0.637433648109436, ce = 0.947858989238739, unr = 0.3604438900947571, ber = 5.638543128967285\n",
      "refe: [CLS] in this image i can see the group of people. in - front of these people i can see the railing. i can see the tower and the black background. [SEP]\n",
      "hypo: [CLS] in this image, we can see group of people are different color dresses. [SEP]\n",
      "samp: [CLS] in this image i can see a group of people standing on the background of the sky. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 11:10:28,409] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.18481333008670903\n",
      "clip_grad_threshold gradient norm: 2.6060318726855223\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.862670859983717\n",
      "unr_coef: 4.13106052654787\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.3594928448318116\n",
      "ce_coef: 0.2762319264154993\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 1.959900602633558\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_111040.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31301b33afe14c24b96973fa6b451894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 8.374163627624512, policy = 7.373770039009742e-09, entropy_loss = -0.002817573957145214, gae = 7.392662048339844, kl_div = 0.07902466505765915, reward = 4.782369136810303, ord = 6.891993999481201, repeat = -4.444203853607178, length = -0.12540727853775024, adv = 1.032423734664917, rougeL = 1.2193523645401, cider = 0.18089082837104797, clip = 0.4083992540836334, crf = 0.301032155752182, ce = 0.6042622923851013, unr = 2.459986448287964, ber = 5.63651704788208\n",
      "refe: [CLS] in this image, we can see a man walking and there is a dog running, there is a wall and there are two white color windows. [SEP]\n",
      "hypo: [CLS] this is a black and white image. in this image, there is a woman is a dog and there is a dog, we can also we can also see the road. [SEP]\n",
      "samp: [CLS] in this picture we can see a person in this image, we can see a person holding a dog on the right side of the road. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 11:10:59,049] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.22912142782580353\n",
      "clip_grad_threshold gradient norm: 1.3876065120614585\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 4.056965228035954\n",
      "unr_coef: 4.608520555421438\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.2509778806680196\n",
      "ce_coef: 0.7585730592728784\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 3.8653395229187644\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_111111.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ed113e61434a619c87337e806dfaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 16.057344436645508, policy = 2.457923420351449e-09, entropy_loss = -0.0028464272618293762, gae = 14.245748519897461, kl_div = 0.07962779700756073, reward = 4.795183181762695, ord = 6.943578243255615, repeat = -4.747586727142334, length = -0.14894545078277588, adv = 1.0664900541305542, rougeL = 1.1919565200805664, cider = 0.26756253838539124, clip = 0.39572086930274963, crf = 0.1915992945432663, ce = 1.5432161092758179, unr = 2.7481374740600586, ber = 5.647106170654297\n",
      "refe: [CLS] as we can see in the image there are trees, few people here and there and face mask. [SEP]\n",
      "hypo: [CLS] in the center of the image we can see the ground and in the background there is blurred. [SEP]\n",
      "samp: [CLS] in the image there is a group of the center of the foreground of the right side of the background there is a tree and there is a person standing. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 11:11:29,056] Trial 31 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.16943730358081638\n",
      "clip_grad_threshold gradient norm: 1.2646875233813841\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.426591349198133\n",
      "unr_coef: 3.686256249480955\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.1643744743438478\n",
      "ce_coef: 0.6031625060299923\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 3.9022001402387274\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_111141.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5ff62db2bd4f19aa02167edb35038b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 20.739648818969727, policy = -3.010956106663798e-08, entropy_loss = -0.0026607615873217583, gae = 19.3265438079834, kl_div = 0.08033392578363419, reward = 4.9420905113220215, ord = 7.032962799072266, repeat = -4.193972110748291, length = -0.14179779589176178, adv = 1.368121862411499, rougeL = 1.2076588869094849, cider = 0.2262042611837387, clip = 0.40243294835090637, crf = 0.12665106356143951, ce = 1.2087785005569458, unr = 2.2448976039886475, ber = 5.645148754119873\n",
      "refe: [CLS] this is a vending machine and there are some food items in this machine and here is a chocolate and this is a cake and there are some items all over the machine. here is the place where we have to insert our currency and here is the place we have to collect your selected food item in the machine. the machine is placed on the floor, beside the machine there is a wall. behind this machine a window is located. [SEP]\n",
      "hypo: [CLS] in this image, we can see a box. there are placed on the background there is a price background there are some text. [SEP]\n",
      "samp: [CLS] this picture consists of the center of the foreground there are placed on the background there is a price background there are some text. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 11:13:27,347] Trial 32 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.20693504429250556\n",
      "clip_grad_threshold gradient norm: 1.6272655955250306\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 4.554638051033333\n",
      "unr_coef: 4.123453259475257\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.04786731182479584\n",
      "ce_coef: 0.48074433843120523\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 3.22822234793267\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_111339.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804c83deac374c6c98746c7d138e2814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 16.339046478271484, policy = 1.8895287112741244e-08, entropy_loss = -0.002663480583578348, gae = 15.247990608215332, kl_div = 0.07969143241643906, reward = 5.2846999168396, ord = 7.1031084060668945, repeat = -4.145054340362549, length = -0.19722925126552582, adv = 1.2222106456756592, rougeL = 1.2382004261016846, cider = 0.2578347325325012, clip = 0.4036270081996918, crf = 0.03610667586326599, ce = 0.9779196977615356, unr = 2.5238754749298096, ber = 5.66790246963501\n",
      "refe: [CLS] in this image i can see few swans. they are in white, black and red color. [SEP]\n",
      "hypo: [CLS] in this image we can see water. [SEP]\n",
      "samp: [CLS] in this image we can see water. [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 16.316919326782227, policy = 0.0923299491405487, entropy_loss = -0.002684127539396286, gae = 15.120084762573242, kl_div = 0.08361737430095673, reward = 5.303963661193848, ord = 7.051790237426758, repeat = -4.072266101837158, length = -0.19093158841133118, adv = 1.2266027927398682, rougeL = 1.2643942832946777, cider = 0.2062651813030243, clip = 0.40323787927627563, crf = 0.03793160989880562, ce = 0.9856386780738831, unr = 2.5153708457946777, ber = 5.6559600830078125\n",
      "refe: [CLS] in this image there is a stage with hut in - front of that there are so many people sitting on the mat, also there is a tree, behind the stage there is a mountain. [SEP]\n",
      "hypo: [CLS] in this image there is a group of people standing. on the benches. in the image there are trees. there are trees. there are trees. in the sky. in the sky. [SEP]\n",
      "samp: [CLS] in this image there is a group of people standing. in the chairs and the chairs and there are trees. there are trees. [SEP] there are trees. [SEP] are lights. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 11:16:08,891] Trial 33 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.1350082506155736\n",
      "clip_grad_threshold gradient norm: 0.8848330440648038\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.6926369541089947\n",
      "unr_coef: 4.623101112741046\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.26651768342367094\n",
      "ce_coef: 0.39142746733749384\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.534116253874471\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_111621.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03968435a8dd4ec48162857a0fb830cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 20.922643661499023, policy = -9.831693681405795e-09, entropy_loss = -0.0026241843588650227, gae = 19.8727970123291, kl_div = 0.07614245265722275, reward = 5.9218292236328125, ord = 7.0961809158325195, repeat = -3.9014077186584473, length = -0.14510519802570343, adv = 1.0399993658065796, rougeL = 1.243515968322754, cider = 0.2824685871601105, clip = 0.40539395809173584, crf = 0.19359271228313446, ce = 0.7827354073524475, unr = 2.8721609115600586, ber = 5.690556049346924\n",
      "refe: [CLS] here we can see bud, stem and leaves. background it is blur. [SEP]\n",
      "hypo: [CLS] in this picture of the foreground of the background we can see the blurry. [SEP]\n",
      "samp: [CLS] in this image i can see a pink colour leaves and we can see a blurry. [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 21.62171745300293, policy = 0.053580932319164276, entropy_loss = -0.0024985596537590027, gae = 20.40749740600586, kl_div = 0.08000442385673523, reward = 5.976742267608643, ord = 7.09416389465332, repeat = -3.777820587158203, length = -0.19421684741973877, adv = 1.0513598918914795, rougeL = 1.2902189493179321, cider = 0.2610733211040497, clip = 0.40564534068107605, crf = 0.29360276460647583, ce = 0.789530873298645, unr = 2.8546152114868164, ber = 5.672619819641113\n",
      "refe: [CLS] this is grass and there are trees. here we can see a wall. in the background there is sky. [SEP]\n",
      "hypo: [CLS] in this image we can see a building. in front of the sky. in the background we can see the sky. [SEP]\n",
      "samp: [CLS] in this image we can see trees. in front of the front of the background we can see the sky. [SEP]\n",
      "lr con   : 1.2962216624685136e-10\n",
      "lr bert  : 1.7100755667506296e-08\n",
      "lr cri   : 5.622166246851385e-05\n",
      "lr others: 4.544584382871536e-07\n",
      "Train epoch = 0.07556675062972293, loss = 21.889148712158203, policy = 0.09367907792329788, entropy_loss = -0.00245428504422307, gae = 20.63724136352539, kl_div = 0.08234131336212158, reward = 6.065066337585449, ord = 7.073577404022217, repeat = -3.7233424186706543, length = -0.19793064892292023, adv = 1.0632083415985107, rougeL = 1.3000105619430542, cider = 0.25556546449661255, clip = 0.40487632155418396, crf = 0.28431063890457153, ce = 0.7940286993980408, unr = 2.912761926651001, ber = 5.664387226104736\n",
      "refe: [CLS] in this image we can see clowns. in the background there is a shed. on the left we can see a tree. [SEP]\n",
      "hypo: [CLS] in this image i can see few people who are standing. in the background there are trees. [SEP]\n",
      "samp: [CLS] in this image i can see few people are standing. behind them there is wearing spectacles. [SEP]. [SEP]\n",
      "lr con   : 1.6307304785894207e-10\n",
      "lr bert  : 2.1513853904282117e-08\n",
      "lr cri   : 7.073047858942065e-05\n",
      "lr others: 5.717380352644836e-07\n",
      "Train epoch = 0.11335012594458438, loss = 21.74222183227539, policy = 0.08790799230337143, entropy_loss = -0.0024664620868861675, gae = 20.484516143798828, kl_div = 0.0838993713259697, reward = 6.070415019989014, ord = 7.035580635070801, repeat = -3.689298152923584, length = -0.19557404518127441, adv = 1.0558161735534668, rougeL = 1.2984641790390015, cider = 0.23423591256141663, clip = 0.4054722189903259, crf = 0.28419917821884155, ce = 0.8041626811027527, unr = 2.9197068214416504, ber = 5.650738716125488\n",
      "refe: [CLS] this image contains a poster having painting of few persons and some text on it. on poster there is painting of a woman carrying a baby in her arms and a woman is writing on a paper with a pen are on it. [SEP]\n",
      "hypo: [CLS] in this image we can see a book. on the bottom of people. [SEP]\n",
      "samp: [CLS] in this image we can see a book with some text on the bottom of people. [SEP]\n",
      "lr con   : 1.561041141897565e-10\n",
      "lr bert  : 2.0594458438287153e-08\n",
      "lr cri   : 6.770780856423173e-05\n",
      "lr others: 5.473047858942065e-07\n",
      "Train epoch = 0.15113350125944586, loss = 23.545625686645508, policy = 0.08101694285869598, entropy_loss = -0.0023800877388566732, gae = 22.265241622924805, kl_div = 0.0822971761226654, reward = 6.404576301574707, ord = 7.03578519821167, repeat = -3.4184374809265137, length = -0.2018858790397644, adv = 1.109632134437561, rougeL = 1.3245532512664795, cider = 0.2185901552438736, clip = 0.4044649004936218, crf = 0.3132342994213104, ce = 0.8062165975570679, unr = 2.98911452293396, ber = 5.651297569274902\n",
      "refe: [CLS] in this image we can see a woman standing at a desk with laptop. in the background there is wall and door. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman wearing black color and talking. there is a mic. [SEP]\n",
      "samp: [CLS] in the image we can see a person wearing black and she front of this is a woman is a woman is a projector. there is a woman is a podium. [SEP]. [SEP]\n",
      "lr con   : 1.4913518052057094e-10\n",
      "lr bert  : 1.9675062972292192e-08\n",
      "lr cri   : 6.468513853904282e-05\n",
      "lr others: 5.228715365239295e-07\n",
      "Train epoch = 0.1889168765743073, loss = 24.81742286682129, policy = 0.09014617651700974, entropy_loss = -0.0023174164816737175, gae = 23.507108688354492, kl_div = 0.0818190649151802, reward = 6.626793384552002, ord = 7.040269374847412, repeat = -3.2473268508911133, length = -0.20862221717834473, adv = 1.1411206722259521, rougeL = 1.3385158777236938, cider = 0.21595753729343414, clip = 0.40441399812698364, crf = 0.33264046907424927, ce = 0.8080244660377502, unr = 3.042473077774048, ber = 5.648310661315918\n",
      "refe: [CLS] in the picture i can see a girl standing on the wooden table and she is holding a piece of paper in her hands. there is a man on the left side is wearing a shirt and he is looking at the girl. i can see a woman and looks like she is speaking. in the background, i can see three persons and there is a smile on their faces. i can see a plant on the right side. i can see another wooden table on the left side.\n",
      "hypo: [CLS] in this image we can see some people standing in front of people standing on the person is a woman there are standing. there is a woman standing on the background there is standing. [SEP]\n",
      "samp: [CLS] in this image i can see few people standing in front of this image, they are two persons standing. on the back there is a table there are two persons sitting on the front of this image looks like a chair. [SEP]\n",
      "lr con   : 1.4216624685138537e-10\n",
      "lr bert  : 1.8755667506297228e-08\n",
      "lr cri   : 6.16624685138539e-05\n",
      "lr others: 4.984382871536523e-07\n",
      "Train epoch = 0.22670025188916876, loss = 25.669065475463867, policy = 0.10325684398412704, entropy_loss = -0.002272252459079027, gae = 24.3406925201416, kl_div = 0.0814032182097435, reward = 6.798707008361816, ord = 7.049404144287109, repeat = -3.123764991760254, length = -0.20485849678516388, adv = 1.1630650758743286, rougeL = 1.3503570556640625, cider = 0.2052820771932602, clip = 0.40386369824409485, crf = 0.342705637216568, ce = 0.8032785654067993, unr = 3.077927350997925, ber = 5.647779941558838\n",
      "refe: [CLS] here in this picture we can see a group of people standing over a place and some of them are holding placards and we can see some of them are wearing goggles and spectacles and beside them we can see stores and buildings with number of windows present. [SEP]\n",
      "hypo: [CLS] in this image we can see a group of people standing on the road. in their hands and holding a building. [SEP] we can see building. [SEP]\n",
      "samp: [CLS] in this picture we can see a group of people standing on the road. in their hands, there is holding placards. i can see buildings in the road. [SEP]\n",
      "lr con   : 1.3519731318219982e-10\n",
      "lr bert  : 1.7836272040302267e-08\n",
      "lr cri   : 5.863979848866499e-05\n",
      "lr others: 4.740050377833753e-07\n",
      "Train epoch = 0.26448362720403024, loss = 25.30518341064453, policy = 0.151052787899971, entropy_loss = -0.0022739374544471502, gae = 23.936506271362305, kl_div = 0.08148728311061859, reward = 6.764161586761475, ord = 7.04971170425415, repeat = -3.1654212474823, length = -0.2045465111732483, adv = 1.1453560590744019, rougeL = 1.3466486930847168, cider = 0.21107803285121918, clip = 0.40375658869743347, crf = 0.33389198780059814, ce = 0.8045194745063782, unr = 3.0844168663024902, ber = 5.649126052856445\n",
      "refe: [CLS] in the picture we can see a person holding a dog with a belt on around its neck. [SEP]\n",
      "hypo: [CLS] in this image we can see a man in this looks pam couch. [SEP] in his hand. [SEP]\n",
      "samp: [CLS] in this image i can see a man in this looks pam couch. [SEP] in his hands. in his hands. [SEP]\n",
      "lr con   : 1.2822837951301427e-10\n",
      "lr bert  : 1.6916876574307306e-08\n",
      "lr cri   : 5.561712846347607e-05\n",
      "lr others: 4.495717884130982e-07\n",
      "Train epoch = 0.3022670025188917, loss = 25.212675094604492, policy = 0.21244078874588013, entropy_loss = -0.0022797458805143833, gae = 23.795673370361328, kl_div = 0.08181094378232956, reward = 6.784111976623535, ord = 7.040557384490967, repeat = -3.1529037952423096, length = -0.20364457368850708, adv = 1.1385935544967651, rougeL = 1.3404620885849, cider = 0.20995166897773743, clip = 0.4035383462905884, crf = 0.31969115138053894, ce = 0.805340588092804, unr = 3.100102424621582, ber = 5.649660587310791\n",
      "refe: [CLS] in this image i can see a man standing and holding a microphone and a paper in hands. in the background i can see a screen. [SEP]\n",
      "hypo: [CLS] in this image i can see a man standing and holding a man standing. [SEP] speaking. in the background. [SEP] blazer. [SEP]\n",
      "samp: [CLS] in this image i can see a man standing and holding a man standing. [SEP] in his hand. [SEP] blazer. [SEP] blazer. [SEP]. [SEP]\n",
      "lr con   : 1.2125944584382872e-10\n",
      "lr bert  : 1.5997481108312342e-08\n",
      "lr cri   : 5.2594458438287154e-05\n",
      "lr others: 4.2513853904282117e-07\n",
      "Train epoch = 0.34005037783375314, loss = 25.337446212768555, policy = 0.2800060510635376, entropy_loss = -0.0022810392547398806, gae = 23.85274887084961, kl_div = 0.08182986825704575, reward = 6.823516845703125, ord = 7.040034294128418, repeat = -3.1266815662384033, length = -0.20437213778495789, adv = 1.135641098022461, rougeL = 1.3378421068191528, cider = 0.20642182230949402, clip = 0.4034392535686493, crf = 0.3171570599079132, ce = 0.8079875707626343, unr = 3.1145355701446533, ber = 5.650453090667725\n",
      "refe: [CLS] in this image we can see a bird on a wood log. at the bottom of the image we can see water. at the top of the image we can see some plants. [SEP]\n",
      "hypo: [CLS] in this image i can see a bird on the branch and a bird. [SEP]\n",
      "samp: [CLS] in this image i can see a bird on it. in the image. [SEP]\n",
      "lr con   : 1.1429051217464315e-10\n",
      "lr bert  : 1.507808564231738e-08\n",
      "lr cri   : 4.957178841309823e-05\n",
      "lr others: 4.0070528967254406e-07\n",
      "Train epoch = 0.3778337531486146, loss = 25.50109100341797, policy = 0.26048189401626587, entropy_loss = -0.002250803168863058, gae = 24.031612396240234, kl_div = 0.08164642751216888, reward = 6.8714518547058105, ord = 7.048540115356445, repeat = -3.0970146656036377, length = -0.20410363376140594, adv = 1.1344999074935913, rougeL = 1.343817949295044, cider = 0.20760022103786469, clip = 0.40347445011138916, crf = 0.32496803998947144, ce = 0.8046310544013977, unr = 3.1240298748016357, ber = 5.652068138122559\n",
      "refe: [CLS] in this image there are four men sitting on a rock, at the background of the image there is a rock, there is a painting on the rock. [SEP]\n",
      "hypo: [CLS] in this image i can see group of people sitting on the wall. in the background. in the wall. [SEP]\n",
      "samp: [CLS] in this image i can see four people are sitting on the wall, there is a floor. [SEP]. [SEP]\n",
      "lr con   : 1.073215785054576e-10\n",
      "lr bert  : 1.4158690176322418e-08\n",
      "lr cri   : 4.654911838790932e-05\n",
      "lr others: 3.76272040302267e-07\n",
      "Train epoch = 0.4156171284634761, loss = 25.51402473449707, policy = 0.24290123581886292, entropy_loss = -0.0022348621860146523, gae = 24.049840927124023, kl_div = 0.08143243193626404, reward = 6.894338130950928, ord = 7.050291061401367, repeat = -3.0764639377593994, length = -0.20649681985378265, adv = 1.1291837692260742, rougeL = 1.347916603088379, cider = 0.20790812373161316, clip = 0.4032681882381439, crf = 0.3345164954662323, ce = 0.8075719475746155, unr = 3.1270079612731934, ber = 5.652040004730225\n",
      "refe: [CLS] in this picture there is a leg on the left side of the image. [SEP]\n",
      "hypo: [CLS] in this image we can see a human legs of a person feet shoes. [SEP]\n",
      "samp: [CLS] in this image i can see a human legs of a bag with wet in the path. [SEP]\n",
      "lr con   : 1.0035264483627203e-10\n",
      "lr bert  : 1.3239294710327456e-08\n",
      "lr cri   : 4.35264483627204e-05\n",
      "lr others: 3.518387909319899e-07\n",
      "Train epoch = 0.4534005037783375, loss = 25.14134407043457, policy = 0.2422916293144226, entropy_loss = -0.002238295041024685, gae = 23.683109283447266, kl_div = 0.08166717737913132, reward = 6.853085041046143, ord = 7.04176139831543, repeat = -3.105137586593628, length = -0.2048136442899704, adv = 1.1117048263549805, rougeL = 1.343018889427185, cider = 0.20613224804401398, clip = 0.4034065008163452, crf = 0.32977667450904846, ce = 0.8067396283149719, unr = 3.1212756633758545, ber = 5.651253700256348\n",
      "refe: [CLS] in this image i can see table with fish and fish pieces beside that there is a person, fan and other things. [SEP]\n",
      "hypo: [CLS] in this image, we can see few birds candies and some objects on the middle of people. [SEP]\n",
      "samp: [CLS] in this image, we can see few birds candies and there are some objects on the middle of people. [SEP]\n",
      "lr con   : 9.338371116708649e-11\n",
      "lr bert  : 1.2319899244332495e-08\n",
      "lr cri   : 4.0503778337531486e-05\n",
      "lr others: 3.2740554156171283e-07\n",
      "Train epoch = 0.491183879093199, loss = 25.366270065307617, policy = 0.228938490152359, entropy_loss = -0.0022179114166647196, gae = 23.918964385986328, kl_div = 0.08165492862462997, reward = 6.916113376617432, ord = 7.050889492034912, repeat = -3.0622901916503906, length = -0.2038772851228714, adv = 1.1144170761108398, rougeL = 1.345741629600525, cider = 0.2072538137435913, clip = 0.40341752767562866, crf = 0.33507171273231506, ce = 0.8038606643676758, unr = 3.131391763687134, ber = 5.652004718780518\n",
      "refe: [CLS] this picture shows a man standing and playing the guitar and we see a microphone in front of him [SEP]\n",
      "hypo: [CLS] in this image we can see a man standing and a man standing. [SEP]. [SEP]\n",
      "samp: [CLS] in this image i can see a person is standing. in his hands. [SEP] standing. [SEP]\n",
      "lr con   : 8.641477749790091e-11\n",
      "lr bert  : 1.140050377833753e-08\n",
      "lr cri   : 3.7481108312342564e-05\n",
      "lr others: 3.029722921914357e-07\n",
      "Train epoch = 0.5289672544080605, loss = 25.242528915405273, policy = 0.21749651432037354, entropy_loss = -0.002204152289777994, gae = 23.798189163208008, kl_div = 0.08174080401659012, reward = 6.916450023651123, ord = 7.052927494049072, repeat = -3.0638484954833984, length = -0.20590485632419586, adv = 1.105363368988037, rougeL = 1.3471213579177856, cider = 0.20725880563259125, clip = 0.4032692015171051, crf = 0.3417089283466339, ce = 0.8055994510650635, unr = 3.133275270462036, ber = 5.651605129241943\n",
      "refe: [CLS] in the image there are few musicians. the man to the left corner and right corner are playing guitars. in the image there are drums, drum stands, microphones and spotlights. [SEP]\n",
      "hypo: [CLS] in this image we can see a group of people are playing the stage. on the background there is a guitar and playing guitar. [SEP]\n",
      "samp: [CLS] in this image i can see a group of this guitars at the stage standing and playing musical instruments and playing guitar. [SEP] playing the right side. [SEP]\n",
      "lr con   : 7.944584382871536e-11\n",
      "lr bert  : 1.048110831234257e-08\n",
      "lr cri   : 3.4458438287153655e-05\n",
      "lr others: 2.785390428211587e-07\n",
      "Train epoch = 0.5667506297229219, loss = 25.273357391357422, policy = 0.20687799155712128, entropy_loss = -0.002189492341130972, gae = 23.832853317260742, kl_div = 0.08160993456840515, reward = 6.93904447555542, ord = 7.057046413421631, repeat = -3.048316240310669, length = -0.2072254866361618, adv = 1.1009509563446045, rougeL = 1.3515522480010986, cider = 0.20605133473873138, clip = 0.4027978777885437, crf = 0.3476746082305908, ce = 0.8065308332443237, unr = 3.137540340423584, ber = 5.652060508728027\n",
      "refe: [CLS] in this image we can see one big blue wall and one red wooden window with glass. [SEP]\n",
      "hypo: [CLS] in this image we can see a window which is a window. [SEP]\n",
      "samp: [CLS] in this image i can see a window with window blind. [SEP]\n",
      "lr con   : 7.24769101595298e-11\n",
      "lr bert  : 9.561712846347607e-09\n",
      "lr cri   : 3.143576826196473e-05\n",
      "lr others: 2.541057934508816e-07\n",
      "Train epoch = 0.6045340050377834, loss = 25.127904891967773, policy = 0.19759540259838104, entropy_loss = -0.002180112525820732, gae = 23.690876007080078, kl_div = 0.08161406964063644, reward = 6.9264726638793945, ord = 7.058480262756348, repeat = -3.0596344470977783, length = -0.2072034329175949, adv = 1.090054988861084, rougeL = 1.3521798849105835, cider = 0.20438288152217865, clip = 0.40243420004844666, crf = 0.3527850806713104, ce = 0.8072161674499512, unr = 3.1348307132720947, ber = 5.65165376663208\n",
      "refe: [CLS] in this image in the left there are trees. there are few people on the ground. in the background there are buildings. on the road there are vehicles. there are plants and trees in the background. [SEP]\n",
      "hypo: [CLS] in this image we can see few people are trees, trees, we can see group of people, we can see a building. [SEP]. [SEP]\n",
      "samp: [CLS] in this image we can see few people are trees, poles, we can see group of trees, trees, trees, trees. we can see windows. [SEP]\n",
      "lr con   : 6.550797649034425e-11\n",
      "lr bert  : 8.642317380352645e-09\n",
      "lr cri   : 2.8413098236775818e-05\n",
      "lr others: 2.2967254408060454e-07\n",
      "Train epoch = 0.6423173803526449, loss = 24.851835250854492, policy = 0.20109394192695618, entropy_loss = -0.0021841826383024454, gae = 23.415027618408203, kl_div = 0.08169614523649216, reward = 6.890819072723389, ord = 7.059961318969727, repeat = -3.0895333290100098, length = -0.20605124533176422, adv = 1.0751593112945557, rougeL = 1.3507851362228394, cider = 0.2085036188364029, clip = 0.4025232493877411, crf = 0.34912922978401184, ce = 0.8070706725120544, unr = 3.1264429092407227, ber = 5.652831554412842\n",
      "refe: [CLS] in the left side it is a tree, in the middle it is water. in the right side it is a house. [SEP]\n",
      "hypo: [CLS] in this image we can see water, in the water, there is a water, trees. in the sky. [SEP]\n",
      "samp: [CLS] in this image we can see water, a lake. in the right side we can see the middle of trees. [SEP] we can see the image, we can see the background. [SEP]\n",
      "lr con   : 5.853904282115869e-11\n",
      "lr bert  : 7.722921914357682e-09\n",
      "lr cri   : 2.5390428211586902e-05\n",
      "lr others: 2.0523929471032745e-07\n",
      "Train epoch = 0.6801007556675063, loss = 24.714706420898438, policy = 0.21693141758441925, entropy_loss = -0.0021744973491877317, gae = 23.256635665893555, kl_div = 0.08167549222707748, reward = 6.884088039398193, ord = 7.061768531799316, repeat = -3.0931310653686523, length = -0.20688490569591522, adv = 1.0660874843597412, rougeL = 1.3526722192764282, cider = 0.20681655406951904, clip = 0.40251263976097107, crf = 0.3537657856941223, ce = 0.8078720569610596, unr = 3.1223361492156982, ber = 5.651941299438477\n",
      "refe: [CLS] in the foreground of the picture i can see two persons. there is a man on the right side is wearing a black color coat. i can see a woman on the left side is wearing a jacket and there is a smile on their face. in the background, i can see a few persons sitting on the chairs and i can see the balloon decoration on the wall. [SEP]\n",
      "hypo: [CLS] in this image we can see people, a woman and smiling and smiling and smiling. on the right side of the chairs. we can see the chairs. [SEP]\n",
      "samp: [CLS] in this picture we can see a man wore t shirt and smiling and smiling. in the right side. we can see the background we can see the background there are some lights. [SEP]\n",
      "lr con   : 5.157010915197313e-11\n",
      "lr bert  : 6.8035264483627206e-09\n",
      "lr cri   : 2.2367758186397984e-05\n",
      "lr others: 1.8080604534005037e-07\n",
      "Train epoch = 0.7178841309823678, loss = 24.698774337768555, policy = 0.20845334231853485, entropy_loss = -0.002164744073525071, gae = 23.246219635009766, kl_div = 0.08152971416711807, reward = 6.902327060699463, ord = 7.064830303192139, repeat = -3.079841375350952, length = -0.20677609741687775, adv = 1.0621925592422485, rougeL = 1.353918194770813, cider = 0.20641197264194489, clip = 0.40257686376571655, crf = 0.3572816550731659, ce = 0.8074549436569214, unr = 3.124114513397217, ber = 5.651833534240723\n",
      "refe: [CLS] a girl and three men are in the water. a person is wearing goggles. [SEP]\n",
      "hypo: [CLS] in this image we can see group of the water. [SEP]\n",
      "samp: [CLS] in this picture we can see group of the water. this image. [SEP]\n",
      "lr con   : 4.460117548278757e-11\n",
      "lr bert  : 5.884130982367758e-09\n",
      "lr cri   : 1.9345088161209068e-05\n",
      "lr others: 1.563727959697733e-07\n",
      "Train epoch = 0.7556675062972292, loss = 24.516319274902344, policy = 0.20754994451999664, entropy_loss = -0.00216250354424119, gae = 23.066896438598633, kl_div = 0.08149706572294235, reward = 6.8870439529418945, ord = 7.065212726593018, repeat = -3.0927071571350098, length = -0.2051183581352234, adv = 1.0522361993789673, rougeL = 1.3524556159973145, cider = 0.20844076573848724, clip = 0.4027171730995178, crf = 0.356582373380661, ce = 0.8059539198875427, unr = 3.119657039642334, ber = 5.651671886444092\n",
      "refe: [CLS] in this image, we can see a woman standing on the white floor and smiling. in the background, we can see the boards, lights, dark view and lights. [SEP]\n",
      "hypo: [CLS] in this image we can see a woman standing on the floor. in front of the floor. [SEP]\n",
      "samp: [CLS] in this image i can see a woman standing on the floor. in front of the ground. [SEP]. [SEP]\n",
      "lr con   : 3.7632241813602014e-11\n",
      "lr bert  : 4.964735516372796e-09\n",
      "lr cri   : 1.632241813602015e-05\n",
      "lr others: 1.3193954659949622e-07\n",
      "Train epoch = 0.7934508816120907, loss = 24.44419288635254, policy = 0.27334845066070557, entropy_loss = -0.002160007366910577, gae = 22.928939819335938, kl_div = 0.08137571811676025, reward = 6.875988960266113, ord = 7.06732702255249, repeat = -3.103914737701416, length = -0.20524954795837402, adv = 1.0435079336166382, rougeL = 1.3521556854248047, cider = 0.20987464487552643, clip = 0.40277981758117676, crf = 0.356774240732193, ce = 0.8059149980545044, unr = 3.1178269386291504, ber = 5.651992321014404\n",
      "refe: [CLS] in this image we can see a black color axe and some wooden pieces. [SEP]\n",
      "hypo: [CLS] in this image we can see a wooden object. in the ground. [SEP]\n",
      "samp: [CLS] in this image we can see a wooden object. in the ground. [SEP]\n",
      "lr con   : 3.066330814441645e-11\n",
      "lr bert  : 4.045340050377834e-09\n",
      "lr cri   : 1.3299748110831234e-05\n",
      "lr others: 1.0750629722921913e-07\n",
      "Train epoch = 0.8312342569269522, loss = 24.368745803833008, policy = 0.26593825221061707, entropy_loss = -0.002153073437511921, gae = 22.85797119140625, kl_div = 0.08127342909574509, reward = 6.878593444824219, ord = 7.066650867462158, repeat = -3.1004183292388916, length = -0.20577852427959442, adv = 1.03760826587677, rougeL = 1.3528660535812378, cider = 0.20884136855602264, clip = 0.4029034972190857, crf = 0.35968759655952454, ce = 0.8060281276702881, unr = 3.1181399822235107, ber = 5.652318477630615\n",
      "refe: [CLS] in this image, we can see some tomatoes are placed on the ground. [SEP]\n",
      "hypo: [CLS] in the foreground of this image. [SEP]\n",
      "samp: [CLS] in the foreground of this image chocolate decorative items. [SEP]\n",
      "lr con   : 2.3694374475230897e-11\n",
      "lr bert  : 3.1259445843828713e-09\n",
      "lr cri   : 1.0277078085642317e-05\n",
      "lr others: 8.307304785894206e-08\n",
      "Train epoch = 0.8690176322418136, loss = 24.262542724609375, policy = 0.29259124398231506, entropy_loss = -0.0021503453608602285, gae = 22.72479820251465, kl_div = 0.08124648034572601, reward = 6.8673787117004395, ord = 7.066423416137695, repeat = -3.111356019973755, length = -0.20562563836574554, adv = 1.0295277833938599, rougeL = 1.3512331247329712, cider = 0.2088424563407898, clip = 0.40283846855163574, crf = 0.3597582280635834, ce = 0.8062979578971863, unr = 3.1179380416870117, ber = 5.652125358581543\n",
      "refe: [CLS] in this image i can see a skeleton and some other things and behind there are some lights, poster and people. [SEP]\n",
      "hypo: [CLS] in this image we can see a toy. in the background we can also see few people. [SEP]\n",
      "samp: [CLS] in this image, we can see a foreground. i can see a floor. [SEP] poles. [SEP]\n",
      "lr con   : 1.6725440806045338e-11\n",
      "lr bert  : 2.206549118387909e-09\n",
      "lr cri   : 7.2544080604534e-06\n",
      "lr others: 5.863979848866498e-08\n",
      "Train epoch = 0.906801007556675, loss = 24.130826950073242, policy = 0.2866990268230438, entropy_loss = -0.0021490443032234907, gae = 22.598953247070312, kl_div = 0.08123622834682465, reward = 6.857879161834717, ord = 7.064896106719971, repeat = -3.11818265914917, length = -0.20551899075508118, adv = 1.022193431854248, rougeL = 1.3509976863861084, cider = 0.20842894911766052, clip = 0.40274474024772644, crf = 0.3597237169742584, ce = 0.806364893913269, unr = 3.116684675216675, ber = 5.65246057510376\n",
      "refe: [CLS] in the picture i can see people walking on the ground, i can see plants, boats floating on water, i can see light poles, water, trees and the blue color sky with clouds in the background. [SEP]\n",
      "hypo: [CLS] in this image we can see a few people standing and some boats. on the image there are trees and some trees. on the sky. [SEP]\n",
      "samp: [CLS] in this image i can see a group of people are boats, few people standing. i can see few persons are few people in the ground. [SEP] i can see water. [SEP]\n",
      "lr con   : 9.75650713685978e-12\n",
      "lr bert  : 1.287153652392947e-09\n",
      "lr cri   : 4.231738035264483e-06\n",
      "lr others: 3.4206549118387904e-08\n",
      "Train epoch = 0.9445843828715366, loss = 24.135656356811523, policy = 0.27942612767219543, entropy_loss = -0.0021415408700704575, gae = 22.608915328979492, kl_div = 0.08120578527450562, reward = 6.872445583343506, ord = 7.0672760009765625, repeat = -3.1088342666625977, length = -0.20511910319328308, adv = 1.0197442770004272, rougeL = 1.3531955480575562, cider = 0.20699504017829895, clip = 0.4027869403362274, crf = 0.36214959621429443, ce = 0.8061017394065857, unr = 3.119122266769409, ber = 5.653383255004883\n",
      "refe: [CLS] in this image there is an animal on the ground, there is an object truncated in the background of the image. [SEP]\n",
      "hypo: [CLS] in this image we can see an animal which is standing and the ground. [SEP]\n",
      "samp: [CLS] in this image i can see a dog which is standing on the ground. [SEP]\n",
      "lr con   : 2.787573467674223e-12\n",
      "lr bert  : 3.677581863979849e-10\n",
      "lr cri   : 1.2090680100755668e-06\n",
      "lr others: 9.773299748110832e-09\n",
      "Train epoch = 0.982367758186398, loss = 24.11431121826172, policy = 0.27215829491615295, entropy_loss = -0.0021356509532779455, gae = 22.592500686645508, kl_div = 0.08106851577758789, reward = 6.8812255859375, ord = 7.066797733306885, repeat = -3.1010172367095947, length = -0.2052232027053833, adv = 1.0165255069732666, rougeL = 1.3536685705184937, cider = 0.20790578424930573, clip = 0.40270647406578064, crf = 0.3646649420261383, ce = 0.8060542941093445, unr = 3.1206676959991455, ber = 5.653653144836426\n",
      "refe: [CLS] in the foreground of the picture there is a wooden rack, in the rack there are toys and text made of lego. in the background it is window. at the top it is wall painted white. [SEP]\n",
      "hypo: [CLS] in this image we can see cupboards on the floor. in the surface. [SEP]\n",
      "samp: [CLS] in this image i can see there is a wooden boxes and we can see a few other objects. [SEP]. [SEP]\n",
      "bsz 56 is not batch_size 128. skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:13:15,957] Trial 34 finished with value: 1.6198623180389404 and parameters: {'config.betas': 2, 'config.len_coef': 3.6926369541089947, 'config.unr_coef': 4.623101112741046, 'config.crf_coef': 0.26651768342367094, 'config.ce_coef': 0.39142746733749384, 'config.gae_coef': 4.534116253874471, 'config.clip_range': 0.1350082506155736, 'clip_grad_threshold': 0.8848330440648038}. Best is trial 20 with value: 1.7153098583221436.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, avg_reward = 1.6198623180389404\n",
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.1323792995951235\n",
      "clip_grad_threshold gradient norm: 0.6223265393253232\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.663448887676835\n",
      "unr_coef: 4.698754948997834\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.455115626256939\n",
      "ce_coef: 0.4092769989578617\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.583030917457745\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_121328.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6edc479ccc844a568f01d898451a6688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 27.55854606628418, policy = -6.759289572499938e-09, entropy_loss = -0.0028060362674295902, gae = 26.220678329467773, kl_div = 0.08058981597423553, reward = 5.4860382080078125, ord = 7.091447353363037, repeat = -4.2214884757995605, length = -0.1439095437526703, adv = 1.530139684677124, rougeL = 1.2444711923599243, cider = 0.32039082050323486, clip = 0.4054398536682129, crf = 0.38106751441955566, ce = 0.8790168166160583, unr = 2.75998854637146, ber = 5.68570613861084\n",
      "refe: [CLS] in this picture i can see few people are walking, behind there is a building with some glasses and some trees. [SEP]\n",
      "hypo: [CLS] this is a black and white image. here we can see a group of them are walking on the background we can see buildings, we can see the left side, we can see [SEP]\n",
      "samp: [CLS] in this image we can see a black where we can see a group of them are walking on the background we can see the image we can see the left side of the left side, we can see windows. [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 30.646780014038086, policy = 0.06808270514011383, entropy_loss = -0.0025905021466314793, gae = 29.121185302734375, kl_div = 0.07167207449674606, reward = 5.7170562744140625, ord = 7.065433025360107, repeat = -3.9129316806793213, length = -0.20700952410697937, adv = 1.5661232471466064, rougeL = 1.2936609983444214, cider = 0.27005401253700256, clip = 0.40142756700515747, crf = 0.5353723168373108, ce = 0.8530583381652832, unr = 2.7715649604797363, ber = 5.65742826461792\n",
      "refe: [CLS] in the picture i can see trees, plants and the grass. in the background i can see mountains and the sky. [SEP]\n",
      "hypo: [CLS] in this image there are trees, we can see the background i can see the background we can see the sky. [SEP]\n",
      "samp: [CLS] in this picture we can see grass on the background, we can see a group of the background there are clouds. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:16:38,276] Trial 35 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.1158984204042253\n",
      "clip_grad_threshold gradient norm: 0.8550050052956548\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.617282567718904\n",
      "unr_coef: 4.971372137671502\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.2710369656654432\n",
      "ce_coef: 0.3754575960859753\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.234157491055759\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_121650.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155f88aa9699419582d0bca19d38ff19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 14.537604331970215, policy = -1.8434425097524354e-09, entropy_loss = -0.002798589179292321, gae = 13.507203102111816, kl_div = 0.07841964066028595, reward = 5.364677429199219, ord = 6.9970598220825195, repeat = -4.458079814910889, length = -0.10116839408874512, adv = 0.8356547951698303, rougeL = 1.2168139219284058, cider = 0.23471428453922272, clip = 0.39732471108436584, crf = 0.2017139345407486, ce = 0.7530672550201416, unr = 2.926866054534912, ber = 5.689323902130127\n",
      "refe: [CLS] in this picture we can see three persons are standing and smiling in the front, in the background there is a wall, there are some boards on the wall, we can see lights and the ceiling at the top of the picture. [SEP]\n",
      "hypo: [CLS] in this image we can see three people are three people are standing and smiling and smiling. behind them there is a wall. [SEP]\n",
      "samp: [CLS] in this image there are three people standing and holding a woman standing. on their hands. in their faces. there is holding a wall. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:17:10,683] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.14935516080179717\n",
      "clip_grad_threshold gradient norm: 0.36172578116629595\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.257718518814527\n",
      "unr_coef: 4.54414038421698\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.35039471296616703\n",
      "ce_coef: 0.2238854361987274\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.977154579653185\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_121723.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8587413cc3914a659111463181469ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 16.41809844970703, policy = 3.4410927440831074e-08, entropy_loss = -0.002738147508352995, gae = 15.662614822387695, kl_div = 0.07874249666929245, reward = 5.179011821746826, ord = 7.044820785522461, repeat = -4.4578447341918945, length = -0.09936923533678055, adv = 0.7059504389762878, rougeL = 1.2139464616775513, cider = 0.2624586820602417, clip = 0.4083895683288574, crf = 0.24184854328632355, ce = 0.43763118982315063, unr = 2.6914050579071045, ber = 5.667481422424316\n",
      "refe: [CLS] this is an inside view of a room. here i can see a bed on which few pillows are placed. in the background there is a wall and pillar. on the right side there is a curtain to the window. beside the bed there is a table. there is a light and a switch board are attached to the wall. [SEP]\n",
      "hypo: [CLS] in this image, we can see a bed, we can see there is a bed. [SEP] pillows and there is a bed attached to the wall. there is a wall. [SEP]\n",
      "samp: [CLS] in this image, we can see the bed in the bed in the middle of the middle of the left side of the bottom there are placed on the background there is a wall. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:17:41,107] Trial 37 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.1318658640892292\n",
      "clip_grad_threshold gradient norm: 1.0602079515178684\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.920841267907446\n",
      "unr_coef: 1.085966489846857\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.09976453511125459\n",
      "ce_coef: 0.31538650609518704\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 3.6491748662392496\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_121753.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eccacbc21f1b4f1e968788d08789c594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 6.5276947021484375, policy = 1.3518579144999876e-08, entropy_loss = -0.0026311944238841534, gae = 5.757044315338135, kl_div = 0.08565118908882141, reward = 3.1756484508514404, ord = 6.973898887634277, repeat = -4.304507255554199, length = -0.1371014267206192, adv = 0.3878866136074066, rougeL = 1.251549243927002, cider = 0.22020719945430756, clip = 0.40449610352516174, crf = 0.06984767317771912, ce = 0.6177825927734375, unr = 0.6433582901954651, ber = 5.695178985595703\n",
      "refe: [CLS] this picture is clicked outside. in the foreground we can see a water body. in the center we can see the metal fence, trees and some objects and we can see the buildings and an architecture. in the background we can see the sky. [SEP]\n",
      "hypo: [CLS] in this image we can see the building in front of the right side of the background there are trees. [SEP] we can see the sky. [SEP]\n",
      "samp: [CLS] in this image i can see the building in front of the image in the right side of the middle of the background we can see the sky. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:18:11,895] Trial 38 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.10973950704280883\n",
      "clip_grad_threshold gradient norm: 1.1734997748588785\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.7294367462002382\n",
      "unr_coef: 2.2500687281851937\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.5516640415579774\n",
      "ce_coef: 0.5178754223780335\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 1.3985745050681921\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_121824.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8c8d01b45f4360a72cafe6ad6f4f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 5.670895099639893, policy = 3.8097812904425155e-08, entropy_loss = -0.0027791804168373346, gae = 4.129765510559082, kl_div = 0.08372048288583755, reward = 3.801076650619507, ord = 7.008514404296875, repeat = -4.43691349029541, length = -0.10219704359769821, adv = 1.0558524131774902, rougeL = 1.2231265306472778, cider = 0.214304581284523, clip = 0.40125617384910583, crf = 0.4049450755119324, ce = 1.0552431344985962, unr = 1.3316731452941895, ber = 5.666410446166992\n",
      "refe: [CLS] in this image there are few people, few objects on the tables, few lights attached to the roof and some objects in the shelf's. [SEP]\n",
      "hypo: [CLS] in this image we can see a group of people standing and some trouser. they are some food items, there are standing. [SEP]\n",
      "samp: [CLS] this picture shows we can see few persons standing and some people standing and some food items in the right side of the bottom there are some other objects. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:18:42,031] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.12484649453148948\n",
      "clip_grad_threshold gradient norm: 1.6878807800757412\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 0.1454493803981003\n",
      "unr_coef: 3.998425159430905\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.19678246155748882\n",
      "ce_coef: 0.599845412094421\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 0.19809613842763119\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_121854.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b5834879c14aa4b91d84507b73b077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 1.9961955547332764, policy = 2.9495080156038966e-08, entropy_loss = -0.0027266740798950195, gae = 0.49893268942832947, kl_div = 0.08217842876911163, reward = 5.068779945373535, ord = 7.027627468109131, repeat = -4.354129791259766, length = -0.006387998349964619, adv = 0.695933997631073, rougeL = 1.2499613761901855, cider = 0.2359037846326828, clip = 0.40913060307502747, crf = 0.15885719656944275, ce = 1.2589539289474487, unr = 2.4016706943511963, ber = 5.690423488616943\n",
      "refe: [CLS] in this image there are some persons standing in middle of this image and there is a building in the background. there is an object kept in the bottom of this image. [SEP]\n",
      "hypo: [CLS] in this image we can see a group of people standing and there are some objects. in front of the table. [SEP]\n",
      "samp: [CLS] in this image we can see a group of people standing and they are some objects. in front of the image. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:19:12,427] Trial 40 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.19421711270287173\n",
      "clip_grad_threshold gradient norm: 1.3599966349170662\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.9501538157333487\n",
      "unr_coef: 3.4098542045300655\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.22861108521579243\n",
      "ce_coef: 0.7424681734063875\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.718120957232741\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_121925.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbd24f6744d49abbbaae77ae4b7716a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 12.594260215759277, policy = -2.457923420351449e-09, entropy_loss = -0.0026797386817634106, gae = 10.813971519470215, kl_div = 0.08124026656150818, reward = 4.773780822753906, ord = 7.172998905181885, repeat = -4.3294358253479, length = -0.15770740807056427, adv = 0.38711002469062805, rougeL = 1.2455281019210815, cider = 0.3154909014701843, clip = 0.4082552492618561, crf = 0.1778978854417801, ce = 1.5238302946090698, unr = 2.087925434112549, ber = 5.67100715637207\n",
      "refe: [CLS] in this picture there is a man and a dog biting a bottle. in the background there is a building with windows. [SEP]\n",
      "hypo: [CLS] this is a black and white image. we can see a man sitting on a person standing. [SEP]\n",
      "samp: [CLS] this is a black and white image sitting on the center there is a person sitting on the right side of the left side of the path. [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 14.692537307739258, policy = 0.09029075503349304, entropy_loss = -0.002545356983318925, gae = 12.744303703308105, kl_div = 0.07276520133018494, reward = 5.084069728851318, ord = 7.064393043518066, repeat = -3.821681499481201, length = -0.20875166356563568, adv = 0.45183265209198, rougeL = 1.2925611734390259, cider = 0.23521003127098083, clip = 0.4030124843120575, crf = 0.2597833573818207, ce = 1.5279395580291748, unr = 2.050110101699829, ber = 5.657402992248535\n",
      "refe: [CLS] in this image there is a person having a smile on her face. around her there are wooden poles. on top of it there are oranges in plates. at the bottom of the image there is grass on the surface. [SEP]\n",
      "hypo: [CLS] in this image, we can see a woman is holding an umbrellas and in the background i can see a hand. [SEP]\n",
      "samp: [CLS] in this image we can see a woman wearing gloveslli bunch of the top of the background i can see a person. [SEP]\n",
      "lr con   : 1.2962216624685136e-10\n",
      "lr bert  : 1.7100755667506296e-08\n",
      "lr cri   : 5.622166246851385e-05\n",
      "lr others: 4.544584382871536e-07\n",
      "Train epoch = 0.07556675062972293, loss = 16.166593551635742, policy = 0.08030303567647934, entropy_loss = -0.00247186585329473, gae = 14.187151908874512, kl_div = 0.07088611274957657, reward = 5.422148704528809, ord = 7.044024467468262, repeat = -3.4474422931671143, length = -0.24788494408130646, adv = 0.5121290683746338, rougeL = 1.3149045705795288, cider = 0.20106537640094757, clip = 0.40263769030570984, crf = 0.2958563268184662, ce = 1.5348682403564453, unr = 2.0734517574310303, ber = 5.657020092010498\n",
      "refe: [CLS] in this image there is a machine. [SEP]\n",
      "hypo: [CLS] in this image we can see there is an object. [SEP]\n",
      "samp: [CLS] in this picture we can see a toy on the foreground of the background there is a bulb\n",
      "lr con   : 1.6307304785894207e-10\n",
      "lr bert  : 2.1513853904282117e-08\n",
      "lr cri   : 7.073047858942065e-05\n",
      "lr others: 5.717380352644836e-07\n",
      "Train epoch = 0.11335012594458438, loss = 16.532405853271484, policy = 0.07966691255569458, entropy_loss = -0.0024338564835488796, gae = 14.529396057128906, kl_div = 0.07021182775497437, reward = 5.51345157623291, ord = 7.056135654449463, repeat = -3.3777782917022705, length = -0.25555530190467834, adv = 0.5228410959243774, rougeL = 1.3276784420013428, cider = 0.18637952208518982, clip = 0.4020903706550598, crf = 0.3135231137275696, ce = 1.5420432090759277, unr = 2.0906500816345215, ber = 5.651418209075928\n",
      "refe: [CLS] in the image there is a person sitting on the footpath beside a garden and in front of the person there is a road and there are many trees around that person. [SEP]\n",
      "hypo: [CLS] in this is clicked outside. here we can see a bicycle. on the background there is a bench and beside him there are trees. beside him there is sky. [SEP]\n",
      "samp: [CLS] this image is clicked outside. at the right side of the bench. on the background there is a pole, we can also there is greenery and beside him there are buildings. [SEP]\n",
      "lr con   : 1.561041141897565e-10\n",
      "lr bert  : 2.0594458438287153e-08\n",
      "lr cri   : 6.770780856423173e-05\n",
      "lr others: 5.473047858942065e-07\n",
      "Train epoch = 0.15113350125944586, loss = 16.523822784423828, policy = 0.08060339093208313, entropy_loss = -0.002421151613816619, gae = 14.50600528717041, kl_div = 0.07055412977933884, reward = 5.537898063659668, ord = 7.0585832595825195, repeat = -3.37239670753479, length = -0.2556474804878235, adv = 0.5181299448013306, rougeL = 1.3349004983901978, cider = 0.18572500348091125, clip = 0.40247073769569397, crf = 0.32220664620399475, ce = 1.546875, unr = 2.1073596477508545, ber = 5.651717662811279\n",
      "refe: [CLS] in this image there are group of people sitting on the chair. on the table there is a glass, paper, pen, cup. at the back side there is a podium. [SEP]\n",
      "hypo: [CLS] in this image we can see some people sitting on the chairs. there is a table and a table. [SEP]\n",
      "samp: [CLS] this picture is taken in this is a group of the chairs. on the tables, there is a table. [SEP]\n",
      "lr con   : 1.4913518052057094e-10\n",
      "lr bert  : 1.9675062972292192e-08\n",
      "lr cri   : 6.468513853904282e-05\n",
      "lr others: 5.228715365239295e-07\n",
      "Train epoch = 0.1889168765743073, loss = 16.623533248901367, policy = 0.09588338434696198, entropy_loss = -0.0024037843104451895, gae = 14.583922386169434, kl_div = 0.0702824518084526, reward = 5.567593574523926, ord = 7.063851356506348, repeat = -3.3441624641418457, length = -0.2586295008659363, adv = 0.5143283605575562, rougeL = 1.3420705795288086, cider = 0.18600741028785706, clip = 0.40357738733291626, crf = 0.3274078369140625, ce = 1.5484387874603271, unr = 2.1065337657928467, ber = 5.6521759033203125\n",
      "refe: [CLS] in this picture we can see a book, paper, pen, and a calculator. [SEP]\n",
      "hypo: [CLS] in this image we can see a mobile phone, a paper, pen, a paper. [SEP]\n",
      "samp: [CLS] in this image we can see a mobile phone, a paper and some text and an object. [SEP]\n",
      "lr con   : 1.4216624685138537e-10\n",
      "lr bert  : 1.8755667506297228e-08\n",
      "lr cri   : 6.16624685138539e-05\n",
      "lr others: 4.984382871536523e-07\n",
      "Train epoch = 0.22670025188916876, loss = 16.67513084411621, policy = 0.09178059548139572, entropy_loss = -0.0023977819364517927, gae = 14.644659996032715, kl_div = 0.07026898115873337, reward = 5.619771957397461, ord = 7.068460464477539, repeat = -3.3167741298675537, length = -0.24889223277568817, adv = 0.5146340727806091, rougeL = 1.343941569328308, cider = 0.1923535019159317, clip = 0.40345704555511475, crf = 0.3299027383327484, ce = 1.5409159660339355, unr = 2.1169769763946533, ber = 5.651957035064697\n",
      "refe: [CLS] in this image there are trees. at the bottom of the image there is sand on the surface. in the background of the image there are mountains. at the top of the image there are clouds in the sky. [SEP]\n",
      "hypo: [CLS] in this image i can see a grassy land in the background i can see a grass and clouds in the sky. [SEP]\n",
      "samp: [CLS] in this image we can see a grassy land in the sky. in the left side there is greenery and clouds in the ground. [SEP]\n",
      "lr con   : 1.3519731318219982e-10\n",
      "lr bert  : 1.7836272040302267e-08\n",
      "lr cri   : 5.863979848866499e-05\n",
      "lr others: 4.740050377833753e-07\n",
      "Train epoch = 0.26448362720403024, loss = 16.775861740112305, policy = 0.08944937586784363, entropy_loss = -0.002389962086454034, gae = 14.751702308654785, kl_div = 0.07038802653551102, reward = 5.649794101715088, ord = 7.07023286819458, repeat = -3.2968125343322754, length = -0.2432572990655899, adv = 0.5111409425735474, rougeL = 1.3483657836914062, cider = 0.18607917428016663, clip = 0.4037480652332306, crf = 0.33141830563545227, ce = 1.5352928638458252, unr = 2.1196305751800537, ber = 5.651351451873779\n",
      "refe: [CLS] in this image i can see a depiction picture where i can see a woman and few lights. here i can see she is wearing white colour dress and a necklace. [SEP]\n",
      "hypo: [CLS] this is an animated image there is a lady see a woman is a woman, there is gown\n",
      "samp: [CLS] in the image i can see a depiction of the center there is a woman standing and we can see a necklace, trees, trees,\n",
      "lr con   : 1.2822837951301427e-10\n",
      "lr bert  : 1.6916876574307306e-08\n",
      "lr cri   : 5.561712846347607e-05\n",
      "lr others: 4.495717884130982e-07\n",
      "Train epoch = 0.3022670025188917, loss = 16.47637176513672, policy = 0.0905274897813797, entropy_loss = -0.0023898466024547815, gae = 14.448246002197266, kl_div = 0.07036690413951874, reward = 5.590715408325195, ord = 7.072583198547363, repeat = -3.3506057262420654, length = -0.24308714270591736, adv = 0.49098482728004456, rougeL = 1.3505356311798096, cider = 0.1885022670030594, clip = 0.40365105867385864, crf = 0.3335970342159271, ce = 1.5360244512557983, unr = 2.111825942993164, ber = 5.651782035827637\n",
      "refe: [CLS] two man are sitting on sofa and they both are holding mic. a person wearing a red t shirt is speaking. there is a table. on the table there is a bottle. in the background there is a wall. [SEP]\n",
      "hypo: [CLS] in this image we can see two persons sitting on the sofa. on the left side, there is a table and there is a table. in the left side, there is a table. [SEP]\n",
      "samp: [CLS] in this picture we can see two men there are two chair and holding a bottle on the left side, there is a table. in the back there is a bag. on the floor. [SEP]\n",
      "lr con   : 1.2125944584382872e-10\n",
      "lr bert  : 1.5997481108312342e-08\n",
      "lr cri   : 5.2594458438287154e-05\n",
      "lr others: 4.2513853904282117e-07\n",
      "Train epoch = 0.34005037783375314, loss = 16.34444808959961, policy = 0.0919235497713089, entropy_loss = -0.00239028362557292, gae = 14.305625915527344, kl_div = 0.07023493200540543, reward = 5.564122676849365, ord = 7.073567867279053, repeat = -3.372755527496338, length = -0.24422763288021088, adv = 0.4775049090385437, rougeL = 1.3480628728866577, cider = 0.18829345703125, clip = 0.40375423431396484, crf = 0.33702927827835083, ce = 1.542022943496704, unr = 2.1075377464294434, ber = 5.651486396789551\n",
      "refe: [CLS] in this image there is a street light on the grassland. there is a building having staircase with few lumps on it. there are few plants on the grassland. there are few trees. top of image there is sky with some clouds. [SEP]\n",
      "hypo: [CLS] in this image we can see a building, trees, trees, there is a pole, there is a building, the left side there are trees. [SEP]\n",
      "samp: [CLS] in this image i can see a building, trees, trees, there is a pole, plants, we can see the left side there are trees. [SEP]\n",
      "lr con   : 1.1429051217464315e-10\n",
      "lr bert  : 1.507808564231738e-08\n",
      "lr cri   : 4.957178841309823e-05\n",
      "lr others: 4.0070528967254406e-07\n",
      "Train epoch = 0.3778337531486146, loss = 15.97948169708252, policy = 0.1538839042186737, entropy_loss = -0.002407544292509556, gae = 13.898730278015137, kl_div = 0.07064103335142136, reward = 5.4767584800720215, ord = 7.0766987800598145, repeat = -3.4495654106140137, length = -0.23965825140476227, adv = 0.45340263843536377, rougeL = 1.3398795127868652, cider = 0.19416525959968567, clip = 0.4037570357322693, crf = 0.3259313702583313, ce = 1.532702088356018, unr = 2.0892839431762695, ber = 5.654907703399658\n",
      "refe: [CLS] in this image i can see few buildings, lights, bridgewater, fencing, few white color flowers to the trees. the sky is in blue color. [SEP]\n",
      "hypo: [CLS] in this image we can see a bridge and some trees, there are trees. in the right side. in the sky. in the sky. [SEP]\n",
      "samp: [CLS] in this image i can see a water. there is a water. in the left side. in the sky. in the left side of the sky. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (85 > 77). Running this sequence through the model will result in indexing errors\n",
      "[I 2026-02-04 12:42:45,729] Trial 41 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.17144628201798337\n",
      "clip_grad_threshold gradient norm: 0.9335174518076925\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 4.737463778590427\n",
      "unr_coef: 3.151306965387721\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.15691810635630632\n",
      "ce_coef: 0.4650569092363527\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.148791917366506\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_124258.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308d9497f1e34c9fa1dce60f20ada0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 13.38955020904541, policy = -7.373770039009742e-09, entropy_loss = -0.002707553096115589, gae = 12.24734115600586, kl_div = 0.07162197679281235, reward = 4.379249095916748, ord = 7.05744743347168, repeat = -4.3616557121276855, length = -0.2167385369539261, adv = 0.819251537322998, rougeL = 1.2508745193481445, cider = 0.2720009982585907, clip = 0.408130019903183, crf = 0.12096206098794937, ce = 0.9523329138755798, unr = 1.9001965522766113, ber = 5.675244331359863\n",
      "refe: [CLS] in this image i can see the person is wearing red color dress. background is in brown and black color. [SEP]\n",
      "hypo: [CLS] in this image we can see a person. in the background we can see the background. [SEP]\n",
      "samp: [CLS] in this image we can see a person in the background there is blurred. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:43:15,860] Trial 42 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.2787205708200087\n",
      "clip_grad_threshold gradient norm: 1.5174457368734962\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 4.121442638116796\n",
      "unr_coef: 3.7195607638809083\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.3338724335727824\n",
      "ce_coef: 0.6213841133732285\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.51287669754763\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_124328.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3158a0dcbc4ec6ae2ac543b72e61fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 17.787328720092773, policy = 1.9048906452212577e-08, entropy_loss = -0.00283035752363503, gae = 16.13225555419922, kl_div = 0.08231906592845917, reward = 4.240259647369385, ord = 6.990759372711182, repeat = -4.711369037628174, length = -0.18450728058815002, adv = 1.1107083559036255, rougeL = 1.2127041816711426, cider = 0.22205674648284912, clip = 0.40607750415802, crf = 0.2643314301967621, ce = 1.311254620552063, unr = 2.1453769207000732, ber = 5.6498236656188965\n",
      "refe: [CLS] this image is taken indoors. at the bottom of the image there is a table with many food items and a few things on it. in the middle of the image a man is standing on the floor and he is serving food. in the background there is a wall with many boards and text on them and there are a few empty chairs and a table. three men are standing on the floor. at the top of the image there is a ceiling with lights. [SEP]\n",
      "hypo: [CLS] in this image we can see a group of the foreground there is a fork eatables, we can see some food items. on the food on the table, spoon. [SEP]\n",
      "samp: [CLS] in this picture we can see a group of the left side of the foreground there is a table, there are some food items. on the right side of the table, glasses. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:43:45,911] Trial 43 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.24978651988072825\n",
      "clip_grad_threshold gradient norm: 1.802240314257959\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.5601330006455605\n",
      "unr_coef: 4.504140417586784\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.6902093341252552\n",
      "ce_coef: 0.8602851466012471\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 3.964914214708034\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_124358.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d673155e184a539ceba84637fb716e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 14.424939155578613, policy = 3.871229381502417e-08, entropy_loss = -0.002860389882698655, gae = 12.016083717346191, kl_div = 0.08510573953390121, reward = 5.0843048095703125, ord = 6.896526336669922, repeat = -4.320263862609863, length = -0.12193439155817032, adv = 0.9500354528427124, rougeL = 1.1873279809951782, cider = 0.22302085161209106, clip = 0.3998802602291107, crf = 0.5477611422538757, ce = 1.77884840965271, unr = 2.6299774646759033, ber = 5.648883819580078\n",
      "refe: [CLS] it is a closed room where the picture is taken and in the middle one man is sitting on the chair and beside him there is one basket one bin and behind him there is one fire place and brick wall on which there are some photos are kept and corner there is one shelf and things are kept in it and at the corner of the picture one person is standing in blue dress and behind him there is one sofa and there is a wall with photos covered on it and there is a\n",
      "hypo: [CLS] in this picture we can see three people are two persons are two persons sitting on the right side of them we can see also there is a table. [SEP]\n",
      "samp: [CLS] in this picture we can see three people are two persons are two persons sitting on the left side of them we can see the bottom there is a table on a table. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:44:16,551] Trial 44 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.1290041234114674\n",
      "clip_grad_threshold gradient norm: 1.197033835798093\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.3015575349194948\n",
      "unr_coef: 2.762858975464239\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.039639292867267306\n",
      "ce_coef: 0.7142372119610317\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.734247570733946\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_124429.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86cd4c1bb594d43804f117030d0a4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 15.610549926757812, policy = 7.220150255449198e-09, entropy_loss = -0.0028359033167362213, gae = 13.968018531799316, kl_div = 0.08564259856939316, reward = 4.139442443847656, ord = 7.027890682220459, repeat = -4.420921325683594, length = -0.09795194864273071, adv = 0.8886954188346863, rougeL = 1.2220020294189453, cider = 0.23381908237934113, clip = 0.40129053592681885, crf = 0.03276074305176735, ce = 1.5269639492034912, unr = 1.6304248571395874, ber = 5.660788059234619\n",
      "refe: [CLS] in this image we can see a tree and the sky is in the background. [SEP]\n",
      "hypo: [CLS] in this image we can see trees. in the sky. [SEP]\n",
      "samp: [CLS] in this image i can see a tree which are trees. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:44:47,271] Trial 45 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.15783978175095803\n",
      "clip_grad_threshold gradient norm: 0.3434639618385269\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.2369353444771423\n",
      "unr_coef: 3.9647957370415017\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.25353636542579816\n",
      "ce_coef: 0.5189371648338742\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 3.6790882236543414\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_124459.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ce700ca8cb47bb9389938e22bc1ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 18.40308380126953, policy = 3.479497934222309e-08, entropy_loss = -0.0028343182057142258, gae = 16.96274757385254, kl_div = 0.08360421657562256, reward = 4.86301326751709, ord = 6.963399887084961, repeat = -4.293218612670898, length = -0.13882768154144287, adv = 1.191759705543518, rougeL = 1.2259089946746826, cider = 0.16902245581150055, clip = 0.4022020399570465, crf = 0.22769969701766968, ce = 1.1318671703338623, unr = 2.3316595554351807, ber = 5.6547112464904785\n",
      "refe: [CLS] in the center of the image we can see two vehicles on the road. in the background there is a building, lights, boards with some text, pillars, few people are walking, few people are holding some objects and a few other objects. [SEP]\n",
      "hypo: [CLS] in this image, we can see the road, we can see the background there are some people are some people. there is written on the road. [SEP]\n",
      "samp: [CLS] in this image, we can see the building and we can see the road, we can also there is written on the background we can see the top of them. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:45:17,181] Trial 46 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.2354238529514482\n",
      "clip_grad_threshold gradient norm: 0.706603808019664\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.9208633762873246\n",
      "unr_coef: 3.2912714566903967\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.40433351514212035\n",
      "ce_coef: 0.38934588128219555\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 2.207780743099258\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_124529.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7217b73f34564c00870c8d5e7dcaf189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 11.680767059326172, policy = -3.072404197723699e-08, entropy_loss = -0.0027330301236361265, gae = 10.582151412963867, kl_div = 0.08411572128534317, reward = 4.6828460693359375, ord = 7.005321502685547, repeat = -4.22830867767334, length = -0.0829995647072792, adv = 1.3055665493011475, rougeL = 1.2055717706680298, cider = 0.2558615207672119, clip = 0.4016098082065582, crf = 0.27002865076065063, ce = 0.7472023963928223, unr = 1.9888328313827515, ber = 5.6627702713012695\n",
      "refe: [CLS] in this image we can see a woman smiling and some text. [SEP]\n",
      "hypo: [CLS] in this picture we can see a woman standing and a woman is a woman wearing spectacles. [SEP] some text. [SEP]\n",
      "samp: [CLS] in this picture we can see a woman wearing middle of the middle of the left side of the background i can see some text. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:45:47,867] Trial 47 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.21188260971848014\n",
      "clip_grad_threshold gradient norm: 2.8270927238274512\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.0359110031955714\n",
      "unr_coef: 4.774587334617673\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.1826927742092421\n",
      "ce_coef: 0.3324829647065757\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 2.804016345608703\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_124600.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8875d08a5f402aa980b44833ae99bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 12.273792266845703, policy = 2.457923420351449e-09, entropy_loss = -0.0027882156427949667, gae = 11.399984359741211, kl_div = 0.08173063397407532, reward = 5.2371416091918945, ord = 7.092769145965576, repeat = -4.599658489227295, length = -0.06587052345275879, adv = 1.1235915422439575, rougeL = 1.2573881149291992, cider = 0.2930903434753418, clip = 0.40635383129119873, crf = 0.1304652988910675, ce = 0.6644003391265869, unr = 2.809901475906372, ber = 5.709786415100098\n",
      "refe: [CLS] in this picture we can see a man in the air. at the bottom portion of the picture we can see a plant and the rock surface. we can see a white object on the water. in the background we can see clouds in the sky. [SEP]\n",
      "hypo: [CLS] in this image we can see a person standing on the image, we can also see the background we can see water. [SEP]\n",
      "samp: [CLS] in this image i can see the we can see the top of the bottom there are trees. we can see water, we can see water. here [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:46:18,728] Trial 48 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.19597090515428528\n",
      "clip_grad_threshold gradient norm: 1.565734631556941\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 1.6327058129632808\n",
      "unr_coef: 3.6543890808102244\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.12107194377940686\n",
      "ce_coef: 0.6347679614492956\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 3.141733221760815\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_124631.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebddcd1af5de45a39b7b72a85de336f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 10.292351722717285, policy = 7.373770039009742e-09, entropy_loss = -0.002754148095846176, gae = 8.683889389038086, kl_div = 0.07563270628452301, reward = 4.434614658355713, ord = 6.956368923187256, repeat = -4.553327560424805, length = -0.0843973234295845, adv = 0.8691930770874023, rougeL = 1.208153247833252, cider = 0.17102551460266113, clip = 0.4056439697742462, crf = 0.11219499260187149, ce = 1.4233886003494263, unr = 2.115971088409424, ber = 5.631948471069336\n",
      "refe: [CLS] in this image, we can see a woman and man are walking on the path. background we can see buildings, people, tower, poles, walls, pillars, lights, few objects and sky. [SEP]\n",
      "hypo: [CLS] in this image we can see there is a woman there is a woman standing and there are buildings, we can see the background we can see the top of the sky. [SEP]\n",
      "samp: [CLS] in the foreground we can see a group of the left side of the background there are trees and we can see the background we can see the top of the sky. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:46:49,056] Trial 49 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.11949840289280128\n",
      "clip_grad_threshold gradient norm: 2.2741808418130818\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.819520526083581\n",
      "unr_coef: 4.133884934025211\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.06302873014305271\n",
      "ce_coef: 0.26448309293328776\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.288039324659637\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_124701.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6879802115c94f1f8827e3caafa7fe5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 13.504033088684082, policy = 6.083360659658865e-08, entropy_loss = -0.002726644976064563, gae = 12.822257995605469, kl_div = 0.08545909821987152, reward = 5.01540994644165, ord = 7.0466132164001465, repeat = -4.352953910827637, length = -0.1970474123954773, adv = 0.7597209811210632, rougeL = 1.2379812002182007, cider = 0.1894330233335495, clip = 0.4050145149230957, crf = 0.0500313974916935, ce = 0.5490111708641052, unr = 2.518798589706421, ber = 5.646812915802002\n",
      "refe: [CLS] in this image in front there is grass on the surface and we can see a few people are standing on the road. at the center of the image there is a bridge. in the background there are trees and sky. [SEP]\n",
      "hypo: [CLS] in this picture we can see there is walking on the pathway. on the right side of the right side, we can see the background we can see the image there are trees, we can see the sky. [SEP]\n",
      "samp: [CLS] in this image we can see there is walking on the pathway, on the background there are walking on the background we can see the background we can see the image there are we can see the top of the sky. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:47:19,570] Trial 50 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.14140936618662112\n",
      "clip_grad_threshold gradient norm: 1.9747179488769473\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.4495002007951996\n",
      "unr_coef: 2.8909573698073197\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.22240494580171535\n",
      "ce_coef: 0.8743213013335216\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 2.6795156414532904\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_124732.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd3201fb3ae41e5a099c9adbcb066e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 8.656180381774902, policy = 2.7651639200598765e-08, entropy_loss = -0.0028238832019269466, gae = 6.566256046295166, kl_div = 0.08408588916063309, reward = 4.230921745300293, ord = 6.882345199584961, repeat = -4.307094097137451, length = -0.08297593891620636, adv = 0.724530041217804, rougeL = 1.1646767854690552, cider = 0.18296483159065247, clip = 0.40503472089767456, crf = 0.17318587005138397, ce = 1.8354763984680176, unr = 1.7386467456817627, ber = 5.648191928863525\n",
      "refe: [CLS] in the image there are two players, the first player is falling on the ground and the second player is standing and there is a ball beside the players on the ground. [SEP]\n",
      "hypo: [CLS] in this image we can see a person standing on the ground. on the ground, we can also see the grass. [SEP]\n",
      "samp: [CLS] in the image there is a person standing on the ground, we can see a person sitting on the background. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 12:47:50,541] Trial 51 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.10465345698866436\n",
      "clip_grad_threshold gradient norm: 1.7276698340994059\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.0962800684917156\n",
      "unr_coef: 2.492827653909649\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.07848304517579724\n",
      "ce_coef: 0.688275676672358\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 2.168931096180323\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_124803.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ab670ed34b4cce9e1c581ff52c24af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 8.173421859741211, policy = 3.8097812904425155e-08, entropy_loss = -0.002647583605721593, gae = 6.670410633087158, kl_div = 0.0792132318019867, reward = 4.339540958404541, ord = 7.071635723114014, repeat = -4.158459663391113, length = -0.07940211147069931, adv = 0.9141733646392822, rougeL = 1.256170630455017, cider = 0.24361620843410492, clip = 0.40257886052131653, crf = 0.056095853447914124, ce = 1.3703502416610718, unr = 1.505767583847046, ber = 5.680501937866211\n",
      "refe: [CLS] in the picture i can see nine images. in the first row first image we can see two person standing and smiling. in the first row second image we can see a person holding camera is sitting and smiling, we can see glass, candle and bottles are placed. in the first row third image we can see computer, cpu, keyboards, speakers and mouse. in the second row first picture we can see an animated picture in which we can see two persons are standing and we can\n",
      "hypo: [CLS] this is a collage image is a collage image, we can see glasses, we can see the top of them, few other objects. [SEP]\n",
      "samp: [CLS] this is a collage image is a collage image, we can see a table we can see the image there are bottles, we can see a second front of them are some other objects. [SEP]\n",
      "lr con   : 6.690176322418135e-11\n",
      "lr bert  : 8.826196473551637e-09\n",
      "lr cri   : 2.90176322418136e-05\n",
      "lr others: 2.3455919395465993e-07\n",
      "Train epoch = 0.037783375314861464, loss = 9.813003540039062, policy = 0.05098019912838936, entropy_loss = -0.0024876436218619347, gae = 8.242419242858887, kl_div = 0.07820979505777359, reward = 5.01962947845459, ord = 7.014724254608154, repeat = -3.4610323905944824, length = -0.09194869548082352, adv = 1.0421854257583618, rougeL = 1.3014185428619385, cider = 0.20230388641357422, clip = 0.40084657073020935, crf = 0.08584226667881012, ce = 1.3580397367477417, unr = 1.5578867197036743, ber = 5.658666133880615\n",
      "refe: [CLS] in this image we can see a bowl in which food items are there. [SEP]\n",
      "hypo: [CLS] in this image we can see some food item. in the food items. [SEP]\n",
      "samp: [CLS] in this picture we can see food item and a table. in the food items. [SEP]\n",
      "lr con   : 1.2962216624685136e-10\n",
      "lr bert  : 1.7100755667506296e-08\n",
      "lr cri   : 5.622166246851385e-05\n",
      "lr others: 4.544584382871536e-07\n",
      "Train epoch = 0.07556675062972293, loss = 10.684980392456055, policy = 0.056644242256879807, entropy_loss = -0.0023714674171060324, gae = 9.04069709777832, kl_div = 0.08093439787626266, reward = 5.3912787437438965, ord = 7.005667686462402, repeat = -3.1112687587738037, length = -0.10672734677791595, adv = 1.1050236225128174, rougeL = 1.3257502317428589, cider = 0.18199317157268524, clip = 0.4016304612159729, crf = 0.10236910730600357, ce = 1.4067070484161377, unr = 1.6036075353622437, ber = 5.6370015144348145\n",
      "refe: [CLS] in this image, we can see the wall with some windows, doors and other objects. we can also see some stairs and the fence. we can see the ground and a pole. we can also see an object on the left. [SEP]\n",
      "hypo: [CLS] in this image there is a building. in the wall with windows. [SEP]\n",
      "samp: [CLS] in this picture we can see a building with windows, we can see railing. [SEP]\n",
      "lr con   : 1.6307304785894207e-10\n",
      "lr bert  : 2.1513853904282117e-08\n",
      "lr cri   : 7.073047858942065e-05\n",
      "lr others: 5.717380352644836e-07\n",
      "Train epoch = 0.11335012594458438, loss = 11.18348503112793, policy = 0.05958179756999016, entropy_loss = -0.002307845512405038, gae = 9.522068977355957, kl_div = 0.0813233032822609, reward = 5.60277795791626, ord = 7.02352237701416, repeat = -2.941612958908081, length = -0.11146408319473267, adv = 1.13619065284729, rougeL = 1.3452019691467285, cider = 0.17136886715888977, clip = 0.4031763970851898, crf = 0.10795015096664429, ce = 1.4148685932159424, unr = 1.6323328018188477, ber = 5.630394458770752\n",
      "refe: [CLS] in this image there are group of people. there are laptops, cups, bottle, clothes on the table. at the bottom there is bag and there is a mat. [SEP]\n",
      "hypo: [CLS] in this image we can see number of people are sitting on chairs. in front of the front of them there are standing. [SEP]\n",
      "samp: [CLS] in this picture we can see people sitting on chairs and a chair. in front of the front of them there are standing. [SEP] standing. [SEP]\n",
      "lr con   : 1.561041141897565e-10\n",
      "lr bert  : 2.0594458438287153e-08\n",
      "lr cri   : 6.770780856423173e-05\n",
      "lr others: 5.473047858942065e-07\n",
      "Train epoch = 0.15113350125944586, loss = 11.28409481048584, policy = 0.05954749137163162, entropy_loss = -0.0022613301407545805, gae = 9.628920555114746, kl_div = 0.08141524344682693, reward = 5.682594299316406, ord = 7.0346150398254395, repeat = -2.896843433380127, length = -0.109379842877388, adv = 1.140559196472168, rougeL = 1.351630687713623, cider = 0.1731197088956833, clip = 0.40396648645401, crf = 0.11013709753751755, ce = 1.4063353538513184, unr = 1.6542034149169922, ber = 5.632345199584961\n",
      "refe: [CLS] in this image i can see two persons. and these people are holding the guitar. [SEP]\n",
      "hypo: [CLS] in this image we can see a man and playing guitar. [SEP] playing guitar and the background there is standing. [SEP]\n",
      "samp: [CLS] in this image i can see a person and playing guitar and playing guitar. [SEP] playing guitar and the background there is standing. [SEP]\n",
      "lr con   : 1.4913518052057094e-10\n",
      "lr bert  : 1.9675062972292192e-08\n",
      "lr cri   : 6.468513853904282e-05\n",
      "lr others: 5.228715365239295e-07\n",
      "Train epoch = 0.1889168765743073, loss = 11.381902694702148, policy = 0.06213415414094925, entropy_loss = -0.002231862163171172, gae = 9.721057891845703, kl_div = 0.08091609179973602, reward = 5.753904342651367, ord = 7.0514044761657715, repeat = -2.855207681655884, length = -0.11239201575517654, adv = 1.1432093381881714, rougeL = 1.3603137731552124, cider = 0.17650920152664185, clip = 0.40363460779190063, crf = 0.11210639774799347, ce = 1.4079201221466064, unr = 1.6700994968414307, ber = 5.633011341094971\n",
      "refe: [CLS] this is an outside view. at the bottom there is a lake. on both sides of the lake there are many plants along with the flowers and grass. in the background there are many trees. at the top of the image i can see the sky. [SEP]\n",
      "hypo: [CLS] in this image we can see the grass, plants, grass. [SEP] surrounded center of the grass. [SEP]\n",
      "samp: [CLS] in this picture we can see the grass, plants, grass. [SEP] surrounded center of the grass on the right side. [SEP]\n",
      "lr con   : 1.4216624685138537e-10\n",
      "lr bert  : 1.8755667506297228e-08\n",
      "lr cri   : 6.16624685138539e-05\n",
      "lr others: 4.984382871536523e-07\n",
      "Train epoch = 0.22670025188916876, loss = 11.4644136428833, policy = 0.062009088695049286, entropy_loss = -0.002207258716225624, gae = 9.8052978515625, kl_div = 0.08096779882907867, reward = 5.817320823669434, ord = 7.054627895355225, repeat = -2.8062963485717773, length = -0.11405737698078156, adv = 1.1440006494522095, rougeL = 1.3698097467422485, cider = 0.17454323172569275, clip = 0.4036707580089569, crf = 0.11314216256141663, ce = 1.4052035808563232, unr = 1.6830472946166992, ber = 5.634515285491943\n",
      "refe: [CLS] in this image we can see a wooden object which is painted with yellow and black color. there are many chair in the image. [SEP]\n",
      "hypo: [CLS] in this image we can see the chairs. [SEP]\n",
      "samp: [CLS] in this image we can see the chairs and the tables. [SEP]\n",
      "lr con   : 1.3519731318219982e-10\n",
      "lr bert  : 1.7836272040302267e-08\n",
      "lr cri   : 5.863979848866499e-05\n",
      "lr others: 4.740050377833753e-07\n",
      "Train epoch = 0.26448362720403024, loss = 11.702279090881348, policy = 0.2877717912197113, entropy_loss = -0.002187228761613369, gae = 9.817404747009277, kl_div = 0.08095907419919968, reward = 5.848577499389648, ord = 7.05744743347168, repeat = -2.784503936767578, length = -0.11473223567008972, adv = 1.1389235258102417, rougeL = 1.3770567178726196, cider = 0.17294764518737793, clip = 0.40338659286499023, crf = 0.11393997818231583, ce = 1.4043902158737183, unr = 1.690367579460144, ber = 5.633444309234619\n",
      "refe: [CLS] in this picture, we see an insect which looks like a housefly is on the green color leaf. in the background, it is black in color. [SEP]\n",
      "hypo: [CLS] in this image we can see an insect on the leaf. [SEP]\n",
      "samp: [CLS] in this image i can see an insect on the leaf. [SEP]\n",
      "lr con   : 1.2822837951301427e-10\n",
      "lr bert  : 1.6916876574307306e-08\n",
      "lr cri   : 5.561712846347607e-05\n",
      "lr others: 4.495717884130982e-07\n",
      "Train epoch = 0.3022670025188917, loss = 11.719189643859863, policy = 0.27917730808258057, entropy_loss = -0.0021683997474610806, gae = 9.845122337341309, kl_div = 0.08051013201475143, reward = 5.8964128494262695, ord = 7.062611103057861, repeat = -2.748610019683838, length = -0.11534377932548523, adv = 1.137007474899292, rougeL = 1.3845438957214355, cider = 0.1788579225540161, clip = 0.4032883942127228, crf = 0.11448745429515839, ce = 1.402062177658081, unr = 1.6977548599243164, ber = 5.634421348571777\n",
      "refe: [CLS] this is the picture of a flower which is in orange and yellow color. [SEP]\n",
      "hypo: [CLS] in this image we can see a flower. [SEP]\n",
      "samp: [CLS] in this image i can see a flower. [SEP]\n",
      "lr con   : 1.2125944584382872e-10\n",
      "lr bert  : 1.5997481108312342e-08\n",
      "lr cri   : 5.2594458438287154e-05\n",
      "lr others: 4.2513853904282117e-07\n",
      "Train epoch = 0.34005037783375314, loss = 11.705900192260742, policy = 0.25585368275642395, entropy_loss = -0.0021628544200211763, gae = 9.8517427444458, kl_div = 0.08061397075653076, reward = 5.927912712097168, ord = 7.065343379974365, repeat = -2.7240779399871826, length = -0.11635291576385498, adv = 1.132545828819275, rougeL = 1.3869818449020386, cider = 0.1800987720489502, clip = 0.4033298194408417, crf = 0.11517298221588135, ce = 1.4046809673309326, unr = 1.7029997110366821, ber = 5.633091449737549\n",
      "refe: [CLS] in this picture there is a view of the road with classic cars parked on the roadside. in the middle there is a road. behind we can see some tall trees. in the background there is some old building with shops. [SEP]\n",
      "hypo: [CLS] in this image we can see vehicles on the road. we can see a road, there are vehicles, there are buildings, there is a road. [SEP]\n",
      "samp: [CLS] in this image i can see vehicles on the road. we can see a road, there are vehicles on the footpath. we can see there is a road. [SEP]\n",
      "lr con   : 1.1429051217464315e-10\n",
      "lr bert  : 1.507808564231738e-08\n",
      "lr cri   : 4.957178841309823e-05\n",
      "lr others: 4.0070528967254406e-07\n",
      "Train epoch = 0.3778337531486146, loss = 11.703995704650879, policy = 0.248826801776886, entropy_loss = -0.0021510233636945486, gae = 9.862335205078125, kl_div = 0.0805366262793541, reward = 5.963703155517578, ord = 7.070705413818359, repeat = -2.6989760398864746, length = -0.11594855040311813, adv = 1.129105806350708, rougeL = 1.3925343751907349, cider = 0.1790943145751953, clip = 0.40316373109817505, crf = 0.11529240757226944, ce = 1.3991570472717285, unr = 1.7079222202301025, ber = 5.635020732879639\n",
      "refe: [CLS] in this picture i can see an aircraft flying, there is grass, and in the background there is the sky. [SEP]\n",
      "hypo: [CLS] in this image we can see an aircraft in the air. in the background there are trees. [SEP]\n",
      "samp: [CLS] in the center of the center there is flying, grass. in the plane can see many trees. [SEP] grass. [SEP]. [SEP] sky. [SEP]\n",
      "lr con   : 1.073215785054576e-10\n",
      "lr bert  : 1.4158690176322418e-08\n",
      "lr cri   : 4.654911838790932e-05\n",
      "lr others: 3.76272040302267e-07\n",
      "Train epoch = 0.4156171284634761, loss = 11.717368125915527, policy = 0.23209761083126068, entropy_loss = -0.0021347426809370518, gae = 9.889586448669434, kl_div = 0.08074908703565598, reward = 6.005663871765137, ord = 7.070132255554199, repeat = -2.6599597930908203, length = -0.11792289465665817, adv = 1.1271038055419922, rougeL = 1.3943495750427246, cider = 0.18329066038131714, clip = 0.4028325080871582, crf = 0.11604076623916626, ce = 1.4010281562805176, unr = 1.7134138345718384, ber = 5.634835720062256\n",
      "refe: [CLS] there are 2 people singing. the person at the left is holding the guitar. at the back hard rock cafe is written. [SEP]\n",
      "hypo: [CLS] in this image there are three men playing guitar. the guitar and playing guitar and playing guitar. [SEP]. [SEP]. [SEP]\n",
      "samp: [CLS] in this image there are two men playing guitar among them there is playing guitar and playing guitar. [SEP] in his hands. [SEP]\n",
      "lr con   : 1.0035264483627203e-10\n",
      "lr bert  : 1.3239294710327456e-08\n",
      "lr cri   : 4.35264483627204e-05\n",
      "lr others: 3.518387909319899e-07\n",
      "Train epoch = 0.4534005037783375, loss = 11.665218353271484, policy = 0.21833260357379913, entropy_loss = -0.0021276359912008047, gae = 9.8422269821167, kl_div = 0.08079114556312561, reward = 6.01395320892334, ord = 7.067832946777344, repeat = -2.6500954627990723, length = -0.11976397782564163, adv = 1.1191315650939941, rougeL = 1.3945595026016235, cider = 0.18034636974334717, clip = 0.40306970477104187, crf = 0.11705073714256287, ce = 1.4089438915252686, unr = 1.7159792184829712, ber = 5.633582592010498\n",
      "refe: [CLS] in this picture, we can see a person running on the ground, and the ground is covered with the snow, we can see dry plants, trees, mountain and the sky. [SEP]\n",
      "hypo: [CLS] in this image we can see a person is walking and a person is walking and the background, trees. [SEP]. [SEP]\n",
      "samp: [CLS] in this image i can see a person is covered with some trees. at the background there are plants, trees. [SEP]\n",
      "lr con   : 9.338371116708649e-11\n",
      "lr bert  : 1.2319899244332495e-08\n",
      "lr cri   : 4.0503778337531486e-05\n",
      "lr others: 3.2740554156171283e-07\n",
      "Train epoch = 0.491183879093199, loss = 11.612222671508789, policy = 0.20690611004829407, entropy_loss = -0.0021154950372874737, gae = 9.796610832214355, kl_div = 0.08073344826698303, reward = 6.021296501159668, ord = 7.070443153381348, repeat = -2.647843599319458, length = -0.12068823724985123, adv = 1.1111021041870117, rougeL = 1.396336317062378, cider = 0.18467417359352112, clip = 0.4030747413635254, crf = 0.11775852739810944, ce = 1.4123278856277466, unr = 1.7193845510482788, ber = 5.634631633758545\n",
      "refe: [CLS] in the center of this picture we can see a child carousel containing the toys of animals and metal rods and we can see the group of persons, lights, metal rods and many other objects. [SEP]\n",
      "hypo: [CLS] in this image we can see group of people are lights and there are lights. [SEP]\n",
      "samp: [CLS] in this image i can see group of people are lights and there are some objects. [SEP]\n",
      "lr con   : 8.641477749790091e-11\n",
      "lr bert  : 1.140050377833753e-08\n",
      "lr cri   : 3.7481108312342564e-05\n",
      "lr others: 3.029722921914357e-07\n",
      "Train epoch = 0.5289672544080605, loss = 11.608007431030273, policy = 0.20299310982227325, entropy_loss = -0.0021061331499367952, gae = 9.794108390808105, kl_div = 0.0808989554643631, reward = 6.045792102813721, ord = 7.07319974899292, repeat = -2.62825608253479, length = -0.12132392078638077, adv = 1.106651782989502, rougeL = 1.3963472843170166, cider = 0.18563149869441986, clip = 0.40322333574295044, crf = 0.11820130050182343, ce = 1.4139117002487183, unr = 1.7221722602844238, ber = 5.635196208953857\n",
      "refe: [CLS] in this picture there are three people sitting on the chair in front of a table. one of them is staring at the camera, the second person is operating a laptop, and the third person is staring at the laptop. [SEP]\n",
      "hypo: [CLS] in this image we can see two persons sitting in front of the table on the table on the table. on the table. [SEP]\n",
      "samp: [CLS] in this image i can see two persons sitting on the chair, laptop, a table. [SEP] front of the table. [SEP]. [SEP]\n",
      "lr con   : 7.944584382871536e-11\n",
      "lr bert  : 1.048110831234257e-08\n",
      "lr cri   : 3.4458438287153655e-05\n",
      "lr others: 2.785390428211587e-07\n",
      "Train epoch = 0.5667506297229219, loss = 11.567802429199219, policy = 0.1952241212129593, entropy_loss = -0.0020976990927010775, gae = 9.760138511657715, kl_div = 0.0808413177728653, reward = 6.057223320007324, ord = 7.072348117828369, repeat = -2.617016077041626, length = -0.12162107974290848, adv = 1.0999705791473389, rougeL = 1.397538185119629, cider = 0.18493609130382538, clip = 0.4033788740634918, crf = 0.11857695132493973, ce = 1.4151175022125244, unr = 1.7235130071640015, ber = 5.63526725769043\n",
      "refe: [CLS] in this picture we can see some people are standing, a woman in the front is holding a mobile phone, a woman on the right side is carrying a bag, there are some posters pasted on the right side, in the background there is a building, we can see a banner in the middle. [SEP]\n",
      "hypo: [CLS] in this image i can see a group of people standing and holding placards papers, boards, we can see buildings. [SEP]. [SEP]\n",
      "samp: [CLS] in this image we can see group of people standing and holding a board and holding a tree. on the background there are buildings. [SEP]. [SEP]\n",
      "lr con   : 7.24769101595298e-11\n",
      "lr bert  : 9.561712846347607e-09\n",
      "lr cri   : 3.143576826196473e-05\n",
      "lr others: 2.541057934508816e-07\n",
      "Train epoch = 0.6045340050377834, loss = 11.539422035217285, policy = 0.18677502870559692, entropy_loss = -0.0020902499090880156, gae = 9.739998817443848, kl_div = 0.08083757013082504, reward = 6.074091911315918, ord = 7.074718475341797, repeat = -2.604219913482666, length = -0.12188374251127243, adv = 1.0946680307388306, rougeL = 1.400758981704712, cider = 0.1847061663866043, clip = 0.4035128057003021, crf = 0.1189073920249939, ce = 1.414994716644287, unr = 1.7254774570465088, ber = 5.636397361755371\n",
      "refe: [CLS] in this picture we can see a person standing. there is a man sitting on a chair. we can see microphones, musical instruments and other objects. there are some lights visible on the left side. we can see some text in the bottom right. [SEP]\n",
      "hypo: [CLS] in this image we can see dark. on the right side, there are standing and there are standing and the stage and the stage. [SEP]\n",
      "samp: [CLS] in this picture we can see dark. on the left side of the right side of the left side of the stage and the image. [SEP] screen. [SEP]\n",
      "lr con   : 6.550797649034425e-11\n",
      "lr bert  : 8.642317380352645e-09\n",
      "lr cri   : 2.8413098236775818e-05\n",
      "lr others: 2.2967254408060454e-07\n",
      "Train epoch = 0.6423173803526449, loss = 11.527172088623047, policy = 0.17912618815898895, entropy_loss = -0.0020818249322474003, gae = 9.732705116271973, kl_div = 0.08093007653951645, reward = 6.095514297485352, ord = 7.072273254394531, repeat = -2.5833981037139893, length = -0.12250669300556183, adv = 1.0906074047088623, rougeL = 1.401192307472229, cider = 0.183391273021698, clip = 0.40346062183380127, crf = 0.11930479109287262, ce = 1.4171885251998901, unr = 1.7291456460952759, ber = 5.636390209197998\n",
      "refe: [CLS] in this picture we can see painting of a person. [SEP]\n",
      "hypo: [CLS] in this image there is a painting. [SEP]\n",
      "samp: [CLS] in this image i can see a drawing a woman. [SEP]\n",
      "lr con   : 5.853904282115869e-11\n",
      "lr bert  : 7.722921914357682e-09\n",
      "lr cri   : 2.5390428211586902e-05\n",
      "lr others: 2.0523929471032745e-07\n",
      "Train epoch = 0.6801007556675063, loss = 11.506178855895996, policy = 0.17261439561843872, entropy_loss = -0.0020757431630045176, gae = 9.716363906860352, kl_div = 0.08092381060123444, reward = 6.110575199127197, ord = 7.072815418243408, repeat = -2.570863962173462, length = -0.12320317327976227, adv = 1.085840106010437, rougeL = 1.4007701873779297, cider = 0.18287576735019684, clip = 0.4032450318336487, crf = 0.11964815855026245, ce = 1.4187055826187134, unr = 1.731826901435852, ber = 5.637495517730713\n",
      "refe: [CLS] in this image there is a group of people standing on stairs with a smile on their face, behind them there is a building, in front of the building there is a chair and a trash can. [SEP]\n",
      "hypo: [CLS] in this image i can see some people standing people standing in the background there is a group of the building. [SEP]\n",
      "samp: [CLS] in this image i can see some people standing and standing in the background there is a group of the background there is a building. [SEP]\n",
      "lr con   : 5.157010915197313e-11\n",
      "lr bert  : 6.8035264483627206e-09\n",
      "lr cri   : 2.2367758186397984e-05\n",
      "lr others: 1.8080604534005037e-07\n",
      "Train epoch = 0.7178841309823678, loss = 11.520071983337402, policy = 0.2465132623910904, entropy_loss = -0.00207347609102726, gae = 9.65371036529541, kl_div = 0.0811307355761528, reward = 6.102148056030273, ord = 7.073486328125, repeat = -2.5787084102630615, length = -0.1234673410654068, adv = 1.076764702796936, rougeL = 1.400502324104309, cider = 0.18342244625091553, clip = 0.40309932827949524, crf = 0.12014421075582504, ce = 1.4206475019454956, unr = 1.730838656425476, ber = 5.637619972229004\n",
      "refe: [CLS] there is a woman holding a stick, wearing a costume and standing in the foreground area of the image, there is a pillar on the left side, there is a lamp, curtain, an arch and the wall in the background. [SEP]\n",
      "hypo: [CLS] in this image we can see a mannequin dress and a statue. in the background, in the background there is a wall. [SEP]\n",
      "samp: [CLS] in this picture we can see a mannequin doing, a statue. on the background. in the background there is a building. [SEP]\n",
      "lr con   : 4.460117548278757e-11\n",
      "lr bert  : 5.884130982367758e-09\n",
      "lr cri   : 1.9345088161209068e-05\n",
      "lr others: 1.563727959697733e-07\n",
      "Train epoch = 0.7556675062972292, loss = 11.48105525970459, policy = 0.24494868516921997, entropy_loss = -0.0020716660656034946, gae = 9.613316535949707, kl_div = 0.08116436749696732, reward = 6.1037983894348145, ord = 7.072372913360596, repeat = -2.5754799842834473, length = -0.1235630065202713, adv = 1.0700840950012207, rougeL = 1.4006798267364502, cider = 0.18259452283382416, clip = 0.4030010998249054, crf = 0.120529904961586, ce = 1.4231688976287842, unr = 1.730468511581421, ber = 5.636953830718994\n",
      "refe: [CLS] in this picture there is a man and a woman in the center of the image and there is a door in the background area of the image, there is a chair on the left side of the image. [SEP]\n",
      "hypo: [CLS] in this image i can see a man standing and smiling and smiling and smiling. in their hands. in their hands. [SEP]\n",
      "samp: [CLS] in this image i can see a man standing and smiling and smiling and smiling and holding one person is holding the left side there is a smile on the left side, a table. [SEP]\n",
      "lr con   : 3.7632241813602014e-11\n",
      "lr bert  : 4.964735516372796e-09\n",
      "lr cri   : 1.632241813602015e-05\n",
      "lr others: 1.3193954659949622e-07\n",
      "Train epoch = 0.7934508816120907, loss = 11.433074951171875, policy = 0.23704583942890167, entropy_loss = -0.0020668976940214634, gae = 9.57535171508789, kl_div = 0.0810936838388443, reward = 6.104877948760986, ord = 7.075043201446533, repeat = -2.5778491497039795, length = -0.12306643277406693, adv = 1.063579797744751, rougeL = 1.4001834392547607, cider = 0.1832668036222458, clip = 0.40306365489959717, crf = 0.12057827413082123, ce = 1.4210736751556396, unr = 1.7307509183883667, ber = 5.637438774108887\n",
      "refe: [CLS] this person is sitting and playing this musical instruments. these 2 persons are standing and playing a guitar. these are plants. a picture on wall. [SEP]\n",
      "hypo: [CLS] in this image i can see a group of this image we can see musical instruments. [SEP]\n",
      "samp: [CLS] in this image we can see a group of this image, musical instruments. [SEP] musical instruments. [SEP] hats. [SEP]. [SEP]\n",
      "lr con   : 3.066330814441645e-11\n",
      "lr bert  : 4.045340050377834e-09\n",
      "lr cri   : 1.3299748110831234e-05\n",
      "lr others: 1.0750629722921913e-07\n",
      "Train epoch = 0.8312342569269522, loss = 11.388206481933594, policy = 0.2288983166217804, entropy_loss = -0.0020623852033168077, gae = 9.538653373718262, kl_div = 0.08107823133468628, reward = 6.106355667114258, ord = 7.073408603668213, repeat = -2.5750744342803955, length = -0.12318417429924011, adv = 1.0575546026229858, rougeL = 1.399959683418274, cider = 0.18422211706638336, clip = 0.40328195691108704, crf = 0.12071499973535538, ce = 1.4209239482879639, unr = 1.7312064170837402, ber = 5.636645793914795\n",
      "refe: [CLS] in this image i can see a text, grass, trees, houses and mountains. at the top i can see the blue sky. this image is taken may be on the ground. [SEP]\n",
      "hypo: [CLS] in this image we can see trees, bottom of the bottom of the bottom of the bottom of the sky. [SEP]\n",
      "samp: [CLS] in this image i can see mountains, bottom of the bottom of the top of the top of the sky. [SEP]\n",
      "lr con   : 2.3694374475230897e-11\n",
      "lr bert  : 3.1259445843828713e-09\n",
      "lr cri   : 1.0277078085642317e-05\n",
      "lr others: 8.307304785894206e-08\n",
      "Train epoch = 0.8690176322418136, loss = 11.3731107711792, policy = 0.22318921983242035, entropy_loss = -0.0020569642074406147, gae = 9.52968978881836, kl_div = 0.08103597164154053, reward = 6.124279022216797, ord = 7.073604106903076, repeat = -2.5590381622314453, length = -0.12337242066860199, adv = 1.054995059967041, rougeL = 1.4009246826171875, cider = 0.18303215503692627, clip = 0.4033665657043457, crf = 0.12076060473918915, ce = 1.4204925298690796, unr = 1.733086347579956, ber = 5.637765407562256\n",
      "refe: [CLS] in this picture we can see the text and a few things on the black object. we can see wooden objects and other objects. [SEP]\n",
      "hypo: [CLS] in this image we can see there is a frame on the wall. [SEP]\n",
      "samp: [CLS] in this image we can see a wall and on the table. [SEP]\n",
      "lr con   : 1.6725440806045338e-11\n",
      "lr bert  : 2.206549118387909e-09\n",
      "lr cri   : 7.2544080604534e-06\n",
      "lr others: 5.863979848866498e-08\n",
      "Train epoch = 0.906801007556675, loss = 11.3419189453125, policy = 0.21637427806854248, entropy_loss = -0.0020513199269771576, gae = 9.504660606384277, kl_div = 0.0809573233127594, reward = 6.132803440093994, ord = 7.073862552642822, repeat = -2.551504373550415, length = -0.12396189570426941, adv = 1.050940990447998, rougeL = 1.4010449647903442, cider = 0.18407052755355835, clip = 0.40334776043891907, crf = 0.12094701826572418, ce = 1.4210309982299805, unr = 1.73440682888031, ber = 5.638334274291992\n",
      "refe: [CLS] here we can see a bird on a fence. on the left and right side we can see branches on a plant. in the background we can see the sky. [SEP]\n",
      "hypo: [CLS] in this image i can see a bird on it. on the background we can see some trees. [SEP]\n",
      "samp: [CLS] in this image we can see a bird on it. in the background we can see a wall. [SEP] sky. [SEP]\n",
      "lr con   : 9.75650713685978e-12\n",
      "lr bert  : 1.287153652392947e-09\n",
      "lr cri   : 4.231738035264483e-06\n",
      "lr others: 3.4206549118387904e-08\n",
      "Train epoch = 0.9445843828715366, loss = 11.326952934265137, policy = 0.21080847084522247, entropy_loss = -0.002045523840934038, gae = 9.4976224899292, kl_div = 0.08085047453641891, reward = 6.144371509552002, ord = 7.0752058029174805, repeat = -2.5435502529144287, length = -0.12330262362957001, adv = 1.0477526187896729, rougeL = 1.402491569519043, cider = 0.18277454376220703, clip = 0.4033602774143219, crf = 0.12084823846817017, ce = 1.4188671112060547, unr = 1.7360185384750366, ber = 5.639673709869385\n",
      "refe: [CLS] in the picture i can see golf ball, there is some grass, in the background of the picture i can see a person wearing green color t - shirt, white color cap standing and holding golf stick in his hands and there are some trees, flag, clear sky. [SEP]\n",
      "hypo: [CLS] in this image we can see a nets in the center of the ground, grass. [SEP] grass. [SEP]\n",
      "samp: [CLS] in this image i can see a tent, grass on the ground. at the right side of trees. [SEP]. [SEP] grass. [SEP]\n",
      "lr con   : 2.787573467674223e-12\n",
      "lr bert  : 3.677581863979849e-10\n",
      "lr cri   : 1.2090680100755668e-06\n",
      "lr others: 9.773299748110832e-09\n",
      "Train epoch = 0.982367758186398, loss = 11.317971229553223, policy = 0.2049289345741272, entropy_loss = -0.002041381783783436, gae = 9.49467945098877, kl_div = 0.08087286353111267, reward = 6.160073280334473, ord = 7.075231075286865, repeat = -2.5293352603912354, length = -0.12340887635946274, adv = 1.0458158254623413, rougeL = 1.4028555154800415, cider = 0.18232563138008118, clip = 0.4030734598636627, crf = 0.12090329080820084, ce = 1.4186269044876099, unr = 1.7375867366790771, ber = 5.6403679847717285\n",
      "refe: [CLS] on the right side, there is a person with a violet color t - shirt, holding dry leaves which are on a wooden pole. beside her, there is another wooden pole and this person is on a wooden object. in the background, there is a mountain. [SEP]\n",
      "hypo: [CLS] in this image, we can see a woman standing and she is holding the hand. in the background there are trees. [SEP]\n",
      "samp: [CLS] in this image, we can see a woman standing and she is holding an umbrellas and i can see an object. [SEP]\n",
      "bsz 56 is not batch_size 128. skip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 13:45:12,456] Trial 52 finished with value: 1.7342315912246704 and parameters: {'config.betas': 3, 'config.len_coef': 2.0962800684917156, 'config.unr_coef': 2.492827653909649, 'config.crf_coef': 0.07848304517579724, 'config.ce_coef': 0.688275676672358, 'config.gae_coef': 2.168931096180323, 'config.clip_range': 0.10465345698866436, 'clip_grad_threshold': 1.7276698340994059}. Best is trial 52 with value: 1.7342315912246704.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, avg_reward = 1.7342315912246704\n",
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.10000762471651962\n",
      "clip_grad_threshold gradient norm: 1.7408373637835932\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 1.9569801416155617\n",
      "unr_coef: 2.5608389701001877\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.019302521580622956\n",
      "ce_coef: 0.8035341258357066\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 1.6653248454553295\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_134526.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342c3cf58d0041e9b15ac40c684b7622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 7.034939289093018, policy = 4.854398838460838e-08, entropy_loss = -0.0027840312104672194, gae = 5.294511795043945, kl_div = 0.08748690783977509, reward = 3.9257919788360596, ord = 6.964080333709717, repeat = -4.473601818084717, length = -0.06524555385112762, adv = 0.9788718819618225, rougeL = 1.190148115158081, cider = 0.2466474026441574, clip = 0.40098097920417786, crf = 0.015075071714818478, ce = 1.6406493186950684, unr = 1.5005590915679932, ber = 5.669954299926758\n",
      "refe: [CLS] this image is taken outdoors. at the bottom of the image there is a ground with grass on it and there are a few trees. in the middle of the image there are many boats and ships. in the background there are many buildings and houses with walls, windows, doors, roofs, railings and balconies. at the top of the image there is a sky with clouds. [SEP]\n",
      "hypo: [CLS] in this image we can see water, we can see number of the water, there are trees. there are trees. [SEP] we can see the sky. [SEP]\n",
      "samp: [CLS] in the image there is a city, there is a grass and some trees. there are trees. there are trees. [SEP] we can see some trees. there are trees. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 13:45:44,221] Trial 53 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.10859025095460942\n",
      "clip_grad_threshold gradient norm: 2.400461907705771\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 1.0774751158545346\n",
      "unr_coef: 2.3758965773414404\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.06138398925209247\n",
      "ce_coef: 0.7110242176330194\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 2.2915448495288824\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_134556.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7284e4d6c04897b4173786e37d6109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 5.250416278839111, policy = 1.1675136413202836e-08, entropy_loss = -0.0028376637492328882, gae = 3.632753849029541, kl_div = 0.08179223537445068, reward = 3.7115070819854736, ord = 6.881249904632568, repeat = -4.491710662841797, length = -0.039544474333524704, adv = 0.37649309635162354, rougeL = 1.1854318380355835, cider = 0.22213877737522125, clip = 0.4063480496406555, crf = 0.04918140172958374, ce = 1.4895260334014893, unr = 1.3615124225616455, ber = 5.670616149902344\n",
      "refe: [CLS] in the image there are two people in the foreground, on the right side there is a woman, she is working with the laptop and beside the laptop there are some papers and there is a glass window beside the papers, on the left side there is a door and behind there is a brick wall. [SEP]\n",
      "hypo: [CLS] in this image there is a woman and a woman standing and spectacles, we can see the table we can see the table we can see the right side, we can see a wall. [SEP]\n",
      "samp: [CLS] in this image there are two women is a woman in the right side of them, we can see the left side of them we can see the left side, we can see a board. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 13:46:15,215] Trial 54 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.12031638935650682\n",
      "clip_grad_threshold gradient norm: 2.078668418043424\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 4.3052470993439576\n",
      "unr_coef: 2.1113187439968604\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.27251852953142686\n",
      "ce_coef: 0.558976928576177\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.839302888158197\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_134627.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01bd2691f14434ea9b2b618b8f2de8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 16.14815330505371, policy = -4.792950747400937e-08, entropy_loss = -0.002898474922403693, gae = 14.600142478942871, kl_div = 0.08077681064605713, reward = 3.4641215801239014, ord = 7.022343158721924, repeat = -4.597306728363037, length = -0.1934220939874649, adv = 1.0073822736740112, rougeL = 1.275817632675171, cider = 0.22451536357402802, clip = 0.40182191133499146, crf = 0.23943811655044556, ce = 1.2306941747665405, unr = 1.232507348060608, ber = 5.693851947784424\n",
      "refe: [CLS] in this picture i can see at the bottom there are trees, in the middle there is a bridge and there are buildings with lights, at the top there is the sky. [SEP]\n",
      "hypo: [CLS] in this picture we can see the road, we can see few vehicles on the road, trees. there are trees. there are trees. there are trees. on the sky. [SEP]\n",
      "samp: [CLS] in this picture we can see the road, there is a bridge and there are trees. on the middle of trees. there are trees. there are trees. on the sky. in the sky. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 13:46:45,662] Trial 55 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.10845755332957682\n",
      "clip_grad_threshold gradient norm: 1.314236633552266\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 1.5814124788652149\n",
      "unr_coef: 1.8115837988978725\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.12861629764263202\n",
      "ce_coef: 0.43324047991442727\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 2.9594004422541085\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_134658.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd08f13bc48148a4affe9105aecfcdcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 5.87204647064209, policy = 3.932677472562318e-08, entropy_loss = -0.002819659421220422, gae = 4.758362770080566, kl_div = 0.08762820810079575, reward = 3.709467887878418, ord = 7.005000591278076, repeat = -4.313444137573242, length = -0.06678201258182526, adv = 0.40546178817749023, rougeL = 1.1939290761947632, cider = 0.2096826732158661, clip = 0.4025244414806366, crf = 0.10486695915460587, ce = 0.9240078926086426, unr = 1.0846935510635376, ber = 5.659356117248535\n",
      "refe: [CLS] in this picture we can see the head of a dog on a colorful object. background is blurry. [SEP]\n",
      "hypo: [CLS] in this image there is a dog and sitting on the background there is a sofa. [SEP]\n",
      "samp: [CLS] in this image, we can see a dog is a sofa. on it is blurred. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 13:47:16,267] Trial 56 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.15151462315906072\n",
      "clip_grad_threshold gradient norm: 2.1740638774129346\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 4.562196051891338\n",
      "unr_coef: 4.38926827483186\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.39738852511156375\n",
      "ce_coef: 0.6751880046480382\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 2.0362309528832605\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_134728.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d814f122a340de8b4cae32e28f0dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 10.238092422485352, policy = -1.9048906452212577e-08, entropy_loss = -0.002887720474973321, gae = 8.415201187133789, kl_div = 0.08326773345470428, reward = 4.888350963592529, ord = 6.85443639755249, repeat = -4.395286560058594, length = -0.19223807752132416, adv = 1.074906826019287, rougeL = 1.178236722946167, cider = 0.25305306911468506, clip = 0.3989124000072479, crf = 0.31956571340560913, ce = 1.4229443073272705, unr = 2.6214394569396973, ber = 5.626006126403809\n",
      "refe: [CLS] in this image we can see an architecture which is in a pyramid shape with stairs. there is a building, cars, poles and trees in the background of the image. the sky is covered with the clouds. [SEP]\n",
      "hypo: [CLS] in this picture we can see dustbin the foreground of the road, there is a pole, we can see buildings, we can see the background we can see the sky. [SEP]\n",
      "samp: [CLS] in this picture we can see dustbin booth on the path, we can also there is a pole, we can see the background there is a pole, we can see the background we can see the sky. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 13:47:46,027] Trial 57 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.13704341795586322\n",
      "clip_grad_threshold gradient norm: 1.8681339775624792\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 3.0431590328281524\n",
      "unr_coef: 3.8562393859859796\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.31169817764394414\n",
      "ce_coef: 0.5057936820370961\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.076343186138645\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_134759.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c11e4ddbc4242c9a6e5e1c4f20b72a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 8.997291564941406, policy = 1.4747540078019483e-08, entropy_loss = -0.0027948732022196054, gae = 7.635260581970215, kl_div = 0.07847187668085098, reward = 4.396799087524414, ord = 6.870462894439697, repeat = -4.6518683433532715, length = -0.11396128684282303, adv = 0.4099670350551605, rougeL = 1.194705605506897, cider = 0.1879560649394989, clip = 0.4067286550998688, crf = 0.24709388613700867, ce = 1.0392602682113647, unr = 2.292166233062744, ber = 5.621432781219482\n",
      "refe: [CLS] this is an edited image, where there is a bridge, trees, lights, poles, water, buildings, statue of a dolphin, and in the background there is sky. [SEP]\n",
      "hypo: [CLS] in this image we can see the fountain in the foreground there is a statue the background there is a water, we can also there is a light poles, we can also there are buildings, we can see the sky. [SEP]\n",
      "samp: [CLS] in this picture we can see the fountain in the foreground there is a statue of the fountains. there is a water. [SEP] buildings, we can see the sky. there is a river. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 13:48:17,056] Trial 58 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.1666047058565046\n",
      "clip_grad_threshold gradient norm: 1.4834545903636525\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.818448198851327\n",
      "unr_coef: 3.5564086779813247\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.1789501538608531\n",
      "ce_coef: 0.4674661064413448\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 2.5332929551767878\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_134829.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6932b41d12ea4acfaf7c55c7def76fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 9.416644096374512, policy = 3.072404197723699e-08, entropy_loss = -0.0028307312168180943, gae = 8.21529483795166, kl_div = 0.08146370202302933, reward = 4.310496807098389, ord = 7.012440204620361, repeat = -4.636581897735596, length = -0.10346578061580658, adv = 1.027307391166687, rougeL = 1.1984529495239258, cider = 0.2789861857891083, clip = 0.405038058757782, crf = 0.14483942091464996, ce = 0.9778764843940735, unr = 2.038104295730591, ber = 5.666934967041016\n",
      "refe: [CLS] there is a plane which is in white color is flying in the air and the sky is blue in color. [SEP]\n",
      "hypo: [CLS] in this image we can see an airplane flying in the background we can see the background we can see [SEP]\n",
      "samp: [CLS] in this image we can see an airplane flying in the background we can see the background we can see [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 13:48:47,715] Trial 59 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.2631306475479517\n",
      "clip_grad_threshold gradient norm: 0.9313749581112375\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.1162837061585806\n",
      "unr_coef: 3.1187265364556\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.09400956733861582\n",
      "ce_coef: 0.044867184533795235\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 3.375669490213764\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_134859.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658ad7752f4b4da8ae5561920ea446f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 7.757046699523926, policy = -4.0862975225763876e-08, entropy_loss = -0.002688593463972211, gae = 7.516563892364502, kl_div = 0.08338702470064163, reward = 4.310384273529053, ord = 7.016834735870361, repeat = -4.507232666015625, length = -0.07025448232889175, adv = 0.7138423323631287, rougeL = 1.205645203590393, cider = 0.2902328670024872, clip = 0.40287476778030396, crf = 0.070501908659935, ce = 0.08928230404853821, unr = 1.8710365295410156, ber = 5.660953521728516\n",
      "refe: [CLS] in this image we can see a group of people standing on the ground. one woman is carrying a baby in her hands. in the background, we can a wall, a group of trees and the sky [SEP]\n",
      "hypo: [CLS] in this image, we can see few people walking on the left side of the background there are trees, we can see the background we can see trees. there are trees. there are trees. [SEP]\n",
      "samp: [CLS] in this picture we can see a woman is a girl who is a group of the image. there are trees and we can also there are trees. [SEP] persons are trees. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 13:49:17,900] Trial 60 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.1254590042850614\n",
      "clip_grad_threshold gradient norm: 1.602792665807704\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.401157237485807\n",
      "unr_coef: 3.358246250193058\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.0008229779626122563\n",
      "ce_coef: 0.6916880316584598\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 2.961662050912121\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_134930.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c58bc02a800447aa6ff3fe26d9e6cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 8.179841041564941, policy = 3.686885108322713e-08, entropy_loss = -0.0027015022933483124, gae = 6.695140361785889, kl_div = 0.08301959186792374, reward = 4.371208190917969, ord = 7.037822246551514, repeat = -4.560383319854736, length = -0.08165336400270462, adv = 0.6095748543739319, rougeL = 1.2555845975875854, cider = 0.2838684320449829, clip = 0.40264391899108887, crf = 0.000606275163590908, ce = 1.4037764072418213, unr = 1.9754226207733154, ber = 5.69580078125\n",
      "refe: [CLS] in the image there are two men, they are in lying position and the first man is holding a gun and behind him another man is watching. [SEP]\n",
      "hypo: [CLS] in this image we can see there are two people, we can see the right side of them there is wearing their hands. [SEP] bullets in the background i can see there is a person. [SEP]\n",
      "samp: [CLS] in this picture we can see two persons wearing clothes, we can see the right side of them are some otherets. [SEP] bullets in the right side there is a hand. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 13:49:48,937] Trial 61 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.1141368099325197\n",
      "clip_grad_threshold gradient norm: 1.746377557935115\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.5124947355058174\n",
      "unr_coef: 2.8731621572570694\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.07668216524729124\n",
      "ce_coef: 0.7747059119910772\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 4.387435365437453\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_135001.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277f3e885e9845dc9c35d3be45372845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 18.0797119140625, policy = 1.1060655502603822e-08, entropy_loss = -0.002747963648289442, gae = 16.320594787597656, kl_div = 0.08513949811458588, reward = 4.22084379196167, ord = 6.950573444366455, repeat = -4.361420631408691, length = -0.09612280875444412, adv = 1.1337932348251343, rougeL = 1.2155009508132935, cider = 0.19900915026664734, clip = 0.40717023611068726, crf = 0.06198456138372421, ce = 1.614740014076233, unr = 1.727813959121704, ber = 5.658764362335205\n",
      "refe: [CLS] in this image i can see there are three persons standing on the floor and in the background i can see the wall and notice papers attached to the wall. [SEP]\n",
      "hypo: [CLS] in this image there are three people standing and standing on the right side of the right side, we can see a wall. [SEP]\n",
      "samp: [CLS] in this picture we can see three men standing and among them there is attached to the left side of the right side of the left side of the wall. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 13:50:19,572] Trial 62 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in TopLayer:\n",
      "in TopLayer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use_saved_pth: True\n",
      "PATH: ../pre_train_crf/model/model_bert_large_NAR_PAD_sft2_curr.pth\n",
      "exist saved_pth: True\n",
      "model parameters were loaded\n",
      "ref_model parameters were loaded\n",
      "begin_epoch: 0\n",
      "global_step: 0\n",
      "file_param: 5\n",
      "train_param: 15\n",
      "val_param: 132\n",
      "epochs: 1\n",
      "batch_size: 128\n",
      "lr_clip: 0.0\n",
      "lr_con: 1.66e-10\n",
      "lr_bert: 2.19e-08\n",
      "lr_cri: 7.2e-05\n",
      "lr_others: 5.82e-07\n",
      "weight_decay: 0.0232\n",
      "betas: (0.9, 0.999)\n",
      "metric: special\n",
      "reward_type: ord+rep+len+unr\n",
      "decode_type: no-pad\n",
      "clip_range ppo clip: 0.1057921660782411\n",
      "clip_grad_threshold gradient norm: 1.4412673028902296\n",
      "ord_coef: 1.0\n",
      "cider_coef: 1.0\n",
      "rouge_coef: 2.53\n",
      "clip_coef: 1.65\n",
      "rep_coef: 5.84\n",
      "repeat_thresh: [3, 2, 2, 2]\n",
      "repeat_weight: [1, 1, 1, 1]\n",
      "len_coef: 2.608507215612119\n",
      "unr_coef: 4.1446067738816526\n",
      "policy_coef: 1.0\n",
      "crf_coef: 0.11965890953137681\n",
      "ce_coef: 0.649097104253217\n",
      "ent_coef: 0.00269\n",
      "gae_coef: 1.8126828181138055\n",
      "kl_coef: 0.0401\n",
      "target_kl: 8.0\n",
      "buffer_kl: 1.2\n",
      "kl_max: 0.1\n",
      "kl_min: 0.1\n",
      "gamma: 0.972\n",
      "lambda: 0.974\n",
      "use_repeat_logits_half: False\n",
      "use_ce_bert: True\n",
      "ratio_clamp_max: -1.0\n",
      "display_include_coef: True\n",
      "temp: 0.71\n",
      "train_loss_file: ./model/MyOriginal_train_loss_20260204_135032.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7078180b66294ca2a9dbbc2ffd0b28bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr con   : 4.1813602015113345e-12\n",
      "lr bert  : 5.516372795969773e-10\n",
      "lr cri   : 1.81360201511335e-06\n",
      "lr others: 1.4659949622166246e-08\n",
      "Train epoch = 0.0, loss = 7.828963756561279, policy = 8.602731860207768e-09, entropy_loss = -0.0027068115305155516, gae = 6.351612567901611, kl_div = 0.08016946166753769, reward = 5.1350789070129395, ord = 7.0033721923828125, repeat = -4.286397933959961, length = -0.09868061542510986, adv = 0.9504370093345642, rougeL = 1.2168482542037964, cider = 0.31180375814437866, clip = 0.40883326530456543, crf = 0.0908409133553505, ce = 1.3090475797653198, unr = 2.516785144805908, ber = 5.670896053314209\n",
      "refe: [CLS] in this picture i can see there are few people riding the bicycle. there is a bicycle lying on the grass. in the backdrop there are few people standing and few of them are sitting, there are few stairs in the backdrop and it looks like there is a building in the backdrop, there are few trees and the sky is clear. [SEP]\n",
      "hypo: [CLS] in this image we can see a group of people sitting on the ground. there are trees, we can see the background there are trees. there are trees. [SEP]\n",
      "samp: [CLS] in this image i can see a group of the road, there are sitting on the ground and we can see the background there are trees. there are trees and trees, trees. [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-02-04 13:50:49,533] Trial 63 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'config.betas': 3, 'config.len_coef': 2.0962800684917156, 'config.unr_coef': 2.492827653909649, 'config.crf_coef': 0.07848304517579724, 'config.ce_coef': 0.688275676672358, 'config.gae_coef': 2.168931096180323, 'config.clip_range': 0.10465345698866436, 'clip_grad_threshold': 1.7276698340994059}\n",
      "Best reward: 1.7342315912246704\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-8\n",
    "\n",
    "# --- 1. 疑似環境・モデルの定義 (実際の環境に合わせて差し替えてください) ---\n",
    "class SimpleEnv:\n",
    "    def reset(self): return np.random.rand(4)\n",
    "    def step(self, action): return np.random.rand(4), np.random.rand(), False, {}\n",
    "\n",
    "'''\n",
    "# --- 2. 損失関数と報酬を計算する関数 (ご質問の通り定義) ---\n",
    "#def calculate_loss_and_reward(model, state, action, target_policy, adv, old_log_prob, coefs):\n",
    "def calculate_loss_and_reward(model, state, action, target_policy, adv, old_log_prob, coefs):\n",
    "    # パラメータ調整用の係数\n",
    "    c_ent, c_kl, c_ce = coefs['ent'], coefs['kl'], coefs['ce']\n",
    "    \n",
    "    # 実際にはここにPPOのPolicy loss, Value lossなどを計算するロジックが入る\n",
    "    # 今回は例として疑似的なテンソルを返す\n",
    "    policy_loss = torch.tensor(0.5, requires_grad=True)\n",
    "    entropy_loss = torch.tensor(0.1, requires_grad=True)\n",
    "    kl_div = torch.tensor(0.01, requires_grad=True)\n",
    "    cross_entropy = torch.tensor(0.2, requires_grad=True)\n",
    "    \n",
    "    # 総合的な損失 (最小化したいもの)\n",
    "    # PPOはpolicy_lossを最小化し、entropyを最大化(減算)する\n",
    "    total_loss = policy_loss - c_ent * entropy_loss + c_kl * kl_div + c_ce * cross_entropy\n",
    "    \n",
    "    # 報酬の取得 (最大化したいもの)\n",
    "    avg_reward = 100.0 # 実際のエピソード報酬\n",
    "    \n",
    "    return total_loss, avg_reward\n",
    "'''\n",
    "\n",
    "# --- 3. Optunaの目的関数 (Objective) の定義 ---\n",
    "def objective(trial):\n",
    "    # 探索するハイパーパラメータの範囲を定義\n",
    "    #lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    #gamma = trial.suggest_float(\"gamma\", 0.9, 0.9999)\n",
    "    #gae_lambda = trial.suggest_float(\"gae_lambda\", 0.9, 1.0)\n",
    "    #ent_coef = trial.suggest_float(\"ent_coef\", 0.0, 0.1)\n",
    "    #kl_coef = trial.suggest_float(\"kl_coef\", 0.0, 0.5)\n",
    "    #ce_coef = trial.suggest_float(\"ce_coef\", 0.0, 0.5)\n",
    "    betas_cate = [(0.9, 0.999), ( 0.95, 0.999 ), (0.9, 0.9999), (0.95, 0.9999 ) ]\n",
    "    choice_index = trial.suggest_categorical(\"config.betas\", list(range(len(betas_cate))))\n",
    "    my_var = betas_cate[choice_index]\n",
    "    trial.set_user_attr(\"config.betas\", my_var)\n",
    "    config.len_coef = trial.suggest_float(\"config.len_coef\", 0.0, 5.0)\n",
    "    config.unr_coef = trial.suggest_float(\"config.unr_coef\", 0.0, 5.0)\n",
    "    config.crf_coef = trial.suggest_float(\"config.crf_coef\", 0.0, 1.0)\n",
    "    config.ce_coef = trial.suggest_float(\"config.ce_coef\", 0.0, 1.0)\n",
    "    config.gae_coef = trial.suggest_float(\"config.gae_coef\", 0.0, 5.0)\n",
    "    config.clip_range = trial.suggest_float(\"config.clip_range\", 0.1, 0.3 )\n",
    "    config.clip_grad_threshold = trial.suggest_float(\"clip_grad_threshold\", 0.1, 3 )\n",
    "    params = {\n",
    "        'config.betas': config.betas, 'config.len_coef': config.len_coef, 'config.unr_coef': config.unr_coef,\n",
    "        'config.crf_coef': config.crf_coef, 'config.ce_coef': config.ce_coef, 'config.gae_coef': config.gae_coef, \n",
    "        'config.clip_range': config.clip_range, 'config.clip_grad_threshold': config.clip_grad_threshold,\n",
    "    }\n",
    "    \n",
    "    '''\n",
    "    config.gamma = trial.suggest_float(\"config.gamma\", 0.9, 0.9999)\n",
    "    config.lam = trial.suggest_float(\"config.lam\", 0.9, 1.0)\n",
    "    config.cider_coef = trial.suggest_float(\"config.ent_cider\", 0.0, 5.0)\n",
    "    config.rouge_coef = trial.suggest_float(\"config.rouge_coef\", 0.0, 5.0)\n",
    "    config.clip_coef = trial.suggest_float(\"config.clip_coef\", 0.0, 5.0)\n",
    "    config.policy_coef = trial.suggest_float(\"config.policy_coef\", 0.0, 2.0)\n",
    "    config.ent_coef = trial.suggest_float(\"config.ent_coef\", 0.0, 0.2)\n",
    "    config.gae_coef = trial.suggest_float(\"config.gae_coef\", 0.0, 0.5)\n",
    "    config.kl_coef = trial.suggest_float(\"config.kl_coef\", 0.0, 0.1)\n",
    "    config.ce_coef = trial.suggest_float(\"config.ce_coef\", 0.0, 0.5)\n",
    "    config.crf_coef = trial.suggest_float(\"config.crf_coef\", 0.0, 0.5)\n",
    "    config.temp = trial.suggest_float(\"config.temp\", 0.7, 1.3 )\n",
    "    '''\n",
    "    #config.lr_bert = trial.suggest_float(\"config.lr_bert\", 1e-9, 1e-6, log=True)\n",
    "    #config.lr_con = trial.suggest_float(\"config.lr_con\", 1e-9, 1e-6, log=True)\n",
    "    #config.lr_others = trial.suggest_float(\"config.lr_others\", 1e-9, 1e-5, log=True)\n",
    "    #config.cider_coef = trial.suggest_float(\"config.cider_coef\", 0.1, 5)\n",
    "    #config.clip_coef = trial.suggest_float(\"config.clip_coef\", 0.1, 5)\n",
    "    #config.bert_coef = trial.suggest_float(\"config.bert_coef\", 0.1, 5)\n",
    "    #config.temp = trial.suggest_float(\"config.temp\", 0.7, 1.5)\n",
    "    #config.lam = trial.suggest_float(\"config.lam\", 0.9, 1.0)\n",
    "    \n",
    "    # パラメータセット\n",
    "    #params = {\n",
    "    #    'config.lr_bert': config.lr_bert, 'config.lr_con': config.lr_con, 'config.lr_others': config.lr_otehrs, \n",
    "    #    'config.lr_cri': config.lr_cri, 'config.cider': config.cider, 'congif.rouge': config.rouge, 'config.temp': config.temp,\n",
    "    #    'config.gamma': config.gamma, 'config.lam': config.lam, 'config.policy': config.policy, 'config.gae': config.gae,\n",
    "    #    'config.ent_coef': config.ent_coef, 'config.kl_coef': config.kl_coef, 'config.ce_coef': config.ce_coef, \n",
    "    #    'config.crf_coef': config.crf_coef, 'config.clip_coef': config.clip_coef \n",
    "    #}\n",
    "\n",
    "\n",
    "    # モデルの定義\n",
    "    model = CaptioningTransformer( config.img_size,\n",
    "        config.dim_embedding, config.length_max, config.vocab_size,\n",
    "        tokenizer, config.dropout, pad_token_id = tokenizer.pad_token_id,\n",
    "        use_repeat_logits_half = config.use_repeat_logits_half,\n",
    "        crf_coef = config.crf_coef, temp=config.temp )\n",
    "    model.to(config.device)\n",
    "    \n",
    "    ref_model = CaptioningTransformer( config.img_size,\n",
    "        config.dim_embedding, config.length_max, config.vocab_size,\n",
    "        tokenizer, config.dropout, pad_token_id = tokenizer.pad_token_id,\n",
    "        use_repeat_logits_half = config.use_repeat_logits_half,\n",
    "        crf_coef = config.crf_coef, temp=1.0 )\n",
    "    ref_model.to(config.device)\n",
    "    \n",
    "    compute_reward = ComputeReward( reward_t = config.reward_t, decode_t = config.decode_t, device = config.device, \n",
    "                                    sentence_level_metric=config.metric, repeat_thresh = config.repeat_thresh, \n",
    "                                    repeat_weight = config.repeat_weight, cider_coef = config.cider_coef, \n",
    "                                    rouge_coef = config.rouge_coef, clip_coef = config.clip_coef, bert_coef = config.bert_coef,\n",
    "                                    use_amp = config.use_amp )\n",
    "\n",
    "    \n",
    "    # 最適化手法の定義\n",
    "    # Optimizerの生成, clipとそうでないモジュールとの\n",
    "    # パラメータで異なる学習率を適用\n",
    "    #params_clip = []\n",
    "    params_con = []\n",
    "    params_bert = []\n",
    "    params_others = []\n",
    "    params_cri = []\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if parameter.requires_grad:\n",
    "            if 'clip_model' in name:\n",
    "                #params_clip.append(parameter)\n",
    "                parameter.requires_grad = False\n",
    "            elif 'connector' in name:\n",
    "                params_con.append(parameter)\n",
    "            elif 'bert' in name and 'critical' not in name:\n",
    "                params_bert.append(parameter)\n",
    "            elif 'critical' in name:\n",
    "                params_cri.append(parameter)\n",
    "            else:\n",
    "                params_others.append(parameter)\n",
    "    param_groups = [\n",
    "        #{'params': params_clip, 'lr': config.lr_clip},\n",
    "        {'params': params_con, 'lr': config.lr_con},\n",
    "        {'params': params_bert, 'lr': config.lr_bert},\n",
    "        {'params': params_cri, 'lr': config.lr_cri},\n",
    "        {'params': params_others, 'lr': config.lr_others}]\n",
    "    #optimizer = torch.optim.AdamW( model.parameters() , lr=config.lr)\n",
    "    #optimizer = torch.optim.AdamW( param_groups, weight_decay = config.weight_decay, betas=config.betas )\n",
    "    optimizer = torch.optim.AdamW( param_groups, weight_decay = config.weight_decay, betas=config.betas )\n",
    "    #t_optimizer = torch.optim.AdamW( toplayer.parameters(), lr = config.lr_top, weight_decay = config.weight_decay, betas=config.betas )\n",
    "    thresh_groups = {\n",
    "    #    'clip': config.clip_thresh_clip,\n",
    "        'con': config.clip_thresh_con,\n",
    "        'bert': config.clip_thresh_bert,\n",
    "        'cri': config.clip_thresh_cri,\n",
    "        'others':config.clip_thresh_others\n",
    "    }\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup( optimizer, num_warmup_steps, num_global_steps )   \n",
    "\n",
    "    print( \"use_saved_pth:\", config.use_saved_pth )\n",
    "    print( \"PATH:\", config.PATH )\n",
    "    print( \"exist saved_pth:\", os.path.isfile(config.PATH) ) \n",
    "    use_saved_pth = config.use_saved_pth\n",
    "    if use_saved_pth and os.path.isfile(config.PATH):\n",
    "        checkpoint = torch.load(config.PATH, map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(checkpoint['model_state_dict'], strict = False)\n",
    "        print( \"model parameters were loaded\")\n",
    "        ref_model.load_state_dict(checkpoint['model_state_dict'], strict = False)\n",
    "        ref_model.eval() # 必須：DropoutやBatchNormを無効化\n",
    "        for param in ref_model.parameters():\n",
    "            param.requires_grad = False # 必須：メモリ節約と誤学習防止\n",
    "        ref_model = ref_model.to(config.device )\n",
    "        print( \"ref_model parameters were loaded\")\n",
    "\n",
    "        #optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        #scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        #device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        ## optimizerのstateを現在のdeviceに移す。これをしないと、保存前後でdeviceの不整合が起こる可能性がある。\n",
    "        #for state in optimizer.state.values():\n",
    "            #for k, v in state.items():\n",
    "                #if isinstance(v, torch.Tensor):\n",
    "                    #state[k] = v.to(device)\n",
    "        #begin_epoch = checkpoint['epoch']\n",
    "        #loss = checkpoint['loss']\n",
    "        #global_step = checkpoint['global_step']    \n",
    "        begin_epoch = 0\n",
    "        global_step = 0\n",
    "    else:\n",
    "        begin_epoch = 0\n",
    "        global_step = 0\n",
    "\n",
    "    file_param = 5\n",
    "    print( \"begin_epoch:\", begin_epoch )\n",
    "    print( \"global_step:\", global_step )\n",
    "    print( \"file_param:\", file_param )\n",
    "\n",
    "    len_tr_loader = len( train_loader )\n",
    "    train_param = len_tr_loader // 30\n",
    "    train_param = get_nearest_multiple( train_param, file_param )\n",
    "    #train_param = len_tr_loader // 10\n",
    "    len_val_loader = len( val_loader )\n",
    "    #train_param = len_val_loader // 3\n",
    "    val_param = len_val_loader // 3\n",
    "    print( \"train_param:\", train_param )\n",
    "    print( \"val_param:\", val_param )\n",
    "    \n",
    "    print( \"epochs:\", config.num_epochs )\n",
    "    print( \"batch_size:\", config.batch_size )\n",
    "    print( \"lr_clip:\", config.lr_clip )\n",
    "    print( \"lr_con:\", config.lr_con )\n",
    "    print( \"lr_bert:\", config.lr_bert )\n",
    "    print( \"lr_cri:\", config.lr_cri )\n",
    "    print( \"lr_others:\", config.lr_others )\n",
    "    #print( \"clip_grad_threshold:\", config.clip_grad_threshold ) \n",
    "    if config.clip_grad_threshold == 0.0:\n",
    "        print( 'clip_thresh_con:', config.clip_thresh_con )\n",
    "        print( 'clip_thresh_bert:', config.clip_thresh_bert )\n",
    "        print( 'clip_thresh_cri:', config.clip_thresh_cri )\n",
    "        print( 'clip_thresh_others:',config.clip_thresh_others )\n",
    "    print( \"weight_decay:\", config.weight_decay )\n",
    "    print( \"betas:\", config.betas )\n",
    "    print( \"metric:\", config.metric )\n",
    "    print( \"reward_type:\", config.reward_t )\n",
    "    print( \"decode_type:\", config.decode_t )\n",
    "    print( \"clip_range ppo clip:\", config.clip_range )\n",
    "    print( \"clip_grad_threshold gradient norm:\", config.clip_grad_threshold)\n",
    "    print( \"ord_coef:\", config.ord_coef )\n",
    "    print( \"cider_coef:\", config.cider_coef )\n",
    "    print( \"rouge_coef:\", config.rouge_coef )\n",
    "    print( \"clip_coef:\", config.clip_coef )\n",
    "    print( \"rep_coef:\", config.rep_coef )\n",
    "    print( \"repeat_thresh:\", config.repeat_thresh )\n",
    "    print( \"repeat_weight:\", config.repeat_weight )\n",
    "    print( \"len_coef:\", config.len_coef )\n",
    "    print( \"unr_coef:\", config.unr_coef )\n",
    "    print( \"policy_coef:\", config.policy_coef )\n",
    "    print( \"crf_coef:\", config.crf_coef )\n",
    "    print( \"ce_coef:\", config.ce_coef )\n",
    "    print( \"ent_coef:\", config.ent_coef )\n",
    "    #print( \"cri_coef:\", config.cri_coef )\n",
    "    print( \"gae_coef:\", config.gae_coef )\n",
    "    print( \"kl_coef:\", config.kl_coef )\n",
    "    print( \"target_kl:\", config.target_kl )\n",
    "    print( \"buffer_kl:\", config.buffer_kl )\n",
    "    print( \"kl_max:\", config.kl_max )\n",
    "    print( \"kl_min:\", config.kl_min )\n",
    "    print( \"gamma:\", config.gamma )\n",
    "    print( \"lambda:\", config.lam )\n",
    "    print( \"use_repeat_logits_half:\", config.use_repeat_logits_half )\n",
    "    print( \"use_ce_bert:\", config.use_ce_bert )\n",
    "    print( \"ratio_clamp_max:\", config.ratio_clamp_max )\n",
    "    print( \"display_include_coef:\", config.display_include_coef )\n",
    "    print( \"temp:\", config.temp )\n",
    "\n",
    "    \n",
    "    # 学習経過の書き込み\n",
    "    now = datetime.datetime.now()\n",
    "    train_loss_file = '{}/MyOriginal_train_loss_{}.csv'\\\n",
    "        .format(config.save_directory, now.strftime('%Y%m%d_%H%M%S'))\n",
    "    with open(train_loss_file, 'a') as f:\n",
    "        print(f'{len_tr_loader}', file=f) \n",
    "    print( \"train_loss_file:\", train_loss_file )\n",
    "    val_loss_file = '{}/MyOriginal_val_loss_{}.csv'\\\n",
    "        .format(config.save_directory, now.strftime('%Y%m%d_%H%M%S'))\n",
    "    with open(val_loss_file, 'a') as f:\n",
    "        print(f'{len_val_loader}', file=f) \n",
    "    norm_file = '{}/norm_{}.csv'\\\n",
    "        .format(config.save_directory, now.strftime('%Y%m%d_%H%M%S'))\n",
    "    \n",
    "    # 学習\n",
    "    val_loss_best = float('inf')\n",
    "    \n",
    "    #fn = bleu_score.SmoothingFunction().method7\n",
    "    #bleu_func = BLEU(effective_order=\"True\")\n",
    "    pad_token_id = tokenizer.pad_token_id\n",
    "    \n",
    "    # AMP用のスケーラー\n",
    "    scaler = GradScaler(enabled=config.use_amp)\n",
    "    \n",
    "    #torch.autograd.set_detect_anomaly(True)\n",
    "    \n",
    "    eps = 1e-8\n",
    "    last_sample_log_probs = 0\n",
    "    model_name = \"distilbert-base-uncased\"\n",
    "    \n",
    "    # 訓練ループ (簡略化)\n",
    "    for epoch in range(config.num_epochs): \n",
    "        # 1. サンプリング・モデル更新\n",
    "        # ... (PPOのデータ収集と学習ステップ) ...\n",
    "        \n",
    "        #avg_reward, global_step, last_sample_log_probs = do_one_epoch( epoch, global_step, model, optimizer, scheduler, \n",
    "        #                         train_loss_file, val_loss_file, norm_file, val_loss_best, bleu_func, pad_token_id, scaler, \n",
    "        #                         eps, train_param, len_tr_loader, last_sample_log_probs, trial )\n",
    "        #\n",
    "    \n",
    "        eps = 1e-8\n",
    "        \n",
    "        with tqdm(train_loader) as pbar:\n",
    "        #with tqdm(val_loader) as pbar:\n",
    "            pbar.set_description(f'[エポック {epoch + 1}]')\n",
    "    \n",
    "            # 学習モードに設定\n",
    "            model.train()\n",
    "    \n",
    "            train_losses = deque()\n",
    "            train_policys = deque()\n",
    "            train_entropies = deque()\n",
    "            train_critics = deque()\n",
    "            train_kl_divs = deque()\n",
    "            train_rewards = deque()\n",
    "            train_rewards2 = deque()\n",
    "            train_ord = deque()\n",
    "            train_repeat = deque()\n",
    "            train_length = deque()\n",
    "            train_adv = deque()\n",
    "            train_errors = deque()\n",
    "            train_bleus = deque()\n",
    "            train_crfs = deque()\n",
    "            train_ces = deque()\n",
    "            train_clips = deque()\n",
    "            train_unrs = deque()\n",
    "            train_berts = deque()\n",
    "            for n_batch, (imgs, imgs2, captions, caption_lengths) in enumerate( pbar ):\n",
    "                #start_time0 = time.time()\n",
    "                #print( \"  captions[0]:\", captions[0] )\n",
    "                # ミニバッチを設定\n",
    "                imgs = imgs.to(config.device)\n",
    "                imgs2 = imgs2.to(config.device)\n",
    "                captions = captions.to(config.device)\n",
    "    \n",
    "                if imgs.size(0) != config.batch_size:\n",
    "                    print( f\"bsz {imgs.size(0)} is not batch_size {config.batch_size}. skip\")\n",
    "                    continue\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # 最後の単語から次を予測する必要はないため最後の単語を除外\n",
    "                with autocast(str(config.device),enabled=config.use_amp):\n",
    "                    #start_time = time.time()                    \n",
    "                    finalized_scores, finalized_tokens, top_probs, top_indices, \\\n",
    "                    critical_value, crf_loss, bert_logits, sampled_beam_idx  = \\\n",
    "                    model( imgs, captions, top_indices = None )\n",
    "                    #end_time = time.time()\n",
    "                    #print( \"model time:\", end_time - start_time )\n",
    "                    bsz, seq_len, beam = top_probs.size()\n",
    "                    if config.use_ce_bert == False:\n",
    "                        ce_tensor = torch.full((bsz, seq_len, vocab_size), float(eps), device=config.device)\n",
    "                        ce_tensor = torch.scatter( ce_tensor, 2, top_indices, top_probs )\n",
    "                        ce_tensor = torch.clamp( ce_tensor, eps )\n",
    "                        log_ce_tensor = torch.log( ce_tensor )\n",
    "                    hypo_ids = finalized_tokens\n",
    "                    #start_time = time.time()\n",
    "                    reward_ord, reward_ord2, reward_repeat, reward_length, reward_unr, preds, sample_log_probs \\\n",
    "                    = compute_reward( top_probs, sampled_beam_idx, top_indices, captions, imgs2 )\n",
    "                    #end_time = time.time()\n",
    "                    #print( \"reward time:\", end_time - start_time )\n",
    "                    with torch.no_grad():\n",
    "                        #if config.use_inference == True:\n",
    "                        #    _, ref_captions, _, _, _, _ = model.inference( imgs )\n",
    "                        #else:\n",
    "                        #    ref_probs = F.softmax( logits, dim = 2 )\n",
    "                        #    ref_captions = torch.multinomial( ref_probs.view( bsz * seq_len, -1 ), num_samples = 1 ).view( bsz, seq_len )\n",
    "                        #ref_logits, _ = ref_model( imgs )\n",
    "                        #ref_top_logits = torch.gather( ref_logits, -1, top_indices )\n",
    "                        #_, ref_top_probs, _ = model.toplayer( ref_logits, ref_top_logits, top_indices, \\\n",
    "                        #                                                   ref_top_logits, ref_captions, is_training = True )\n",
    "                        ref_captions = preds\n",
    "                        _, _, ref_top_probs, _, _, _, _, _ = ref_model( imgs, ref_captions, top_indices = top_indices )\n",
    "                    \n",
    "                    # 1. Policy側の対数確率（学習対象）\n",
    "                    tmp = torch.clamp( top_probs, min = eps )\n",
    "                    top_log_probs = torch.log( tmp )\n",
    "                    policy_lp = torch.gather(top_log_probs, -1, sampled_beam_idx).squeeze(-1) # lp は log_prob の略と思われる。 bsz * seq_len\n",
    "                    \n",
    "                    # 2. Reference側の対数確率（固定）\n",
    "                    tmp = torch.clamp( ref_top_probs, min = eps )\n",
    "                    ref_top_log_probs = torch.log(tmp)\n",
    "                    ref_lp = torch.gather(ref_top_log_probs, -1, sampled_beam_idx).squeeze(-1)\n",
    "                    \n",
    "                    if config.decode_t == \"no-pad\":\n",
    "                        lengths = []\n",
    "                        for pred in preds:\n",
    "                            length = my_index( pred.tolist(), eos_token_id )\n",
    "                            if length != -1:\n",
    "                                lengths.append( length )\n",
    "                            else:\n",
    "                                lengths.append( 0 )\n",
    "                        lengths = torch.tensor( lengths, device = config.device )[:,None].expand( -1, preds.size(1) )\n",
    "            \n",
    "                        arange1 = torch.arange( 0, preds.size(1), device = config.device )\n",
    "                        arange1 = arange1[None,:].expand( preds.size(0), -1 )\n",
    "                        \n",
    "                        masks = arange1 < ( lengths + 2 )\n",
    "                    \n",
    "                        kl_divs = ( policy_lp - ref_lp ) * masks.float()\n",
    "                    else:\n",
    "                        kl_divs = policy_lp - ref_lp \n",
    "                    \n",
    "                    rewards = config.ord_coef * reward_ord + config.rep_coef * reward_repeat + config.len_coef * reward_length \\\n",
    "                        + config.unr_coef * reward_unr\n",
    "                    rewards2 = reward_ord2 + reward_repeat + reward_length + reward_unr\n",
    "                    \n",
    "                    if global_step == 0:\n",
    "                        last_sample_log_probs = sample_log_probs.detach()\n",
    "            \n",
    "                    ratio = torch.exp(sample_log_probs - last_sample_log_probs[:sample_log_probs.size(0)]) # bsz * seq_len\n",
    "                    rewards_t = torch.zeros( ( bsz, seq_len ) , device = config.device, dtype = torch.float)\n",
    "                    rewards_t[:,-1] = rewards[:,0]\n",
    "                    values = critical_value\n",
    "                    zeros = torch.zeros((values.size(0), 1), device=values.device, dtype=torch.float)\n",
    "                    values_cat = torch.cat((values, zeros), dim=1)\n",
    "                    advantages = generalized_advantage_estimation(rewards_t, values_cat, gamma=config.gamma, lam=config.lam)\n",
    "                    advantages_norm = (advantages - advantages.mean()) / (advantages.std() + eps) # bsz * seq_len\n",
    "            \n",
    "                    if config.ratio_clamp_max == -1.0:\n",
    "\n",
    "                        # clipped surrogate loss\n",
    "                        policy_loss_1 = - advantages_norm * ratio\n",
    "                        policy_loss_2 = - advantages_norm * torch.clamp(ratio, 1 - config.clip_range, 1 + config.clip_range)\n",
    "                    \n",
    "                        policy_loss = - torch.min(policy_loss_1, policy_loss_2).mean() # bsz * seq_len の平均\n",
    "                    \n",
    "                    elif config.ratio_clamp_max != 0.0:                \n",
    "            \n",
    "                        ratio = torch.clamp( ratio , min = 0.0, max = config.ratio_clamp_max )\n",
    "                    \n",
    "                        # clipped surrogate loss\n",
    "                        policy_loss_1 = - advantages_norm * ratio\n",
    "                        policy_loss_2 = - advantages_norm * torch.clamp(ratio, 1 - config.clip_range, 1 + config.clip_range)\n",
    "                    \n",
    "                        #policy_loss = - torch.min(policy_loss_1, policy_loss_2).mean() # bsz * seq_len の平均\n",
    "                        if config.decode_t == \"no-pad\":\n",
    "                            policy_loss = ( torch.min( policy_loss_1, policy_loss_2) )\n",
    "                            policy_loss = policy_loss.sum() / bsz / masks.float().sum()\n",
    "                        else:\n",
    "                            policy_loss = ( torch.min( policy_loss_1, policy_loss_2))\n",
    "                            policy_loss = policy_loss.sum() / bsz / seq_len\n",
    "                    else:\n",
    "                        mul_minus = ( advantages_norm > 0.0 ).float() * 2.0 - 1.0 \n",
    "                    \n",
    "                        # clipped surrogate loss\n",
    "                        policy_loss_1 = - advantages_norm * ratio\n",
    "                        policy_loss_2 = - advantages_norm * torch.clamp(ratio, 1 - config.clip_range, 1 + config.clip_range)\n",
    "                    \n",
    "                        if config.decode_t == \"no-pad\":\n",
    "                            policy_loss_before = ( torch.min( torch.abs(policy_loss_1), torch.abs( policy_loss_2)) )\n",
    "                            policy_loss = ( policy_loss_before * mul_minus ).sum() / bsz / masks.float().sum()\n",
    "                        else:\n",
    "                            policy_loss_before = ( torch.min(torch.abs(policy_loss_1), torch.abs(policy_loss_2)))\n",
    "                            policy_loss = (policy_loss_before * mul_minus).sum() / bsz / seq_len\n",
    "            \n",
    "                    entropy = entropy_func(top_probs)\n",
    "                    entropy_loss = - torch.mean(entropy)\n",
    "            \n",
    "                    targets = (values + advantages).detach()\n",
    "                    gae_loss = nn.MSELoss()( targets, values )\n",
    "            \n",
    "                    kl_per_sample = torch.sum(kl_divs, dim=1) / (torch.sum(masks, dim=1) + 1e-8)\n",
    "                    kl_div_loss = torch.mean(kl_per_sample)\n",
    "                    if config.use_adaptive_KL:\n",
    "                        if n_batch % 100 == 0:\n",
    "                            if kl_div_loss < config.target_kl / config.buffer_kl:\n",
    "                                print(f\"kl_coef:\", config.kl_coef )\n",
    "                                print(f\"Update kl_coef (low KL): {config.kl_coef} -> {config.kl_coef / 2.0}\")\n",
    "                                config.kl_coef = max(config.kl_coef / 2.0, config.kl_min) # 下限 0.05\n",
    "                                print(f\"kl_coef:\", config.kl_coef )\n",
    "                            elif kl_div_loss > config.target_kl * config.buffer_kl:\n",
    "                                print(f\"kl_coef:\", config.kl_coef )\n",
    "                                print(f\"Update kl_coef (high KL): {config.kl_coef} -> {config.kl_coef * 2.0}\")\n",
    "                                config.kl_coef = min(config.kl_coef * 2.0, config.kl_max)  # 上限 5.0\n",
    "                                print(f\"kl_coef:\", config.kl_coef )\n",
    "                    \n",
    "                    loss =  config.policy_coef * policy_loss \\\n",
    "                        + config.ent_coef * entropy_loss + config.gae_coef * gae_loss + config.kl_coef * kl_div_loss\n",
    "                    if config.crf_coef != 0.0:\n",
    "                        loss =  loss + config.crf_coef * crf_loss\n",
    "                    if config.ce_coef != 0.0:\n",
    "                        if config.use_ce_bert:\n",
    "                            ce_loss = nn.CrossEntropyLoss()( bert_logits.transpose(1,2), captions )\n",
    "                        else:\n",
    "                            ce_loss = nn.NLLLoss()( log_ce_tensor.view( bsz * seq_len, -1 ), captions.view( bsz * seq_len ) )\n",
    "                        loss =  loss + config.ce_coef * ce_loss\n",
    "                   \n",
    "                with torch.no_grad():\n",
    "                    last_sample_log_probs = sample_log_probs.detach()\n",
    "\n",
    "                #start_time = time.time()\n",
    "                scaler.scale(loss).backward()\n",
    "                #end_time = time.time()\n",
    "                #print( \"backward time:\", end_time - start_time )\n",
    "                # batch 内の平均\n",
    "                loss_item = loss.item()\n",
    "                reward_item = rewards.mean().item()\n",
    "                reward2_item = rewards2.mean().item()\n",
    "                adv_item = advantages.mean().item()\n",
    "                if config.display_include_coef:\n",
    "                    policy_item = config.policy_coef * policy_loss.item()\n",
    "                    entropy_item = config.ent_coef * entropy_loss.item()\n",
    "                    critic_item = config.gae_coef * gae_loss.item()\n",
    "                    #critic_item = 0\n",
    "                    kl_div_item = config.kl_coef * kl_div_loss.item()\n",
    "                    ord_item = config.ord_coef * reward_ord.mean().item()\n",
    "                    repeat_item = config.rep_coef * reward_repeat.mean().item()\n",
    "                    length_item = config.len_coef * reward_length.mean().item()\n",
    "                    if config.crf_coef != 0.0:\n",
    "                        crf_item = config.crf_coef * crf_loss.mean().item()\n",
    "                    else:\n",
    "                        crf_item = 0.0\n",
    "                    if config.ce_coef != 0.0:\n",
    "                        ce_item = config.ce_coef * ce_loss.mean().item()\n",
    "                    else:\n",
    "                        ce_item = 0.0\n",
    "                    unr_item = config.unr_coef * reward_unr.mean().item()\n",
    "                else:\n",
    "                    policy_item = policy_loss.item()\n",
    "                    entropy_item = entropy_loss.item()\n",
    "                    critic_item = gae_loss.item()\n",
    "                    #critic_item = 0\n",
    "                    kl_div_item = kl_div_loss.item()\n",
    "                    ord_item = reward_ord.mean().item()\n",
    "                    repeat_item = reward_repeat.mean().item()\n",
    "                    length_item = reward_length.mean().item()\n",
    "                    if config.crf_coef != 0.0:\n",
    "                        crf_item = crf_loss.mean().item()\n",
    "                    else:\n",
    "                        crf_item = 0.0\n",
    "                    if config.ce_coef != 0.0:\n",
    "                        ce_item = ce_loss.mean().item()\n",
    "                    else:\n",
    "                        ce_item = 0.0\n",
    "                    unr_item = reward_unr.mean().item()\n",
    "                del loss, rewards, reward_ord, reward_repeat, reward_length\n",
    "                del policy_loss, policy_loss_1, policy_loss_2, entropy_loss, kl_div_loss\n",
    "                del sample_log_probs, advantages, ratio\n",
    "                #del logits, ref_logits, top_logits, ref_top_logits, preds, top_indices\n",
    "                del finalized_scores, finalized_tokens\n",
    "                #del ref_probs, ref_captions, tmp, policy_lp, ref_lp\n",
    "                del kl_divs, masks, kl_per_sample\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                #start_time = time.time()\n",
    "                scaler.unscale_(optimizer)\n",
    "                if config.clip_grad_threshold != 0.0:\n",
    "                    torch.nn.utils.clip_grad_norm_(\\\n",
    "                       model.parameters(),\n",
    "                       config.clip_grad_threshold)\n",
    "                else:\n",
    "                    custom_gradient_clipping(\n",
    "                        #params_clip, \n",
    "                        params_con, \n",
    "                        params_bert,\n",
    "                        params_cri,\n",
    "                        params_others,\n",
    "                        #thresh_groups['clip'], \n",
    "                        thresh_groups['con'], \n",
    "                        thresh_groups['bert'], \n",
    "                        thresh_groups['cri'], \n",
    "                        thresh_groups['others'], \n",
    "                    )\n",
    "                \n",
    "            \n",
    "                # オプティマイザにより，パラメータを更新する\n",
    "                #for i, ( name, param ) in enumerate(model.named_parameters()):\n",
    "                #    #params.grad = grad[i]\n",
    "                #    print( \"parameter name:\", name )\n",
    "                #norm0 = torch.sqrt( torch.norm( model.clip_model.vision_model.encoder.layers[0].self_attn.q_proj.weight.grad, p = 2 ) ).item()\n",
    "                #norm1 = torch.sqrt( torch.norm( model.clip_model.vision_model.encoder.layers[12].self_attn.q_proj.weight.grad, p = 2 ) ).item()\n",
    "                norm0 = torch.norm( model.ln_critical.weight.grad, p = 2 ).item()\n",
    "                norm1 = torch.norm( model.linear_critical.weight.grad, p = 2 ).item()\n",
    "                norm2 = torch.norm( model.bert.encoder.layer[0].attention.self.query.weight.grad, p = 2 ).item()\n",
    "                norm3 = torch.norm( model.bert.encoder.layer[23].attention.self.query.weight.grad, p = 2 ).item()\n",
    "                mean_norm = torch.mean( torch.stack ([  torch.norm( param.grad, p = 2 ) \\\n",
    "                                                      for param in model.parameters() if param.grad is not None ] ) ).item()\n",
    "                #total_norm = torch.nn.utils.clip_grad_norm_(params_bert, thresh_groups['bert']).item()\n",
    "                #print( norm0, norm1, norm2, norm3, norm_mean )\n",
    "                with open(norm_file, 'a') as f:\n",
    "                    print( \"epcoch:\", epoch, \", step:\", global_step, \", norm0:\", norm0, \", norm1:\", norm1, \", norm2:\", norm2, \\\n",
    "                           \", norm3:\", norm3, \", mean_norm:\", mean_norm, file=f  )\n",
    "                    f.flush()\n",
    "            \n",
    "                #optimizer.step()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()            \n",
    "                scheduler.step()\n",
    "                #end_time = time.time()\n",
    "                #print( \"step time:\", end_time - start_time )\n",
    "                \n",
    "                if global_step % file_param == 0:                \n",
    "                    #start_time = time.time()\n",
    "                    hypo_sentence1 = []\n",
    "                    ref_sentence1 = []\n",
    "                    if config.metric == 'cider' or config.metric == 'special':\n",
    "                        if config.decode_t == 'no-endoftext':\n",
    "                            preds_str = [tokenizer.decode(\n",
    "                                [pred[i] for i in range( 1, len( pred )  ) if not (pred[i-1] == endoftext_token_id and pred[i] == endoftext_token_id) ]\n",
    "                                ) for pred in hypo_ids]\n",
    "                            samps_str = [tokenizer.decode(\n",
    "                                [pred[i] for i in range( 1, len( pred )  ) if not (pred[i-1] == endoftext_token_id and pred[i] == endoftext_token_id) ]\n",
    "                                ) for pred in preds]\n",
    "                            targets_str = [tokenizer.decode(\n",
    "                                [target[i] for i in range( 1,  len( target )  ) if not (target[i-1] == endoftext_token_id and target[i] == endoftext_token_id) ]\n",
    "                                ) for target in captions]\n",
    "                        elif config.decode_t == 'no-pad':\n",
    "                            preds_str = [\n",
    "                                tokenizer.decode([i for i in pred if i != eos_token_id \\\n",
    "                                and i != pad_token_id ] ) \n",
    "                                for pred in hypo_ids\n",
    "                            ]\n",
    "                            preds_str2 = [\n",
    "                                tokenizer.decode([i for i in pred if i != eos_token_id], skip_special_tokens=True) \n",
    "                                for pred in hypo_ids\n",
    "                            ]\n",
    "                            samps_str = [tokenizer.decode(\n",
    "                                [ i for i in pred \\\n",
    "                                 if i != pad_token_id \\\n",
    "                                 and i != eos_token_id ] \\\n",
    "                                ) for pred in preds]\n",
    "                            targets_str = [tokenizer.decode(\n",
    "                                [ i for i in target \\\n",
    "                                if i != pad_token_id \\\n",
    "                                 and i != eos_token_id ]       \n",
    "                                ) for target in captions]\n",
    "                        else:\n",
    "                            preds_str = [tokenizer.decode(pred) for pred in hypo_ids]\n",
    "                            targets_str = [tokenizer.decode(target) for target in captions]\n",
    "                        pred_dict = { str(i): [item] for i, item in enumerate( preds_str)}\n",
    "                        target_dict = { str(i): [item] for i, item in enumerate( targets_str)}\n",
    "                        avg_bleu, scores = compute_reward.scorer.compute_score(target_dict, pred_dict) # cider の計算\n",
    "                        #avg_error = compute_reward.meteor.compute(predictions=preds_str, references=targets_str)['meteor']\n",
    "                        #avg_error = bleu_score.corpus_bleu( targets_str, preds_str, smoothing_function=fn  )\n",
    "                        rouge_scores = [compute_reward.rougeL.score(target, pred)['rougeL'][0] for pred, target in zip(preds_str, targets_str)]\n",
    "                        avg_error = sum( rouge_scores ) / len( rouge_scores )\n",
    "                        #clip_scores = [compute_reward.metric( img2, pred).detach() for img2, pred in zip( imgs2, preds_str2 )]\n",
    "                        with autocast(str(config.device),enabled=config.use_amp):\n",
    "                            with torch.no_grad():\n",
    "                                clip_score = compute_reward.metric( imgs2, preds_str2 ) / 100.0\n",
    "                                bert_scores = compute_reward.bert.compute(predictions=preds_str, references=targets_str, model_type=model_name, \\\n",
    "                                                                  lang='en',  device=config.device)['f1']\n",
    "                                #bert_scores = [score for score in bert_scores]\n",
    "                                bert_score = sum( bert_scores ) / len( bert_scores )\n",
    "                        if  global_step % train_param == 0:\n",
    "                            hypo_sentence1 = [preds_str[0]]\n",
    "                            samp_sentence1 = [samps_str[0]]\n",
    "                            ref_sentence1 = [targets_str[0]]\n",
    "                    #end_time = time.time()\n",
    "                    #print( \"sentence time:\", end_time - start_time )\n",
    "                    #start_time = time.time()\n",
    "                    if config.display_include_coef:                \n",
    "                        avg_bleu = config.cider_coef *  avg_bleu\n",
    "                        avg_error = config.rouge_coef * avg_error\n",
    "                        clip_score = config.clip_coef * clip_score\n",
    "                        bert_score = config.bert_coef * bert_score\n",
    "                    \n",
    "                    # 学習時の損失をログに書き込み\n",
    "                    #エポック内の平均\n",
    "                    train_losses.append(loss_item)\n",
    "                    train_policys.append(policy_item)\n",
    "                    train_entropies.append(entropy_item)\n",
    "                    train_critics.append(critic_item)\n",
    "                    train_kl_divs.append(kl_div_item)\n",
    "                    train_rewards.append(reward_item)\n",
    "                    train_rewards2.append(reward2_item)\n",
    "                    train_ord.append(ord_item)\n",
    "                    train_repeat.append(repeat_item)\n",
    "                    train_length.append(length_item)\n",
    "                    train_adv.append(adv_item)\n",
    "                    train_errors.append( avg_error )\n",
    "                    train_bleus.append( avg_bleu )\n",
    "                    train_crfs.append( crf_item )\n",
    "                    train_ces.append( ce_item )\n",
    "                    train_clips.append( clip_score )\n",
    "                    train_unrs.append( unr_item )\n",
    "                    train_berts.append( bert_score )\n",
    "                    if len(train_losses) > config.moving_avg:\n",
    "                        train_losses.popleft()\n",
    "                        train_policys.popleft()\n",
    "                        train_entropies.popleft()\n",
    "                        train_critics.popleft()\n",
    "                        train_kl_divs.popleft()\n",
    "                        train_rewards.popleft()\n",
    "                        train_rewards2.popleft()\n",
    "                        train_ord.popleft()\n",
    "                        train_repeat.popleft()\n",
    "                        train_length.popleft()\n",
    "                        train_adv.popleft()\n",
    "                        train_errors.popleft()\n",
    "                        train_bleus.popleft()\n",
    "                        train_crfs.popleft()\n",
    "                        train_ces.popleft()\n",
    "                        train_clips.popleft()\n",
    "                        train_unrs.popleft()\n",
    "                        train_berts.popleft()\n",
    "                    mean_loss = torch.Tensor(train_losses).mean().item()\n",
    "                    mean_policy = torch.Tensor(train_policys).mean().item()\n",
    "                    mean_entropy = torch.Tensor(train_entropies).mean().item()\n",
    "                    mean_critic = torch.Tensor(train_critics).mean().item()\n",
    "                    mean_kl_div = torch.Tensor(train_kl_divs).mean().item()\n",
    "                    mean_reward = torch.Tensor(train_rewards).mean().item()\n",
    "                    mean_reward2 = torch.Tensor(train_rewards2).mean().item()\n",
    "                    mean_ord = torch.Tensor(train_ord).mean().item()\n",
    "                    mean_repeat = torch.Tensor(train_repeat).mean().item()\n",
    "                    mean_length = torch.Tensor(train_length).mean().item()\n",
    "                    mean_adv = torch.Tensor(train_adv).mean().item()\n",
    "                    mean_error = torch.Tensor(train_errors).mean().item()\n",
    "                    mean_bleu = torch.Tensor(train_bleus).mean().item()\n",
    "                    mean_crf = torch.Tensor(train_crfs).mean().item()\n",
    "                    mean_ce = torch.Tensor(train_ces).mean().item()\n",
    "                    mean_clip = torch.Tensor(train_clips).mean().item()\n",
    "                    mean_unr = torch.Tensor(train_unrs).mean().item()\n",
    "                    mean_bert = torch.Tensor(train_berts).mean().item()\n",
    "                    #print( \"mean_reward2:\", mean_reward2 ) \n",
    "                    pbar.set_postfix({\n",
    "                        'loss': mean_loss,\n",
    "                        'policy': mean_policy,\n",
    "                        'entropy': mean_entropy,\n",
    "                        'gae': mean_critic,\n",
    "                        'kl_div': mean_kl_div,\n",
    "                        'reward': mean_reward,\n",
    "                        'reward2': mean_reward2,\n",
    "                        'ord': mean_ord,\n",
    "                        'repeat': mean_repeat,\n",
    "                        'length': mean_length,\n",
    "                        'adv': mean_adv,\n",
    "                        'rougeL': mean_error,\n",
    "                        'cider': mean_bleu,\n",
    "                        'crf': mean_crf,\n",
    "                        'ce': mean_ce,\n",
    "                        'clip': mean_clip,\n",
    "                        'unr': mean_unr,\n",
    "                        'bert': mean_bert,\n",
    "                    })\n",
    "                    with open(train_loss_file, 'a') as f:\n",
    "                        #print(f'{epoch}, {mean_loss}, {mean_reward}, {mean_ord}, {mean_repeat}, {mean_length}, {mean_error}, {mean_bleu}', file=f)\n",
    "                        #print( \"global_step:\", global_step )\n",
    "                        #print( \"file_param:\", file_param )\n",
    "                        print(f' {global_step}, {mean_loss}, {mean_policy}, {mean_entropy}, {mean_critic}, {mean_kl_div}, {mean_reward}, ' \\\n",
    "                              f'{mean_ord}, {mean_repeat}, {mean_length}, {mean_adv}, {mean_error}, {mean_bleu}, {mean_crf}, {mean_ce}, '\\\n",
    "                              f'{mean_clip}, {mean_unr}, {mean_bert}', file=f)\n",
    "                        #print(f'{epoch}, {mean_loss}, {mean_reward}, {mean_error}, {mean_bleu}', file=f)\n",
    "                    print_flag = 1\n",
    "                    for ( hypo_se, ref_se, samp_se ) in zip( hypo_sentence1, ref_sentence1, samp_sentence1 ):\n",
    "                        if print_flag == 1:\n",
    "                            #print( \"lr clip  :\", optimizer.param_groups[0][\"lr\"] )\n",
    "                            print( \"lr con   :\", optimizer.param_groups[0][\"lr\"] )\n",
    "                            print( \"lr bert  :\", optimizer.param_groups[1][\"lr\"] )\n",
    "                            print( \"lr cri   :\", optimizer.param_groups[2][\"lr\"] )\n",
    "                            print( \"lr others:\", optimizer.param_groups[3][\"lr\"] )\n",
    "                            print_flag = 0\n",
    "                        print(f'Train epoch = {global_step/len_tr_loader}, loss = {mean_loss}, policy = {mean_policy}, '\\\n",
    "                              f'entropy_loss = {mean_entropy}, gae = {mean_critic}, kl_div = {mean_kl_div}, reward = {mean_reward}, '\\\n",
    "                              f'ord = {mean_ord}, repeat = {mean_repeat}, length = {mean_length}, adv = {mean_adv}, '\\\n",
    "                              f'rougeL = {mean_error}, cider = {mean_bleu}, clip = {mean_clip}, crf = {mean_crf}, ce = {mean_ce}, '\\\n",
    "                              f'unr = {mean_unr}, ber = {mean_bert}' )\n",
    "                        #print(f'Train epoch = { global_step / len_tr_loader }, loss = {mean_loss}, reward = {mean_reward}, WER = {mean_error}, BLEU = {mean_bleu}')\n",
    "                        print( \"refe:\", ref_se )\n",
    "                        print( \"hypo:\", hypo_se )\n",
    "                        print( \"samp:\", samp_se )\n",
    "                    #end_time = time.time()\n",
    "                    #print( \"file time:\", end_time - start_time )\n",
    "                    \n",
    "                    # 4. 中間報告 (枝刈り用)\n",
    "                    trial.report(float(mean_reward2), global_step)\n",
    "                    if trial.should_prune():\n",
    "                        raise optuna.exceptions.TrialPruned()\n",
    "                    #end_time0 = time.time()\n",
    "                    #print( \"all time:\", end_time0 - start_time0 )\n",
    "                global_step += 1\n",
    "        avg_reward = mean_reward2\n",
    "        \n",
    "        # 2. 損失と報酬の計算\n",
    "        # 実際には学習データが必要ですが、ここではダミー\n",
    "        '''\n",
    "        dummy_state = torch.randn(1, 4)\n",
    "        total_loss, avg_reward = calculate_loss_and_reward(\n",
    "            model, dummy_state, None, None, None, None, params\n",
    "        )\n",
    "        '''\n",
    "        #avg_reward = mean_reward\n",
    "        print( f'epoch = {epoch}, avg_reward = {avg_reward}' )\n",
    "        \n",
    "        # 3. 学習（実際はここにoptimizer.step()が入る）\n",
    "        \n",
    "        ## 4. 中間報告 (枝刈り用)\n",
    "        #trial.report(avg_reward, epoch)\n",
    "        #if trial.should_prune():\n",
    "        #    raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    # Optunaは目的関数が「最大化」か「最小化」かを選択する。\n",
    "    # ここでは報酬を最大化したいので、負の報酬を返すか、direction=\"maximize\"を指定する\n",
    "    return avg_reward\n",
    "\n",
    "\n",
    "\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "config = ConfigTrain()\n",
    "\n",
    "model_id = \"google-bert/bert-large-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_id)\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "cls_token_id = tokenizer.cls_token_id\n",
    "sep_token_id = tokenizer.sep_token_id\n",
    "sos_token_id = tokenizer.encode( [ \"[unused0]\" ] )[1]\n",
    "eos_token_id = tokenizer.encode( [ \"[unused1]\" ] )[1]\n",
    "a_token_id = tokenizer.encode( [ \"a\" ] )[1]\n",
    "the_token_id = tokenizer.encode( [ \"the\" ] )[1]\n",
    "and_token_id = tokenizer.encode( [ \"and\" ] )[1]\n",
    "in_token_id = tokenizer.encode( [ \"in\" ] )[1]\n",
    "we_token_id = tokenizer.encode( [ \"we\" ] )[1]\n",
    "i_token_id = tokenizer.encode( [ \"i\" ] )[1]\n",
    "he_token_id = tokenizer.encode( [ \"he\" ] )[1]\n",
    "she_token_id = tokenizer.encode( [ \"she\" ] )[1]\n",
    "it_token_id = tokenizer.encode( [ \"it\" ] )[1]\n",
    "they_token_id = tokenizer.encode( [ \"they\" ] )[1]\n",
    "period_token_id = tokenizer.encode( [ \".\" ] )[1]\n",
    "comma_token_id = tokenizer.encode( [ \",\" ] )[1]\n",
    "dbl_token_id = tokenizer.encode( [ '\"' ] )[1]\n",
    "sgl_token_id = tokenizer.encode( [ \"'\" ] )[1]\n",
    "\n",
    "# 辞書サイズを保存\n",
    "vocab_size = len( tokenizer )\n",
    "\n",
    "# モデル出力用のディレクトリを作成\n",
    "os.makedirs(config.save_directory, exist_ok=True)\n",
    "\n",
    "# 画像のtransformsを定義\n",
    "transforms = v2.Compose([\n",
    "    v2.Resize((336, 336)),\n",
    "    v2.AutoAugment(),\n",
    "    #v2.ToTensor(),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    ## Coco データセット 2017 train の平均と標準偏差\n",
    "    #v2.Normalize((0.456,0.427,0.401),(0.224,0.219,0.231) )\n",
    "    # ImageNetデータセットの平均と標準偏差\n",
    "    #v2.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "    # Clip Model の config から引用。\n",
    "    v2.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "])\n",
    "\n",
    "transforms2 = v2.Compose([\n",
    "    v2.Resize((224, 224)),\n",
    "    v2.ToImage(),\n",
    "    #v2.ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "# v7 データセット\n",
    "train_dataset = MyDataset( file_path=config.anno_file,\n",
    "                           img_directory = config.img_directory,\n",
    "                           transforms=transforms, transforms2 = transforms2,\n",
    "                           tokenizer=tokenizer, length_max = config.length_max)\n",
    "\n",
    "# Subset samplerの生成\n",
    "test_set, val_set, train_set = util.generate_subset_test_val_train(\n",
    "    train_dataset, config.test_ratio, config.val_ratio )\n",
    "    \n",
    "# 学習時にランダムにサンプルするためのサンプラー\n",
    "train_sampler = SubsetRandomSampler(train_set)\n",
    "test_sampler = SubsetRandomSampler(test_set)\n",
    "\n",
    "# DataLoaderを生成\n",
    "collate_func_lambda = lambda x: collate_func(x, tokenizer.pad_token_id, config.length_max)\n",
    "#train_loader = torch.utils.data.DataLoader(\n",
    "#                    train_dataset,\n",
    "#                    batch_size=config.batch_size,\n",
    "#                    num_workers=config.num_workers,\n",
    "#                    sampler=train_sampler,\n",
    "#                    collate_fn=collate_func_lambda)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                    train_dataset,\n",
    "                    #batch_size=config.batch_size,\n",
    "                    batch_size=config.batch_size,\n",
    "                    num_workers=config.num_workers,\n",
    "                    sampler=test_sampler,\n",
    "                    collate_fn=collate_func_lambda)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "                    train_dataset,\n",
    "                    batch_size=config.batch_size,\n",
    "                    num_workers=config.num_workers,\n",
    "                    sampler=val_set,\n",
    "                    collate_fn=collate_func_lambda)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                    train_dataset,\n",
    "                    #batch_size=config.batch_size,\n",
    "                    batch_size=config.batch_size,\n",
    "                    num_workers=config.num_workers,\n",
    "                    sampler=test_set,\n",
    "                    collate_fn=collate_func_lambda)\n",
    "\n",
    "\n",
    "print( \"config.device:\", config.device )\n",
    "print( \"学習セット数:\",len( train_loader ) )\n",
    "print( \"評価セット数:\",len( val_loader ))\n",
    "print( \"テストセット数:\",len( test_loader ))\n",
    "print( \"use_amp:\", config.use_amp )\n",
    "print( \"use_saved_pth:\", config.use_saved_pth )\n",
    "\n",
    "\n",
    "# 全ステップ数\n",
    "num_global_steps = len( train_loader ) * config.num_epochs\n",
    "print( \"num_global_steps:\", num_global_steps )\n",
    "print( \"warmup:\", config.warmup )\n",
    "num_warmup_steps = num_global_steps * config.warmup\n",
    "print( \"num_warmup_steps:\", num_warmup_steps )\n",
    "\n",
    "def entropy_func(probs):\n",
    "    input_probs = torch.clamp( probs, eps )\n",
    "    log_probs = torch.log( input_probs )\n",
    "    p_log_p = probs * log_probs\n",
    "    return - p_log_p.sum(-1)\n",
    "\n",
    "def baseline( probs, targets, top_k ):\n",
    "    probs_k, preds_k = torch.topk( probs, dim = 2, k = top_k )\n",
    "    renorm_probs_k = probs_k / torch.sum( probs_k, dim = 2 )[:,:, None]\n",
    "    base_ = torch.stack( [ probs_k[:,:,k] * compue_reward._compute_reward(preds_k[:,:,k], targets, sources = None ) \\\n",
    "                        for k in range( top_k ) ], dim = 0 )\n",
    "    base = torch.sum( base_, dim = 0 )\n",
    "    \n",
    "    return base\n",
    "\n",
    "def custom_gradient_clipping(clip_params, gpt2_params, cri_params, others_params, \n",
    "                             clip_threshold, gpt2_threshold, cri_threshold, others_threshold):\n",
    "    # エンコーダーの勾配クリッピング\n",
    "    if clip_params:\n",
    "        # torch.nn.utils.clip_grad_norm_ は、与えられたパラメータのリストに勾配クリッピングを適用する\n",
    "        torch.nn.utils.clip_grad_norm_(clip_params, clip_threshold)\n",
    "    # デコーダーの勾配クリッピング\n",
    "    if gpt2_params:\n",
    "        torch.nn.utils.clip_grad_norm_(gpt2_params, gpt2_threshold)\n",
    "    # デコーダーの勾配クリッピング\n",
    "    if cri_params:\n",
    "        torch.nn.utils.clip_grad_norm_(cri_params, cri_threshold)\n",
    "    # デコーダーの勾配クリッピング\n",
    "    if gpt2_params:\n",
    "        torch.nn.utils.clip_grad_norm_(others_params, others_threshold)\n",
    "\n",
    "def generalized_advantage_estimation(rewards, values, gamma=0.99, lam=0.95):\n",
    "\n",
    "    B, T = rewards.size()\n",
    "    \n",
    "    # 各タイムステップでのTD誤差 (delta_t) を計算\n",
    "    # delta_t = R_t + gamma * V(s_{t+1}) - V(s_t)\n",
    "    # values[:, :-1] は V(s_t)、values[:, 1:] は V(s_{t+1}) に対応\n",
    "    deltas = rewards + gamma * values[:, 1:] - values[:, :-1]\n",
    "    # deltas の形状は (B, T)\n",
    "\n",
    "    advantages = torch.zeros((B, T), device=rewards.device, dtype=torch.float)\n",
    "    \n",
    "    # 最後のタイムステップのadvantageは delta_t そのもの\n",
    "    advantages[:, T-1] = deltas[:, T-1]\n",
    "    \n",
    "    for t in range(T - 2, -1, -1):\n",
    "        advantages[:, t] = deltas[:, t] + gamma * lam * advantages[:, t+1]\n",
    "        \n",
    "    return advantages\n",
    "    \n",
    "#if config.metric == 'rouge':\n",
    "#    rougeL = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "def my_index( list1, target ):\n",
    "    if target in list1:\n",
    "        return list1.index( target )\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def get_nearest_multiple(a, b):\n",
    "    \"\"\"\n",
    "    a に最も近い b の倍数を求める\n",
    "    \"\"\"\n",
    "    # a/b を四捨五入して、それに b を掛ける\n",
    "    # round() は .5 の場合、偶数側に丸める性質があるため、\n",
    "    # 厳密な四捨五入が必要な場合は整数演算を使用する\n",
    "    return round(a / b) * b\n",
    "\n",
    "#torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "\n",
    "# --- 4. 最適化の実行 ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 報酬を最大化したいのでdirection=\"maximize\"\n",
    "    file_path = \"./optuna_journal_storage_20260204.log\"\n",
    "    \n",
    "    # Create the storage object using JournalFileBackend\n",
    "    storage = JournalStorage(JournalFileBackend(file_path))\n",
    "    #study = optuna.create_study(direction=\"maximize\", storage=\"sqlite:///db.sqlite3\", study_name=\"quadratic-simple6\" )\n",
    "    pruner = optuna.pruners.PercentilePruner(\n",
    "        percentile= 65.0, \n",
    "        n_startup_trials=5\n",
    "    )\n",
    "    study = optuna.create_study(direction=\"maximize\", study_name=\"example-study15\", storage=storage, \n",
    "                                pruner = pruner )\n",
    "    #study = optuna.create_study(direction=\"maximize\", study_name=\"example-study15\", storage=storage, \n",
    "    #                            pruner = optuna.pruners.MedianPruner() )\n",
    "    study.optimize(objective, n_trials=64, n_jobs = 1 ) # 64回試行\n",
    "\n",
    "    print(\"Best params:\", study.best_params)\n",
    "    print(\"Best reward:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを保存\n",
    "torch.save({'epoch': epoch,\n",
    "    'global_step': global_step,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict(),\n",
    "    #'loss': loss,\n",
    "    },\n",
    "    f'{config.save_directory}/model_rl_ppo_critic_crf_ontheway.pth')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "b411586366dd8bdb0fc2800d6aef8fbd6cc14d2a48eec1b457375028a8621915"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "10ac0991cf0d4346a2dd950c4e69de74": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc134416b78b4e16ab143f7b3c9b4db1",
      "placeholder": "​",
      "style": "IPY_MODEL_3e3ad9c31b8244d9987cb5d09ac80909",
      "value": " 230M/230M [00:03&lt;00:00, 57.2MB/s]"
     }
    },
    "189ddc1a5e674235a5a4c9461ec37bb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89ed549065394bad9c015c612b04c1d5",
      "placeholder": "​",
      "style": "IPY_MODEL_f9994c1870c348b0ab983404decb722e",
      "value": "100%"
     }
    },
    "2030796b20a24135908446e8a05b2447": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e3ad9c31b8244d9987cb5d09ac80909": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "741ba7eec1f94e6889152972dbf220c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89ed549065394bad9c015c612b04c1d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af8d4c88aa714714b864351862297512": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_741ba7eec1f94e6889152972dbf220c0",
      "max": 241669177,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_be3b477f459a4fdd80b055ef88cf8b52",
      "value": 241669177
     }
    },
    "be3b477f459a4fdd80b055ef88cf8b52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dc134416b78b4e16ab143f7b3c9b4db1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee1785c740b7449584ceec0225c64c78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_189ddc1a5e674235a5a4c9461ec37bb7",
       "IPY_MODEL_af8d4c88aa714714b864351862297512",
       "IPY_MODEL_10ac0991cf0d4346a2dd950c4e69de74"
      ],
      "layout": "IPY_MODEL_2030796b20a24135908446e8a05b2447"
     }
    },
    "f9994c1870c348b0ab983404decb722e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
